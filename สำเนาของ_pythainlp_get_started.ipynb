{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thippawan72/Thesis/blob/main/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_pythainlp_get_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5cVDAWIgp7"
      },
      "source": [
        "# PyThaiNLP Get Started\n",
        "\n",
        "Code examples for basic functions in PyThaiNLP https://github.com/PyThaiNLP/pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HsfhZlwInqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "5e9ba644-0750-40aa-ea59-c0cff7144da0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-7-cd796c9ecdfa>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-cd796c9ecdfa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install required modules\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# # pip install required modules\n",
        "# # uncomment if running from colab\n",
        "# # see list of modules in `requirements` and `extras`\n",
        "# # in https://github.com/PyThaiNLP/pythainlp/blob/dev/setup.py\n",
        "\n",
        "#!pip install pythainlp\n",
        "#!pip install epitran"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install required modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaT_g8fV-7xp",
        "outputId": "4fcf473b-e94b-4d73-c03a-b62f99cfa17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting required\n",
            "  Downloading required-0.4.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting modules\n",
            "  Downloading modules-1.0.0.tar.gz (525 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from required) (1.16.0)\n",
            "Collecting lark-parser (from required)\n",
            "  Downloading lark_parser-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading required-0.4.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading lark_parser-0.12.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: modules\n",
            "  Building wheel for modules (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modules: filename=modules-1.0.0-py3-none-any.whl size=1198 sha256=9a5dedfa03d15c0b8938e8099271605bca31f0c26a909d441ad734f16260c461\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/1b/5a/0e7760d483cf2ac6001c9df78809f16feb9632607248e3ab78\n",
            "Successfully built modules\n",
            "Installing collected packages: modules, lark-parser, required\n",
            "Successfully installed lark-parser-0.12.0 modules-1.0.0 required-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp\n",
        "!pip install epitran"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E32blbWe_CLX",
        "outputId": "4ec5d394-3d2b-4a5f-b366-2dd4b486bedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n",
            "Requirement already satisfied: epitran in /usr/local/lib/python3.10/dist-packages (1.25.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from epitran) (71.0.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from epitran) (2024.5.15)\n",
            "Requirement already satisfied: panphon>=0.20 in /usr/local/lib/python3.10/dist-packages (from epitran) (0.21.2)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.10/dist-packages (from epitran) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from epitran) (2.32.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from epitran) (0.4.1)\n",
            "Requirement already satisfied: g2pk in /usr/local/lib/python3.10/dist-packages (from epitran) (0.9.4)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.14.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.26.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.8.1)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (3.8.1)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (0.6.0)\n",
            "Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (1.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2024.8.30)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy->g2pk->epitran) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy->g2pk->epitran) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (4.66.5)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.10/dist-packages (from python-mecab-ko->g2pk->epitran) (2.1.1.post2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy->g2pk->epitran) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqR6Klwc-UAH"
      },
      "source": [
        "## Import PyThaiNLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp"
      ],
      "metadata": {
        "id": "9IhnIXQJ-oDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7CkITTf-UAH",
        "outputId": "44d70726-ba91-4795-a446-86974b8399b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import pythainlp\n",
        "\n",
        "pythainlp.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6gy4MLGIgp9"
      },
      "source": [
        "## Thai Characters\n",
        "\n",
        "PyThaiNLP provides some ready-to-use Thai character set (e.g. Thai consonants, vowels, tonemarks, symbols) as a string for convenience. There are also few utility functions to test if a string is in Thai or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GAvoeZg3Igp-",
        "outputId": "d516c0c1-39fd-4608-b707-34acba43e034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮฤฦะัาำิีึืุูเแโใไๅํ็่้๊๋ฯฺๆ์ํ๎๏๚๛๐๑๒๓๔๕๖๗๘๙฿'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "pythainlp.thai_characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFPtK_FL-UAI",
        "outputId": "b06d9b29-3d67-4a40-91bf-5dbdda96ddba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(pythainlp.thai_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uPwx53A6IgqF",
        "outputId": "08cd9333-4ccc-49d3-a28b-118ba8061033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "pythainlp.thai_consonants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5-lZjsd-UAJ",
        "outputId": "5c834204-285e-4065-9aae-5642ff246252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(pythainlp.thai_consonants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UA7Hwy_IgqI",
        "outputId": "e9bb135f-4098-4da8-8b21-d43201176b42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"๔\" in pythainlp.thai_digits  # check if Thai digit \"4\" is in the character set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vFPqeB-UAJ"
      },
      "source": [
        "## Checking if a string contains Thai character or not, or how many"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3NvXqYFIgqK",
        "outputId": "2b26fbe8-86a0-42c9-f06d-7cd64d181076"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pythainlp.util\n",
        "\n",
        "pythainlp.util.isthai(\"ก\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRzSQjugIgqM",
        "outputId": "5c7c8eb9-bb6f-4f3a-acb0-cc8143358e59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP5yfJebIgqP",
        "outputId": "3df56ae7-2228-4428-a02a-027a9fe5bad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\", ignore_chars=\".()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67XQsoLL-UAK"
      },
      "source": [
        "`counthai()` returns proportion of Thai characters in the text. It will ignore non-alphabets by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Z8P9WPIgqS",
        "outputId": "0d2d9f85-e412-4d14-a50e-100bd311c0a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pythainlp.util.countthai(\"วันอาทิตย์ที่ 24 มีนาคม 2562\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGszqWuT-UAK"
      },
      "source": [
        "You can specify characters to be ignored, using `ignore_chars=` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukSQP8ZTIgqV",
        "outputId": "ba26f044-8651-4d98-96d3-583ca619b6d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.85714285714286"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "pythainlp.util.countthai(\"วันอาทิตย์ที่ 24 มีนาคม 2562\", ignore_chars=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW89ZW-IIgqX"
      },
      "source": [
        "## Collation\n",
        "\n",
        "Sorting according to Thai dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT1Pj52bIgqY",
        "outputId": "381e1cfd-50bb-4629-db8b-03ec1e65039c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['กรรไกร', 'กระดาษ', 'ไข่', 'ค้อน', 'ผ้าไหม']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from pythainlp.util import collate\n",
        "\n",
        "thai_words = [\"ค้อน\", \"กระดาษ\", \"กรรไกร\", \"ไข่\", \"ผ้าไหม\"]\n",
        "collate(thai_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgWpZM8hIgqb",
        "outputId": "687fe07f-9e04-4022-fa10-89af2b48bd66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ผ้าไหม', 'ค้อน', 'ไข่', 'กระดาษ', 'กรรไกร']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "collate(thai_words, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-czYhLoIgqd"
      },
      "source": [
        "## Date/Time Format and Spellout\n",
        "\n",
        "### Date/Time Format\n",
        "\n",
        "Get Thai day and month names with Thai Buddhist Era (B.E.).\n",
        "Use [formatting directives](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes) similar to `datetime.strftime()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F03_rMWzIgqe",
        "outputId": "67a398d3-c787-4af3-e582-71c5285a81a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'วันพุธที่ 6 ตุลาคม พ.ศ. 2519 เวลา 01:40 น. (พ 06-ต.ค.-19)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import datetime\n",
        "from pythainlp.util import thai_strftime\n",
        "\n",
        "fmt = \"%Aที่ %-d %B พ.ศ. %Y เวลา %H:%M น. (%a %d-%b-%y)\"\n",
        "date = datetime.datetime(1976, 10, 6, 1, 40)\n",
        "\n",
        "thai_strftime(date, fmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbjY7JYm-UAL"
      },
      "source": [
        "From version 2.2, these modifiers can be applied right before the main directive:\n",
        "\n",
        "- \\- *(minus)* Do not pad a numeric result string (also available in version 2.1)\n",
        "- _ *(underscore)* Pad a numeric result string with spaces\n",
        "- 0 *(zero)* Pad a number result string with zeros\n",
        "- ^ Convert alphabetic characters in result string to upper case\n",
        "- \\# Swap the case of the result string\n",
        "- O *(letter o)* Use the locale's alternative numeric symbols (Thai digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcqzsFJp-UAL",
        "outputId": "95b09ec9-0bcd-4830-8a33-2abb7344e838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'06 ต.ค. 19'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "thai_strftime(date, \"%d %b %y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppX8FG1b-UAM",
        "outputId": "e5f7fba7-60b7-47bf-cd62-1d8d4516d59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'06 ต.ค. 2519'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "thai_strftime(date, \"%d %b %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej4VAWSJ-UAM"
      },
      "source": [
        "### Time Spellout\n",
        "\n",
        "*Note: `Ctrl + H()` will be renamed to `time_to_thaiword()` in version 2.2.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.util import time_to_thaiword"
      ],
      "metadata": {
        "id": "DxAJC8CTAXZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z70PRUbm-UAM",
        "outputId": "bd14a125-b81c-4f6e-ba33-ab32f06b32bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ศูนย์นาฬิกาสิบสี่นาทียี่สิบเก้าวินาที'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "time_to_thaiword(\"00:14:29\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QS26XLp-UAM"
      },
      "source": [
        "The way to spellout can be chosen, using `fmt` parameter.\n",
        "It can be `24h`, `6h`, or `m6h`. Try one by yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENrLyM27-UAM",
        "outputId": "e4b6f20d-fcb0-4a21-efd8-5a5ea1524409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'เที่ยงคืนสิบสี่นาทียี่สิบเก้าวินาที'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "time_to_thaiword(\"00:14:29\", fmt=\"6h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grli9O1A-UAM"
      },
      "source": [
        "Precision of spellout can be chosen as well. Using `precision` parameter.\n",
        "It can be `m` for minute-level, `s` for second-level, or `None` for only read the non-zero value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7LTZ0XA-UAM",
        "outputId": "77eebd58-7040-4fef-8424-c9d15e5aca8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ศูนย์นาฬิกาสิบสี่นาที'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "time_to_thaiword(\"00:14:29\", precision=\"m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "7puTs1z4ClQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiMb6ove-UAM",
        "outputId": "6175b7d2-4465-44c3-96b4-984d6d323dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'datetime.time' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-baa16a11d9f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"8:17:00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"6h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"8:17:00\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m6h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"18:30:01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m6h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"13:30:01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"6h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'datetime.time' object is not callable"
          ]
        }
      ],
      "source": [
        "print(datetime and time(\"8:17:00\", fmt=\"6h\"))\n",
        "print(datetime and time(\"8:17:00\", fmt=\"m6h\", precision=\"s\"))\n",
        "print(datetime and time(\"18:30:01\", fmt=\"m6h\", precision=\"m\"))\n",
        "print(datetime and time(\"13:30:01\", fmt=\"6h\", precision=\"m\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0igdpyv-UAN"
      },
      "source": [
        "We can also pass `datetime` and `time` objects to `Ctrl + H()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjkCgAFH-UAN",
        "outputId": "888dc521-e6e8-443b-a506-b7b0c8f857e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Ctrl' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f76e3bd3335f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mCtrl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Ctrl' is not defined"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "\n",
        "time = datetime.time(13, 14, 15)\n",
        "Ctrl + H(time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2KewA0a-UAN",
        "outputId": "5ba5ed8c-1399-473d-df87-b9fd68173310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b85c1f6430dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCtrl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"6h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
          ]
        }
      ],
      "source": [
        "time = datetime.datetime(10, 11, 12, 13, 14, 15)\n",
        "Ctrl + H(time, fmt=\"6h\", precision=\"m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VFPOHyZIgqh"
      },
      "source": [
        "## Tokenization and Segmentation\n",
        "\n",
        "At sentence, word, and sub-word levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzDO2rIP-UAN"
      },
      "source": [
        "### Sentence\n",
        "\n",
        "Default sentence tokenizer is \"crfcut\". Tokenization engine can be chosen ussing `engine=` parameter."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import sent_tokenize"
      ],
      "metadata": {
        "id": "WDZtB1BND8m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSfHsKYc-UAN",
        "outputId": "296ece4b-c0e6-4d76-9434-04703a7878d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default (crfcut):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycrfsuite'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c4b28ede4b21>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default (crfcut):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# การตัดแบ่งด้วยเครื่องมือ CRF (ค่าเริ่มต้น)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nwhitespace+newline:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pythainlp/tokenize/core.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, engine, keep_whitespace)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crfcut\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrfcut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pythainlp/tokenize/crfcut.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycrfsuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpus_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycrfsuite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "text = (\"พระราชบัญญัติธรรมนูญการปกครองแผ่นดินสยามชั่วคราว พุทธศักราช ๒๔๗๕ \"\n",
        "        \"เป็นรัฐธรรมนูญฉบับชั่วคราว ซึ่งถือว่าเป็นรัฐธรรมนูญฉบับแรกแห่งราชอาณาจักรสยาม \"\n",
        "        \"ประกาศใช้เมื่อวันที่ 27 มิถุนายน พ.ศ. 2475 \"\n",
        "        \"โดยเป็นผลพวงหลังการปฏิวัติเมื่อวันที่ 24 มิถุนายน พ.ศ. 2475 โดยคณะราษฎร\")\n",
        "\n",
        "print(\"default (crfcut):\")\n",
        "print(sent_tokenize(text))  # การตัดแบ่งด้วยเครื่องมือ CRF (ค่าเริ่มต้น)\n",
        "\n",
        "print(\"\\nwhitespace+newline:\")\n",
        "print(sent_tokenize(text, engine=\"whitespace+newline\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SklPJ-DbIgqi"
      },
      "source": [
        "### Word\n",
        "Default word tokenizer (\"newmm\") use maximum matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbY-MGCIgqi",
        "outputId": "8f3ff00e-a522-4260-e005-b337ba3cb819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default (newmm):\n",
            "['ก็', 'จะ', 'รู้ความ', 'ชั่วร้าย', 'ที่', 'ทำ', 'ไว้', '     ', 'และ', 'คงจะ', 'ไม่', 'ยอมให้', 'ทำนาบนหลังคน', ' ']\n",
            "\n",
            "newmm and keep_whitespace=False:\n",
            "['ก็', 'จะ', 'รู้ความ', 'ชั่วร้าย', 'ที่', 'ทำ', 'ไว้', 'และ', 'คงจะ', 'ไม่', 'ยอมให้', 'ทำนาบนหลังคน']\n"
          ]
        }
      ],
      "source": [
        "from pythainlp import word_tokenize\n",
        "\n",
        "text = \"ก็จะรู้ความชั่วร้ายที่ทำไว้     และคงจะไม่ยอมให้ทำนาบนหลังคน \"\n",
        "\n",
        "print(\"default (newmm):\")\n",
        "print(word_tokenize(text))\n",
        "print(\"\\nnewmm and keep_whitespace=False:\")\n",
        "print(word_tokenize(text, keep_whitespace=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import word_tokenize\n",
        "\n",
        "text = \"กฎหมายแรงงานฉบับปรับปรุงใหม่ประกาศใช้แล้ว\"\n",
        "\n",
        "print(\"default (newmm):\")\n",
        "print(word_tokenize(text))\n",
        "print(\"\\nnewmm and keep_whitespace=False:\")\n",
        "print(word_tokenize(text, keep_whitespace=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjRCSZN_Ipca",
        "outputId": "9f68eba8-5591-4489-e68c-1c2a008e97f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default (newmm):\n",
            "['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศ', 'ใช้แล้ว']\n",
            "\n",
            "newmm and keep_whitespace=False:\n",
            "['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศ', 'ใช้แล้ว']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5P_YygrIgqm"
      },
      "source": [
        "Other algorithm can be chosen. We can also create a tokenizer with a custom dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI_Qz3k3Igqm",
        "outputId": "957fe076-356b-45cf-83b4-3d232e96a275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "newmm  : ['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศ', 'ใช้แล้ว']\n",
            "longest: ['กฎหมายแรงงาน', 'ฉบับ', 'ปรับปรุง', 'ใหม่', 'ประกาศใช้', 'แล้ว']\n",
            "newmm (custom dictionary): ['กฎหมาย', 'แรงงาน', 'ฉบับปรับปรุงใหม่ประกาศใช้แล้ว']\n"
          ]
        }
      ],
      "source": [
        "from pythainlp import word_tokenize, Tokenizer\n",
        "\n",
        "text = \"กฎหมายแรงงานฉบับปรับปรุงใหม่ประกาศใช้แล้ว\"\n",
        "\n",
        "print(\"newmm  :\", word_tokenize(text))  # default engine is \"newmm\"\n",
        "print(\"longest:\", word_tokenize(text, engine=\"longest\"))\n",
        "\n",
        "words = [\"แรงงาน\"]\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"newmm (custom dictionary):\", custom_tokenizer.word_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXUxXlTIgqo"
      },
      "source": [
        "Default word tokenizer use a word list from `pythainlp.corpus.common.thai_words()`.\n",
        "We can get that list, add/remove words, and create new tokenizer from the modified list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RblqNckGIgqp",
        "outputId": "3170b8e3-99fb-4652-be0c-deefb6670b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นิยาย', 'วิทยาศาสตร์', 'ของ', 'ไอแซค', ' ', 'อสิ', 'มอ', 'ฟ']\n",
            "custom dictionary : ['นิยาย', 'วิทยาศาสตร์', 'ของ', 'ไอแซค', ' ', 'อสิมอฟ']\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.corpus.common import thai_words\n",
        "from pythainlp import Tokenizer\n",
        "\n",
        "text = \"นิยายวิทยาศาสตร์ของไอแซค อสิมอฟ\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"ไอแซค\")  # Isaac\n",
        "words.add(\"อสิมอฟ\")  # Asimov\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mWg1n_Z-UAR"
      },
      "source": [
        "We can also, alternatively, create a dictionary trie, using `pythainlp.util.Trie()` function, and pass it to a default tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uliOPlop-UAR",
        "outputId": "84f4a829-bd92-415e-de21-dd9da5f390d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ILO', '87', ' ', 'ว่าด้วย', 'เสรีภาพ', 'ใน', 'การสมาคม', 'และ', 'การ', 'คุ้มครอง', 'สิทธิ', 'ใน', 'การ', 'รวมตัว', ' ', 'ILO', '98', ' ', 'ว่าด้วย', 'สิทธิ', 'ใน', 'การ', 'รวมตัว', 'และ', 'การ', 'ร่วม', 'เจรจา', 'ต่อรอง']\n",
            "custom dictionary : ['ILO87', ' ', 'ว่าด้วย', 'เสรีภาพในการสมาคม', 'และ', 'การ', 'คุ้มครอง', 'สิทธิในการรวมตัว', ' ', 'ILO98', ' ', 'ว่าด้วย', 'สิทธิในการรวมตัว', 'และ', 'การร่วมเจรจาต่อรอง']\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.corpus.common import thai_words\n",
        "from pythainlp.util import Trie\n",
        "\n",
        "text = \"ILO87 ว่าด้วยเสรีภาพในการสมาคมและการคุ้มครองสิทธิในการรวมตัว ILO98 ว่าด้วยสิทธิในการรวมตัวและการร่วมเจรจาต่อรอง\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text))\n",
        "\n",
        "new_words = {\"ILO87\", \"ILO98\", \"การร่วมเจรจาต่อรอง\", \"สิทธิในการรวมตัว\", \"เสรีภาพในการสมาคม\", \"แรงงานสัมพันธ์\"}\n",
        "words = new_words.union(thai_words())\n",
        "\n",
        "custom_dictionary_trie = Trie(words)\n",
        "print(\"custom dictionary :\", word_tokenize(text, custom_dict=custom_dictionary_trie))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GF8qRVK-UAR"
      },
      "source": [
        "Testing different tokenization engines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L2kRMY5Igqr"
      },
      "outputs": [],
      "source": [
        "speedtest_text = \"\"\"\n",
        "ครบรอบ 14 ปี ตากใบ เช้าวันนั้น 25 ต.ค. 2547 ผู้ชุมนุมชายกว่า 1,370 คน\n",
        "ถูกโยนขึ้นรถยีเอ็มซี 22 หรือ 24 คัน นอนซ้อนกันคันละ 4-5 ชั้น เดินทางจากสถานีตำรวจตากใบ ไปไกล 150 กิโลเมตร\n",
        "ไปถึงค่ายอิงคยุทธบริหาร ใช้เวลากว่า 6 ชั่วโมง / ในอีกคดีที่ญาติฟ้องร้องรัฐ คดีจบลงที่การประนีประนอมยอมความ\n",
        "กระทรวงกลาโหมจ่ายค่าสินไหมทดแทนรวม 42 ล้านบาทให้กับญาติผู้เสียหาย 79 ราย\n",
        "ปิดหีบและนับคะแนนเสร็จแล้ว ที่หน่วยเลือกตั้งที่ 32 เขต 13 แขวงหัวหมาก เขตบางกะปิ กรุงเทพมหานคร\n",
        "ผู้สมัคร ส.ส. และตัวแทนพรรคการเมืองจากหลายพรรคต่างมาเฝ้าสังเกตการนับคะแนนอย่างใกล้ชิด โดย\n",
        "ฐิติภัสร์ โชติเดชาชัยนันต์ จากพรรคพลังประชารัฐ และพริษฐ์ วัชรสินธุ จากพรรคประชาธิปัตย์ได้คะแนน\n",
        "96 คะแนนเท่ากัน\n",
        "เช้าวันอาทิตย์ที่ 21 เมษายน 2019 ซึ่งเป็นวันอีสเตอร์ วันสำคัญของชาวคริสต์\n",
        "เกิดเหตุระเบิดต่อเนื่องในโบสถ์คริสต์และโรงแรมอย่างน้อย 7 แห่งในประเทศศรีลังกา\n",
        "มีผู้เสียชีวิตแล้วอย่างน้อย 156 คน และบาดเจ็บหลายร้อยคน ยังไม่มีข้อมูลว่าผู้ก่อเหตุมาจากฝ่ายใด\n",
        "จีนกำหนดจัดการประชุมข้อริเริ่มสายแถบและเส้นทางในช่วงปลายสัปดาห์นี้ ปักกิ่งยืนยันว่า\n",
        "อภิมหาโครงการเชื่อมโลกของจีนไม่ใช่เครื่องมือแผ่อิทธิพล แต่ยินดีรับฟังข้อวิจารณ์ เช่น ประเด็นกับดักหนี้สิน\n",
        "และความไม่โปร่งใส รัฐบาลปักกิ่งบอกว่า เวทีประชุม Belt and Road Forum ในช่วงวันที่ 25-27 เมษายน\n",
        "ถือเป็นงานการทูตที่สำคัญที่สุดของจีนในปี 2019\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMF_0xyOIgqs",
        "outputId": "4aad7935-6b2d-4893-aa93-2d326fd68cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 443 ms, sys: 0 ns, total: 443 ms\n",
            "Wall time: 463 ms\n"
          ]
        }
      ],
      "source": [
        "# Speed test: Calling \"longest\" engine through word_tokenize wrapper\n",
        "%time tokens = word_tokenize(speedtest_text, engine=\"longest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCSHylIIgqv",
        "outputId": "1c6e1bc3-defb-4081-f003-1237ab7de705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.3 ms, sys: 0 ns, total: 11.3 ms\n",
            "Wall time: 12.3 ms\n"
          ]
        }
      ],
      "source": [
        "# Speed test: Calling \"newmm\" engine through word_tokenize wrapper\n",
        "%time tokens = word_tokenize(speedtest_text, engine=\"newmm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44T0ELdX-UAS",
        "outputId": "7d9f79d7-8c80-4337-886a-c160eb9e83c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.07 ms, sys: 0 ns, total: 6.07 ms\n",
            "Wall time: 6.09 ms\n"
          ]
        }
      ],
      "source": [
        "# Speed test: Calling \"newmm\" engine through word_tokenize wrapper\n",
        "%time tokens = word_tokenize(speedtest_text, engine=\"newmm-safe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npvyhQPx-UAS",
        "outputId": "a190c42b-c2d1-431a-cfb7-10b09450788a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'attacut'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pythainlp/tokenize/core.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, custom_dict, engine, keep_whitespace, join_broken_num)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"attacut\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mpythainlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattacut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pythainlp/tokenize/attacut.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mattacut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'attacut'"
          ]
        }
      ],
      "source": [
        "#!pip install attacut\n",
        "# Speed test: Calling \"attacut\" engine through word_tokenize wrapper\n",
        "%time tokens = word_tokenize(speedtest_text, engine=\"attacut\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v3nPkeT-UAS"
      },
      "source": [
        "Get all possible segmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFTYqAB1Igq1",
        "outputId": "6a7a8ade-9f46-42f9-afa6-493a69cf0900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['มี|ความ|เป็น|ไป|ได้|อย่าง|ไร|บ้าง|',\n",
              " 'มี|ความ|เป็นไป|ได้|อย่าง|ไร|บ้าง|',\n",
              " 'มี|ความ|เป็นไปได้|อย่าง|ไร|บ้าง|',\n",
              " 'มี|ความเป็นไป|ได้|อย่าง|ไร|บ้าง|',\n",
              " 'มี|ความเป็นไปได้|อย่าง|ไร|บ้าง|',\n",
              " 'มี|ความ|เป็น|ไป|ได้|อย่างไร|บ้าง|',\n",
              " 'มี|ความ|เป็นไป|ได้|อย่างไร|บ้าง|',\n",
              " 'มี|ความ|เป็นไปได้|อย่างไร|บ้าง|',\n",
              " 'มี|ความเป็นไป|ได้|อย่างไร|บ้าง|',\n",
              " 'มี|ความเป็นไปได้|อย่างไร|บ้าง|',\n",
              " 'มี|ความ|เป็น|ไป|ได้|อย่างไรบ้าง|',\n",
              " 'มี|ความ|เป็นไป|ได้|อย่างไรบ้าง|',\n",
              " 'มี|ความ|เป็นไปได้|อย่างไรบ้าง|',\n",
              " 'มี|ความเป็นไป|ได้|อย่างไรบ้าง|',\n",
              " 'มี|ความเป็นไปได้|อย่างไรบ้าง|']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "from pythainlp.tokenize.multi_cut import find_all_segment, mmcut, segment\n",
        "\n",
        "find_all_segment(\"มีความเป็นไปได้อย่างไรบ้าง\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWXiNUoBIgq4"
      },
      "source": [
        "### Subword, syllable, and Thai Character Cluster (TCC)\n",
        "\n",
        "Tokenization can also be done at subword level, either syllable or Thai Character Cluster (TCC).\n",
        "\n",
        "- Syllable segmentation is using [`ssg`](https://github.com/ponrawee/ssg), a CRF syllable segmenter for Thai by Ponrawee Prasertsom.\n",
        "- TCC is smaller than syllable. For information about TCC, see [Character Cluster Based Thai Information Retrieval](https://www.researchgate.net/publication/2853284_Character_Cluster_Based_Thai_Information_Retrieval) (Theeramunkong et al. 2004)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjqQ3Ytu-UAS"
      },
      "source": [
        "#### Subword tokenization\n",
        "Default subword tokenization engine is `tcc`, which will use Thai Character Cluster (TCC) as a subword unit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Z1wdMmdmIgq6",
        "outputId": "c74fa03a-a288-47b8-9c49-7ed42c3545c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ป', 'ระ', 'เท', 'ศ', 'ไท', 'ย']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp import subword_tokenize\n",
        "\n",
        "subword_tokenize(\"ประเทศไทย\")  # default subword unit is TCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opYe64Zo-UAT"
      },
      "source": [
        "#### Syllable tokenization\n",
        "Default syllable tokenization engine is `dict`, which will use `newmm` word tokenization engine with a custom dictionary contains known syllables in Thai language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmLKY37j-UAT",
        "outputId": "766bfa86-f5b6-4371-c172-65647aa4bc5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['อับ',\n",
              " 'ดุล',\n",
              " 'เลาะ',\n",
              " ' ',\n",
              " 'อี',\n",
              " 'ซอ',\n",
              " 'มู',\n",
              " 'ซอ',\n",
              " ' ',\n",
              " 'สมอง',\n",
              " 'บวม',\n",
              " 'รุน',\n",
              " 'แรง']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.tokenize import syllable_tokenize\n",
        "\n",
        "text = \"อับดุลเลาะ อีซอมูซอ สมองบวมรุนแรง\"\n",
        "\n",
        "syllable_tokenize(text)  # default engine is \"dict\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOPTTDBo-UAT"
      },
      "source": [
        "External [`ssg`](https://github.com/ponrawee/ssg) engine call be called. Note that `ssg` engine ommitted whitespaces in the output tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZZg8k8x-UAT",
        "outputId": "61b35fc8-81ae-4bf4-9538-4b42e221524e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['อับ', 'ดุล', 'เลาะ', ' อี', 'ซอ', 'มู', 'ซอ ', 'สมอง', 'บวม', 'รุน', 'แรง']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "syllable_tokenize(text, engine=\"ssg\")  # use \"ssg\" for syllable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfO1WbneIgq9"
      },
      "source": [
        "#### Low-level subword operations\n",
        "\n",
        "These low-level TCC operations can be useful for some pre-processing tasks. Like checking if it's ok to cut a string at a certain point or to find typos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3Gyig20XIgq-",
        "outputId": "da9484b7-4dc4-4159-9b5f-df2771805ac9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ป', 'ระ', 'เท', 'ศ', 'ไท', 'ย']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.tokenize import tcc\n",
        "\n",
        "tcc.segment(\"ประเทศไทย\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cF-zQJU1IgrA",
        "outputId": "fd966eb3-fd8b-46b6-ea61-93427431cdf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1, 3, 5, 6, 8, 9}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tcc.tcc_pos(\"ประเทศไทย\")  # return positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aL2PiPUvIgrE",
        "outputId": "a04d64f4-b174-4337-8859-ecac7e660f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ป-ระ-เท-ศ-ไท-ย-"
          ]
        }
      ],
      "source": [
        "for ch in tcc.tcc(\"ประเทศไทย\"):  # TCC generator\n",
        "    print(ch, end='-')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxvgbdlhIgrG"
      },
      "source": [
        "## Transliteration\n",
        "\n",
        "There are two types of transliteration here: romanization and transliteration.\n",
        "\n",
        "- Romanization will render Thai words in the Latin alphabet using the [Royal Thai General System of Transcription (RTGS)](https://en.wikipedia.org/wiki/Royal_Thai_General_System_of_Transcription).\n",
        "  - Two engines are supported here: a simple `royin` engine (default) and a more accurate `thai2rom` engine.\n",
        "- Transliteration here, in PyThaiNLP context, means the sound representation of a string.\n",
        "  - Two engines are supported here: `ipa` (International Phonetic Alphabet system, using [Epitran](https://github.com/dmort27/epitran)) (default) and `icu` (International Components for Unicode, using [PyICU](https://github.com/ovalhub/pyicu))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ujAsMHwyIgrH",
        "outputId": "4a14e9df-9699-4ede-848b-a280ac0ba5d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'maeo'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.transliterate import romanize\n",
        "\n",
        "romanize(\"แมว\")  # output: 'maeo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHsqWSQl-UAU",
        "outputId": "93ef3ec7-e099-43e8-dc49-b758e373dc10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'phapn'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "romanize(\"ภาพยนตร์\")  # output: 'phapn' (*obviously wrong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "LlDosHqXIgrJ",
        "outputId": "a7a88a3a-a04e-4e90-aef4-c6b357ab04c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Update Corpus...\n",
            "Corpus: thai-g2p\n",
            "- Already up to date.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'m ɛː w ˧'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.transliterate import transliterate\n",
        "\n",
        "transliterate(\"แมว\")  # output: 'mɛːw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oANCw5Bv-UAU",
        "outputId": "e9e6c36e-3ba3-40b4-be96-df4264d4dd22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pʰ aː p̚ ˥˩ . pʰ a ˦˥ . j o n ˧'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transliterate(\"ภาพยนตร์\")  # output: 'pʰaːpjanot'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UwQtF3oIgrM"
      },
      "source": [
        "## Normalization\n",
        "\n",
        "`normalize()` removes zero-width spaces (ZWSP and ZWNJ), duplicated spaces, repeating vowels, and dangling characters. It also reorder vowels and tone marks during the process of removing repeating vowels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WXPq5bqfIgrN",
        "outputId": "42a7a5be-7d7d-4997-811c-424c79ce3169"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.util import normalize\n",
        "\n",
        "normalize(\"เเปลก\") == \"แปลก\"  # เ เ ป ล ก  vs แ ป ล ก"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ9GUqcG-UAW"
      },
      "source": [
        "The string below contains a non-standard order of Thai characters,\n",
        "Sara Aa (following vowel) + Mai Ek (upper tone mark).\n",
        "`normalize()` will reorder it to Mai Ek + Sara Aa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IFPpZMH-UAW",
        "outputId": "732faa6d-edba-4a15-b3a6-da8c07e7357e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'เก่า'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"เกา่\"\n",
        "normalize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEvL8Mlr-UAW"
      },
      "source": [
        "This can be useful for string matching, including tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObVwZ893-UAW",
        "outputId": "a69c4925-207e-470d-866d-edf9a6c31dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenize immediately:\n",
            "['เก็บ', 'วัน', 'น้ี', ' ', 'พรุ่งน้ี', 'ก็', 'เกา', '่']\n",
            "\n",
            "normalize, then tokenize:\n",
            "['เก็บ', 'วันนี้', ' ', 'พรุ่งนี้', 'ก็', 'เก่า']\n"
          ]
        }
      ],
      "source": [
        "from pythainlp import word_tokenize\n",
        "\n",
        "text = \"เก็บวันน้ี พรุ่งน้ีก็เกา่\"\n",
        "\n",
        "print(\"tokenize immediately:\")\n",
        "print(word_tokenize(text))\n",
        "print(\"\\nnormalize, then tokenize:\")\n",
        "print(word_tokenize(normalize(text)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYBshvsB-UAW"
      },
      "source": [
        "The string below contains repeating vowels (multiple Sara A in a row)\n",
        "normalize() will keep only one of them. It can be use to reduce variations in spellings, useful for classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Zx1l6e-UAX",
        "outputId": "29d17192-0277-4e56-813c-133f4ee11385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'เกะ'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normalize(\"เกะะะ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEA8UwtA-UAX"
      },
      "source": [
        "Internally, `normalize()` is just a series of function calls like this:\n",
        "```\n",
        "text = remove_zw(text)\n",
        "text = remove_dup_spaces(text)\n",
        "text = remove_repeat_vowels(text)\n",
        "text = remove_dangling(text)\n",
        "```\n",
        "\n",
        "If you don't like the behavior of default `normalize()`, you can call those functions shown above, also `remove_tonemark()` and `reorder_vowels()`, individually from `pythainlp.util`, to customize your own normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNOFUB8T-UAX"
      },
      "source": [
        "## Digit conversion\n",
        "\n",
        "Thai text sometimes use Thai digits. This can reduce performance for classification and searching. PyThaiNP provides few utility functions to deal with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGvzdhC1-UAX",
        "outputId": "343c9a3c-37cc-42ec-ffe1-24aab6aebf60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ฉุกเฉินที่ยุโรปเรียก ๑๑๒ ๑๑๒'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.util import arabic_digit_to_thai_digit, thai_digit_to_arabic_digit, digit_to_text\n",
        "\n",
        "text = \"ฉุกเฉินที่ยุโรปเรียก 112 ๑๑๒\"\n",
        "\n",
        "arabic_digit_to_thai_digit(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx1S6Xe3-UAX",
        "outputId": "dace6b8a-2d3b-4864-954d-239b6c693b02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ฉุกเฉินที่ยุโรปเรียก 112 112'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thai_digit_to_arabic_digit(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi1_2Lm_-UAX",
        "outputId": "e9459386-e50f-4614-d5ac-9b32999456e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ฉุกเฉินที่ยุโรปเรียก หนึ่งหนึ่งสอง หนึ่งหนึ่งสอง'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digit_to_text(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlDji6ecIgrP"
      },
      "source": [
        "## Soundex\n",
        "\n",
        "\"Soundex is a phonetic algorithm for indexing names by sound.\" ([Wikipedia](https://en.wikipedia.org/wiki/Soundex)). PyThaiNLP provides three kinds of Thai soundex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "I4JyUCRJIgrP",
        "outputId": "6af3c11c-3f9a-4154-b7f2-c899312846dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.soundex import lk82, metasound, udom83\n",
        "\n",
        "# check equivalence\n",
        "print(lk82(\"รถ\") == lk82(\"รด\"))\n",
        "print(udom83(\"วรร\") == udom83(\"วัน\"))\n",
        "print(metasound(\"นพ\") == metasound(\"นภ\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "XTznoTg5IgrS",
        "outputId": "8178cd7b-735d-4ccc-c36b-a8c67ea2ddb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "บูรณะ - lk82: บE400 - udom83: บ930000 - metasound: บ550\n",
            "บูรณการ - lk82: บE419 - udom83: บ931900 - metasound: บ551\n",
            "มัก - lk82: ม1000 - udom83: ม100000 - metasound: ม100\n",
            "มัค - lk82: ม1000 - udom83: ม100000 - metasound: ม100\n",
            "มรรค - lk82: ม1000 - udom83: ม310000 - metasound: ม551\n",
            "ลัก - lk82: ร1000 - udom83: ร100000 - metasound: ล100\n",
            "รัก - lk82: ร1000 - udom83: ร100000 - metasound: ร100\n",
            "รักษ์ - lk82: ร1000 - udom83: ร100000 - metasound: ร100\n",
            " - lk82:  - udom83:  - metasound: \n"
          ]
        }
      ],
      "source": [
        "texts = [\"บูรณะ\", \"บูรณการ\", \"มัก\", \"มัค\", \"มรรค\", \"ลัก\", \"รัก\", \"รักษ์\", \"\"]\n",
        "for text in texts:\n",
        "    print(\n",
        "        \"{} - lk82: {} - udom83: {} - metasound: {}\".format(\n",
        "            text, lk82(text), udom83(text), metasound(text)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spFQD8QsIgrT"
      },
      "source": [
        "## Spellchecking\n",
        "\n",
        "Default spellchecker uses [Peter Norvig's algorithm](http://www.norvig.com/spell-correct.html) together with word frequency from Thai National Corpus (TNC).\n",
        "\n",
        "`spell()` returns a list of all possible spellings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GAz0q6lWIgrU",
        "outputId": "73427202-cdfe-47d9-8925-9596baafd9d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['เหลียม', 'เหลือม']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp import spell\n",
        "\n",
        "spell(\"เหลืยม\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acLxDvoK-UAY"
      },
      "source": [
        "`correct()` returns the most likely spelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "I_fDSYEmIgrV",
        "outputId": "e9b6f2eb-37b6-4189-8cfd-1273caf48f38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'เหลียม'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp import correct\n",
        "\n",
        "correct(\"เหลืยม\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-dOvexUIgrX"
      },
      "source": [
        "## Spellchecking - Custom dictionary and word frequency\n",
        "\n",
        "Custom dictionary can be provided when creating spellchecker.\n",
        "\n",
        "When create a `NorvigSpellChecker` object, you can pass a custom dictionary to `custom_dict` parameter.\n",
        "\n",
        "`custom_dict` can be:\n",
        "- a dictionary (`dict`), with words (`str`) as keys and frequencies (`int`) as values; or\n",
        "- a list, a tuple, or a set of (word, frequency) tuples; or\n",
        "- a list, a tuple, or a set of just words, without their frequencies -- in this case `1` will be assigned to every words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "ixx-8YtfIgrY",
        "outputId": "0dbcf0dc-287e-4c00-f005-c371c81211cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['เหลือม', 'เหลียม']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.spell import NorvigSpellChecker\n",
        "\n",
        "user_dict = [(\"เหลียม\", 50), (\"เหลือม\", 1000), (\"เหลียว\", 1000000)]\n",
        "checker = NorvigSpellChecker(custom_dict=user_dict)\n",
        "\n",
        "checker.spell(\"เหลืยม\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98YzUgOq-UAY"
      },
      "source": [
        "\n",
        "As you can see, our version of `NorvigSpellChecker` gives the edit distance a priority over a word frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p30q8c-f-UAY"
      },
      "source": [
        "You can use word frequencies from Thai National Corpus and Thai Textbook Corpus as well.\n",
        "\n",
        "By default, `NorvigSpellChecker` uses Thai National Corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbzQ-XAN-UAZ",
        "outputId": "6721bebe-c90e-45f9-9129-6da64c23e77d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['เหลือม']"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.corpus import ttc  # Thai Textbook Corpus\n",
        "\n",
        "checker = NorvigSpellChecker(custom_dict=ttc.word_freqs())\n",
        "\n",
        "checker.spell(\"เหลืยม\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOqiCkT5-UAZ",
        "outputId": "0f98c584-2c59-4de0-c32b-9c90d3dda52b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'เหลือม'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checker.correct(\"เหลืยม\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7agUXc7-UAZ"
      },
      "source": [
        "To check the current dictionary of a spellchecker:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "H7TxgdwbIgra",
        "outputId": "3709f50f-3541-41d1-d8c6-7dfd090f3c1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('พิธีเปิด', 18),\n",
              " ('ไส้กรอก', 40),\n",
              " ('ปลิง', 6),\n",
              " ('เต็ง', 13),\n",
              " ('ขอบคุณ', 356),\n",
              " ('ประสาน', 84),\n",
              " ('รำไร', 11),\n",
              " ('ร่วมท้อง', 4),\n",
              " ('ฝักมะขาม', 3)]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(checker.dictionary())[1:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70sKEAlGIgrc"
      },
      "source": [
        "We can also apply conditions and filter function to dictionary when creating spellchecker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gT8G4cFzIgrc",
        "outputId": "ad4dd927-4c65-4164-a6cb-d123a08c9ee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39963"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checker = NorvigSpellChecker()  # use default filter (remove any word with number or non-Thai character)\n",
        "len(checker.dictionary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "w6qI7M92Igre",
        "outputId": "862b3111-e83d-4662-f643-e013e2fc8cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30376"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checker = NorvigSpellChecker(min_freq=5, min_len=2, max_len=15)\n",
        "len(checker.dictionary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cTkFjK8IIgrh",
        "outputId": "7c2e3d09-aa49-4ee0-edfa-49fd4876a968"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66209"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checker_no_filter = NorvigSpellChecker(dict_filter=None)  # use no filter\n",
        "len(checker_no_filter.dictionary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "70ZHCbBQIgrm",
        "outputId": "0dc68873-9e46-4578-bd22-aa3fc1cfb198"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66204"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_yamok(word):\n",
        "    return False if \"ๆ\" in word else True\n",
        "\n",
        "checker_custom_filter = NorvigSpellChecker(dict_filter=remove_yamok)  # use custom filter\n",
        "len(checker_custom_filter.dictionary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hoODyDrIgro"
      },
      "source": [
        "## Part-of-Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "39JixRHsIgro",
        "outputId": "cff28d16-3fa7-4b66-df2e-beef601ec41d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('การ', 'FIXN'), ('เดินทาง', 'VACT')]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.tag import pos_tag, pos_tag_sents\n",
        "\n",
        "pos_tag([\"การ\",\"เดินทาง\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "qrSDelkrIgrq",
        "outputId": "8cce2c89-7599-4020-b5a6-771c0fa0c005"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[('ประกาศสำนักนายกฯ', 'NCMN'),\n",
              "  (' ', 'PUNC'),\n",
              "  ('ให้', 'JSBR'),\n",
              "  (' ', 'PUNC'),\n",
              "  (\"'พล.ท.สรรเสริญ แก้วกำเนิด'\", 'NCMN'),\n",
              "  (' ', 'PUNC'),\n",
              "  ('พ้นจากตำแหน่ง', 'NCMN'),\n",
              "  (' ', 'PUNC'),\n",
              "  ('ผู้ทรงคุณวุฒิพิเศษ', 'NCMN'),\n",
              "  ('กองทัพบก', 'NCMN'),\n",
              "  (' ', 'PUNC'),\n",
              "  ('กระทรวงกลาโหม', 'NCMN')],\n",
              " [('และ', 'JCRG'),\n",
              "  ('แต่งตั้ง', 'VACT'),\n",
              "  ('ให้', 'JSBR'),\n",
              "  ('เป็น', 'VSTA'),\n",
              "  (\"'อธิบดีกรมประชาสัมพันธ์'\", 'NCMN')]]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sents = [[\"ประกาศสำนักนายกฯ\", \" \", \"ให้\",\n",
        "    \" \", \"'พล.ท.สรรเสริญ แก้วกำเนิด'\", \" \", \"พ้นจากตำแหน่ง\",\n",
        "    \" \", \"ผู้ทรงคุณวุฒิพิเศษ\", \"กองทัพบก\", \" \", \"กระทรวงกลาโหม\"],\n",
        "    [\"และ\", \"แต่งตั้ง\", \"ให้\", \"เป็น\", \"'อธิบดีกรมประชาสัมพันธ์'\"]]\n",
        "\n",
        "pos_tag_sents(sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ShDKpHIgrs"
      },
      "source": [
        "## Named-Entity Tagging\n",
        "\n",
        "The tagger use BIO scheme:\n",
        "- B - beginning of entity\n",
        "- I - inside entity\n",
        "- O - outside entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "TVso09S7Igrv",
        "outputId": "f801ac2c-d013-4243-ba0e-b8f88bc69efd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('24', 'NUM', 'B-DATE'),\n",
              " (' ', 'PUNCT', 'I-DATE'),\n",
              " ('มิ.ย.', 'NOUN', 'I-DATE'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('2563', 'NUM', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('ทดสอบระบบ', 'PART', 'O'),\n",
              " ('เวลา', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('6:00', 'NUM', 'B-TIME'),\n",
              " (' ', 'PUNCT', 'I-TIME'),\n",
              " ('น.', 'NOUN', 'I-TIME'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('เดินทาง', 'VERB', 'O'),\n",
              " ('จาก', 'ADP', 'O'),\n",
              " ('ขนส่ง', 'NOUN', 'B-ORGANIZATION'),\n",
              " ('กรุงเทพ', 'NOUN', 'I-ORGANIZATION'),\n",
              " ('ใกล้', 'ADJ', 'O'),\n",
              " ('ถนน', 'NOUN', 'B-LOCATION'),\n",
              " ('กำแพงเพชร', 'NOUN', 'I-LOCATION'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('ไป', 'AUX', 'O'),\n",
              " ('จังหวัด', 'VERB', 'B-LOCATION'),\n",
              " ('กำแพงเพชร', 'NOUN', 'I-LOCATION'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('ตั๋ว', 'NOUN', 'O'),\n",
              " ('ราคา', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('297', 'NUM', 'B-MONEY'),\n",
              " (' ', 'PUNCT', 'I-MONEY'),\n",
              " ('บาท', 'NOUN', 'I-MONEY')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip3 install pythainlp[ner]\n",
        "from pythainlp.tag.thainer import ThaiNameTagger\n",
        "\n",
        "ner = ThaiNameTagger()\n",
        "ner.get_ner(\"24 มิ.ย. 2563 ทดสอบระบบเวลา 6:00 น. เดินทางจากขนส่งกรุงเทพใกล้ถนนกำแพงเพชร ไปจังหวัดกำแพงเพชร ตั๋วราคา 297 บาท\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cF88wN2Igry"
      },
      "source": [
        "## Word Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "GshCfJiBIgrz",
        "outputId": "921340b3-4962-41a5-f550-f463360fb3b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2504981"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pythainlp.word_vector\n",
        "\n",
        "pythainlp.word_vector.similarity(\"คน\", \"มนุษย์\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "qJP9As-_Igr0",
        "outputId": "7f528d29-0edf-4b3c-9c31-138d7b85e83a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ไก่'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pythainlp.word_vector.doesnt_match([\"คน\", \"มนุษย์\", \"บุคคล\", \"เจ้าหน้าที่\", \"ไก่\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS7iwPoiIgr3"
      },
      "source": [
        "## Number Spell Out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "F9PEEvWLIgr4",
        "outputId": "a5782efd-aceb-4c5e-d746-df69ba9cad8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'หนึ่งล้านสองแสนสามหมื่นสี่พันห้าร้อยหกสิบเจ็ดล้านแปดแสนเก้าหมื่นหนึ่งร้อยยี่สิบสามบาทสี่สิบห้าสตางค์'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pythainlp.util import bahttext\n",
        "\n",
        "bahttext(1234567890123.45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBbhS0lS-UAb"
      },
      "source": [
        "`bahttext()` will round the satang part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Y6DLJYOEIgr7",
        "outputId": "eac48468-ab8b-4e67-acad-5d6560a18979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'หนึ่งบาทเก้าสิบเอ็ดสตางค์'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bahttext(1.909)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a1d6ff38954a1cdba4cf61ffa51e42f4658fc35985cd256cd89123cae8466a39"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}