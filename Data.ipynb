{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ri5cVDAWIgp7",
        "MqR6Klwc-UAH",
        "A6gy4MLGIgp9",
        "32vFPqeB-UAJ",
        "B9hosQNsPiw0",
        "_9FW41E0WuWg",
        "IdPMtwGPqLDK"
      ],
      "mount_file_id": "1MsIwZL9GB6DnXojABJF5N2V1zIPRxx3d",
      "authorship_tag": "ABX9TyPh6dS7jplg18adr8WplDEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thippawan72/Thesis/blob/main/Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VhBw2AmK4sGQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "jEVHz8jCFOnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install moviepy"
      ],
      "metadata": {
        "id": "m23WOv5CmOHg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f05dnQR43St",
        "outputId": "e9e1cecd-6c18-4c6e-8cfa-941cc1626756"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip"
      ],
      "metadata": {
        "id": "e4GtPYPDnl3F"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the input and output directories\n",
        "formal_input_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ภาษาระดับกึ่งทางการ/วิดีโอทั้งหมดกึ่งทางการ'\n",
        "formal_output_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ภาษาระดับกึ่งทางการ/Video_กึ่งทางการ'\n",
        "\n",
        "casual_input_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ระดับการใช้ในชีวิตประจำวัน /วิดีโอทั้งหมดการใช้ชีวิตประจำวัน'\n",
        "casual_output_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ระดับการใช้ในชีวิตประจำวัน /Video_การใช้ชีวิตประจำวัน'"
      ],
      "metadata": {
        "id": "dxA0Dw77n1ZC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert GIF to MP4\n",
        "def convert_gif_to_mp4(input_gif, output_mp4):\n",
        "    try:\n",
        "        # Load the GIF file\n",
        "        clip = VideoFileClip(input_gif)\n",
        "\n",
        "        # Write the video to MP4 format\n",
        "        clip.write_videofile(output_mp4, codec='libx264')\n",
        "        print(f\"Successfully converted {input_gif} to {output_mp4}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to convert {input_gif}: {e}\" )"
      ],
      "metadata": {
        "id": "1OSXPthpm8r3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess all GIFs in a directory\n",
        "#def preprocess_videos(input_dir, output_dir):\n",
        "#   if not os.path.exists(output_dir):\n",
        " #       os.makedirs(output_dir)\n",
        "\n",
        "#    # Loop over all files in the input directory\n",
        " #   for filename in os.listdir(input_dir):\n",
        "  #      if filename.endswith(\".gif\"):\n",
        "   #         input_path = os.path.join(input_dir, filename)\n",
        "    #        output_filename = filename.replace(\".gif\", \".mp4\")\n",
        "     #       output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "            # Convert GIF to MP4\n",
        "      #      convert_gif_to_mp4(input_path, output_path)\n",
        "\n",
        "# Start preprocessing the GIFs\n",
        "#preprocess_videos(formal_input_directory, formal_output_directory)"
      ],
      "metadata": {
        "id": "HVpZAsKSna4v"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5cVDAWIgp7"
      },
      "source": [
        "# PyThaiNLP Get Started\n",
        "\n",
        "Code examples for basic functions in PyThaiNLP https://github.com/PyThaiNLP/pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3HsfhZlwInqs"
      },
      "outputs": [],
      "source": [
        "# # pip install required modules\n",
        "# # uncomment if running from colab\n",
        "# # see list of modules in `requirements` and `extras`\n",
        "# # in https://github.com/PyThaiNLP/pythainlp/blob/dev/setup.py\n",
        "\n",
        "#!pip install pythainlp\n",
        "#!pip install epitran"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install required modules"
      ],
      "metadata": {
        "id": "BaT_g8fV-7xp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp\n",
        "!pip install epitran"
      ],
      "metadata": {
        "id": "E32blbWe_CLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7619c64c-ab38-484e-b90e-ae224971a9cc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n",
            "Requirement already satisfied: epitran in /usr/local/lib/python3.10/dist-packages (1.25.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from epitran) (71.0.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from epitran) (2024.9.11)\n",
            "Requirement already satisfied: panphon>=0.20 in /usr/local/lib/python3.10/dist-packages (from epitran) (0.21.2)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.10/dist-packages (from epitran) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from epitran) (2.32.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from epitran) (0.4.1)\n",
            "Requirement already satisfied: g2pk in /usr/local/lib/python3.10/dist-packages (from epitran) (0.9.4)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.14.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.26.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.8.1)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (3.8.1)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (0.6.0)\n",
            "Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (1.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2024.8.30)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy->g2pk->epitran) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy->g2pk->epitran) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (4.66.5)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.10/dist-packages (from python-mecab-ko->g2pk->epitran) (2.1.1.post2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy->g2pk->epitran) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqR6Klwc-UAH"
      },
      "source": [
        "## Import PyThaiNLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp"
      ],
      "metadata": {
        "id": "9IhnIXQJ-oDg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "R7CkITTf-UAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "399f73e8-5d24-40a5-82db-8716ceeeec09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "import pythainlp\n",
        "\n",
        "pythainlp.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6gy4MLGIgp9"
      },
      "source": [
        "## Thai Characters\n",
        "\n",
        "PyThaiNLP provides some ready-to-use Thai character set (e.g. Thai consonants, vowels, tonemarks, symbols) as a string for convenience. There are also few utility functions to test if a string is in Thai or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GAvoeZg3Igp-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "283cf319-7f24-4705-dbcb-78c32ec4d459"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮฤฦะัาำิีึืุูเแโใไๅํ็่้๊๋ฯฺๆ์ํ๎๏๚๛๐๑๒๓๔๕๖๗๘๙฿'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "pythainlp.thai_characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "TFPtK_FL-UAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50d1478-354e-4649-eb03-38253fceb2cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "len(pythainlp.thai_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "uPwx53A6IgqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2483895e-cb76-4bef-9ff4-9d95f606d086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "pythainlp.thai_consonants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "e5-lZjsd-UAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773d28a3-ff74-4ee1-fff5-eb160c841ae1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "len(pythainlp.thai_consonants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5UA7Hwy_IgqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbe1717-4a5e-4b3f-aa16-aa65ba0f652e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "\"๔\" in pythainlp.thai_digits  # check if Thai digit \"4\" is in the character set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vFPqeB-UAJ"
      },
      "source": [
        "## Checking if a string contains Thai character or not, or how many"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "t3NvXqYFIgqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2097f777-e821-478f-b4b0-b53326c5ade7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import pythainlp.util\n",
        "\n",
        "pythainlp.util.isthai(\"ก\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sRzSQjugIgqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a404b4d-9a04-4e9d-d33f-0ff94fdd1536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DP5yfJebIgqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffa4ac7-dd6d-4bde-fb30-d3101b33010e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\", ignore_chars=\".()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ภาษาระดับกึ่งทางการ\n"
      ],
      "metadata": {
        "id": "FxkLG5Av-BoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import sent_tokenize\n",
        "from pythainlp.corpus.common import thai_words\n",
        "from pythainlp import Tokenizer\n",
        "from pythainlp.tokenize import subword_tokenize\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.tag import pos_tag\n",
        "from pythainlp.corpus import thai_stopwords"
      ],
      "metadata": {
        "id": "WDZtB1BND8m_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Category มหาวิทยาลัย\n",
        "```\n",
        "1.สวัสดีค่ะอาจารย์ที่ปรึกษา\n",
        "2.นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\n",
        "3.ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\n",
        "4.นักศึกษาต้องการโน็ตบุ๊คในการทำงานหรือไม่\n",
        "5.ผมขอสอบถามเกี่ยวกับการเตรียมพร้อมในการสอบวิชาอาจาร์ยหน่อยครับ\n",
        "6.นักศึกษาควรเตรียมพร้อมสำหรับการสอบในหนึ่งสัปดาห์หน้า\n",
        "7.นักศึกษาสามารถใช้อินเตอร์เน็ตในการเรียนได้\n",
        "8.คุณคือหัวหน้า เขียนชื่อ-นามสกุลนักศึกษาที่ลาออกมาให้อาจารย์\n",
        "9.นักศึกษาหมดกำลังใจในการทำงาน\n",
        "10.อาจาร์ยที่ปรึกษาอนุมัติให้ทำงานตามข้อหัวนี้\n",
        "```"
      ],
      "metadata": {
        "id": "PN8cnBkOV-Ul"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VFPOHyZIgqh"
      },
      "source": [
        "###Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5P_YygrIgqm"
      },
      "source": [
        "Other algorithm can be chosen. We can also create a tokenizer with a custom dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXUxXlTIgqo"
      },
      "source": [
        "Default word tokenizer use a word list from `pythainlp.corpus.common.thai_words()`.\n",
        "We can get that list, add/remove words, and create new tokenizer from the modified list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SklPJ-DbIgqi"
      },
      "source": [
        "### Word\n",
        "Default word tokenizer (\"newmm\") use maximum matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"newmm (custom dictionary):\", custom_tokenizer.word_tokenize(text1))"
      ],
      "metadata": {
        "id": "IKvEDM3U-YGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce507139-ff67-46de-c8fc-2981165ab742"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "newmm (custom dictionary): ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "JEbY-MGCIgqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce951d3f-fdf1-4e16-85e1-4a6e7875f45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำแนะนำ', 'ได้', 'กับ', 'อาจารย์ที่ปรึกษา']\n",
            "custom dictionary : ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำ', 'แนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ],
      "source": [
        "text2 = \"นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text2))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.discard(\"คำแนะนำ\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text3))"
      ],
      "metadata": {
        "id": "Dc9PVhShepRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc06178-bc12-4bf5-f465-4a0fff3e4217"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำแนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text4 = \"นักศึกษาต้องการโน็ตบุ๊คในการทำงานหรือไม่\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text4))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"โน็ตบุ๊ค\")\n",
        "words.discard(\"การทำงาน\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text4))"
      ],
      "metadata": {
        "id": "D7EBXclqYM6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6090ff69-1d7a-4135-ffbf-26730285bf85"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'ต้องการ', 'โน', '็ต', 'บุ๊ค', 'ใน', 'การทำงาน', 'หรือไม่']\n",
            "custom dictionary: ['นักศึกษา', 'ต้องการ', 'โน็ตบุ๊ค', 'ใน', 'การ', 'ทำงาน', 'หรือไม่']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text5 = \"ผมขอสอบถามเกี่ยวกับการสอบวิชาอาจาร์ยหน่อยครับ\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text5))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจาร์ย\")\n",
        "words.discard(\"สอบถาม\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYqQnvnZ1V7P",
        "outputId": "fe4b19f5-dc55-4dc0-a037-62b4f43da491"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ผม', 'ขอ', 'สอบถาม', 'เกี่ยวกับ', 'การ', 'สอบ', 'วิชา', 'อา', 'จาร์ย', 'หน่อย', 'ครับ']\n",
            "custom dictionary: ['ผม', 'ขอ', 'สอบ', 'ถาม', 'เกี่ยวกับ', 'การ', 'สอบ', 'วิชา', 'อาจาร์ย', 'หน่อย', 'ครับ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text6 = \"นักศึกษาควรเตรียมพร้อมสำหรับการสอบในหนึ่งสัปดาห์หน้า\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text6))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"หนึ่งสัปดาห์หน้า\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14EMK8Db1WDU",
        "outputId": "db499996-edc5-4515-8a68-4f130e329ed2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'ควร', 'เตรียมพร้อม', 'สำหรับ', 'การ', 'สอบ', 'ใน', 'หนึ่ง', 'สัปดาห์', 'หน้า']\n",
            "custom dictionary: ['นักศึกษา', 'ควร', 'เตรียมพร้อม', 'สำหรับ', 'การ', 'สอบ', 'ใน', 'หนึ่งสัปดาห์หน้า']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text7 = \"นักศึกษาสามารถใช้อินเตอร์เน็ตในการเรียนได้\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text7))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"การเรียน\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqHgG3eo1i5C",
        "outputId": "efb80388-1894-48af-d22d-a27c08b311a4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'สามารถ', 'ใช้', 'อินเตอร์เน็ต', 'ใน', 'การเรียน', 'ได้']\n",
            "custom dictionary: ['นักศึกษา', 'สามารถ', 'ใช้', 'อินเตอร์เน็ต', 'ใน', 'การ', 'เรียน', 'ได้']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text8 = \"คุณคือหัวหน้าใช่มั้ย เขียนชื่อ-นามสกุลนักศึกษาที่ลาออกมาให้อาจารย์\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text8))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"ชื่อ-นามสกุล\")\n",
        "words.add(\"ลาออก\")\n",
        "words.discard(\"ออกมา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzV1lNl2RvQw",
        "outputId": "d7dabad6-9737-428d-cf50-0369ee00c548"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['คุณ', 'คือ', 'หัวหน้า', 'ใช่', 'มั้ย', ' ', 'เขียน', 'ชื่อ', '-', 'นามสกุล', 'นักศึกษา', 'ที่', 'ลา', 'ออกมา', 'ให้', 'อาจารย์']\n",
            "custom dictionary: ['คุณ', 'คือ', 'หัวหน้า', 'ใช่', 'มั้ย', ' ', 'เขียน', 'ชื่อ-นามสกุล', 'นักศึกษา', 'ที่', 'ลาออก', 'มา', 'ให้', 'อาจารย์']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text9 = \"นักศึกษาหมดกำลังใจในการทำงาน\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text9))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"การทำงาน\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPY9kXuJZGCM",
        "outputId": "d3b95adb-3e8a-4d10-f378-186f45cd589f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'หมดกำลังใจ', 'ใน', 'การทำงาน']\n",
            "custom dictionary: ['นักศึกษา', 'หมดกำลังใจ', 'ใน', 'การ', 'ทำงาน']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text10 = \"อาจารย์ที่ปรึกษาอนุมัติให้ทำงานตามข้อหัวนี้\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text10))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"ข้อหัว\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.discard(\"ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8W4aQntZGiM",
        "outputId": "9b5133ea-1cb7-455e-d87b-ad04d893b889"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['อาจารย์ที่ปรึกษา', 'อนุมัติ', 'ให้', 'ทำงาน', 'ตาม', 'ข้อ', 'หัว', 'นี้']\n",
            "custom dictionary: ['อาจารย์', 'ที่', 'ปรึกษา', 'อนุมัติ', 'ให้', 'ทำงาน', 'ตาม', 'ข้อหัว', 'นี้']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.tokenize import word_detokenize\n",
        "print(word_detokenize(['โน็', 'ตบุ๊ค']))"
      ],
      "metadata": {
        "id": "p7Q3qoEPYegy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7517b95-075c-4004-f8ec-9fa06105826d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "โน็ตบุ๊ค\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Word Removal\n"
      ],
      "metadata": {
        "id": "lRuhGEg-O53A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords)"
      ],
      "metadata": {
        "id": "JLpuvsxOO53A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a62e709-bc33-4ae2-d45d-a03ef4590385"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'จัง', 'บางๆ', 'เรียก', 'คราวละ', 'ก็แค่', 'ช่วงหน้า', 'ถึงแม้ว่า', 'ยก', 'ถูกๆ', 'ล้วน', 'ภายนอก', 'มีแต่', 'ปิด', 'อย่างๆ', 'ดั่งกับว่า', 'หาใช่', 'น้อยๆ', 'เชื่อ', 'ยิ่งจน', 'อย่างไรก็', 'ภายใต้', 'แค่เพียง', 'ทว่า', 'เช่นดัง', 'จ๋า', 'คิด', 'ทั้งสิ้น', 'ใกล้ๆ', 'แก่', 'เราๆ', 'เท่าใด', 'คงอยู่', 'แต่ก่อน', 'หากว่า', 'เผื่อที่', 'เสียจนถึง', 'ทีไร', 'จด', 'เชื่อว่า', 'ใหญ่ๆ', 'เฉย', 'หลัง', 'พบว่า', 'ได้รับ', 'ขาด', 'นับแต่ที่', 'เรื่อย', 'ถือว่า', 'เป็นด้วย', 'เป็นเพราะ', 'จนทั่ว', 'ระยะๆ', 'จัดตั้ง', 'ตรง', 'เหล่า', 'แต่ทว่า', 'ตนเอง', 'ที่ว่า', 'ตลอดวัน', 'ก่อน', 'พร้อมที่', 'ระยะ', 'ค่อนมาทาง', 'เช่น', 'ดั่ง', 'นั่นเอง', 'ไม่ว่า', 'เท่าไร', 'น่า', 'เถิด', 'หรือเปล่า', 'หาความ', 'ตรงๆ', 'นัก', 'เผื่อว่า', 'ส่วนที่', 'ภายหลัง', 'ไป่', 'ยาก', 'ฯ', 'เป็นที', 'มิได้', 'อย่างนี้', 'นั่นไง', 'ที', 'ทั่ว', 'แต่ต้อง', 'ยังไง', 'หนึ่ง', 'ใหม่', 'เท่าไหร่', 'รึว่า', 'อันที่จริง', 'อย่างไร', 'รึ', 'เน้น', 'เพื่อที่จะ', 'มา', 'แต่เดิม', 'ตลอดทั้ง', 'หน่อย', 'ยืนยง', 'เช่นดังก่อน', 'ปรับ', 'พวกเขา', 'เห็น', 'ทั้งคน', 'มุ่งเน้น', 'วันไหน', 'เช่นเคย', 'กำลังจะ', 'เปลี่ยน', 'ล่าสุด', 'อันที่', 'เท่ากัน', 'เป็น', 'จะได้', 'ด้วยว่า', 'กันนะ', 'ถ้าจะ', 'เพียงใด', 'จัดงาน', 'การ', 'ทันที', 'ระหว่าง', 'มี', 'เพิ่มเติม', 'เกือบ', 'นอกจากนั้น', 'ตนฯ', 'ซึ่งได้แก่', 'นับจากนี้', 'พวกกัน', 'ได้', 'กันไหม', 'เฉพาะ', 'ไม่ใช่', 'ทันใดนั้น', 'เคยๆ', 'พอกัน', 'แห่ง', 'ยังโง้น', 'ทุกสิ่ง', 'จนบัดนี้', 'อาจเป็น', 'คราวๆ', 'ที่', 'เดียว', 'ฯล', 'พวกนี้', 'เหลือเกิน', 'ด้วย', 'คล้าย', 'กระนั้น', 'เท่าที่', 'คราวหนึ่ง', 'เล็ก', 'คราวใด', 'ครับ', 'เรียบ', 'ที่สุด', 'ทั้งที่', 'ช้าๆ', 'แม้', 'ซึ่งก็คือ', 'ตลอดระยะเวลา', 'บ่อยกว่า', 'ข้างต้น', 'ยืนนาน', 'เมื่อคืน', 'ถ้าหาก', 'ทุกชิ้น', 'สู่', 'ทั้งเป็น', 'อีก', 'เพียงแค่', 'ดั่งเก่า', 'เมื่อเย็น', 'ผู้', 'เกินๆ', 'จวบจน', 'ทุกๆ', 'จวน', 'สั้นๆ', 'ทุกแห่ง', 'จัดแจง', 'ทุกตัว', 'มิใช่', 'แค่นั้น', 'พวกมึง', 'ใหญ่โต', 'อย่างไรก็ได้', 'ที่นั้น', 'พอที่', 'นับแต่นั้น', 'พร้อมด้วย', 'จำพวก', 'กำลัง', 'ประมาณ', 'สมัยโน้น', 'คราไหน', 'เช่นดังเก่า', 'ไฉน', 'เป็นเพื่อ', 'หากแม้น', 'เหล่านั้น', 'ทุกครา', 'แก', 'กล่าว', 'ทำๆ', 'รวมกัน', 'ทีละ', 'ได้ที่', 'เสียยิ่ง', 'ความ', 'ส่ง', 'ๆ', 'ยังงั้น', 'ยาวนาน', 'นานๆ', 'กระผม', 'อันไหน', 'ยอม', 'ร่วมกัน', 'ต่อกัน', 'จนตลอด', 'บอก', 'บ่อย', 'เข้า', 'นอกเหนือ', 'ขั้น', 'เล็กๆ', 'เมื่อครั้ง', 'พวกฉัน', 'กระทั่ง', 'แห่งโน้น', 'ถึงจะ', 'เป็นเพียงว่า', 'พร้อมทั้ง', 'อาจจะ', 'นี่นา', 'คราวนั้น', 'ขณะนั้น', 'กู', 'แห่งใด', 'เช่นดังที่', 'ทุกทาง', 'ไม่', 'เป็นอันๆ', 'เมื่อไร', 'ซึ่งก็', 'บอกว่า', 'ค่อย', 'แค่', 'เพียงเพื่อ', 'ค่อยๆ', 'นับตั้งแต่', 'ที่ๆ', 'ด้วยประการฉะนี้', 'ช่วง', 'ที่แท้จริง', 'มั้ย', 'ส่วน', 'ล้วนแต่', 'นิดๆ', 'จวนจะ', 'ปฏิบัติ', 'มั้ยล่ะ', 'นี่แหละ', 'บน', 'ที่ซึ่ง', 'เมื่อคราวที่', 'พวกนั้น', 'ด้วยเหมือนกัน', 'เอง', 'จึงจะ', 'ยังแต่', 'สิ่งใด', 'เร็วๆ', 'คงจะ', 'ถึงบัดนี้', 'ตน', 'ถือ', 'เป็นต้นมา', 'เสียยิ่งนัก', 'เพราะ', 'จนกว่า', 'หมดกัน', 'พอจะ', 'ส่วนด้อย', 'โตๆ', 'ขณะนี้', 'นำพา', 'ภาค', 'ครั้งครา', 'ตั้ง', 'พวกกู', 'ใต้', 'เธอ', 'พึง', 'ยังคง', 'ยิ่งนัก', 'นํา', 'ด้วยเหตุที่', 'บางที', 'รับรอง', 'เมื่อเช้า', 'ฉะนี้', 'แสดงว่า', 'รวดเร็ว', 'มั้ยเนี่ย', 'คือ', 'ทรง', 'เป็นอันว่า', 'เหตุนั้น', 'ตาม', 'อื่นๆ', 'กันดีกว่า', 'คราวก่อน', 'ฉัน', 'พวกมัน', 'ถึง', 'เกี่ยวๆ', 'ดั่งเคย', 'ใหม่ๆ', 'เช่นที่เคย', 'นอกจากนี้', 'ครั้ง', 'เริ่ม', 'ทุกครั้ง', 'อันละ', 'เป็นที่สุด', 'แยะ', 'เชื่อมั่น', 'ทาง', 'ขณะใดๆ', 'สูง', 'รวด', 'ใคร', 'ตลอดทั่วทั้ง', 'คุณ', 'เอ็ง', 'พอเพียง', 'เดียวกัน', 'ทีใด', 'พอ', 'คราหนึ่ง', 'เพิ่ง', 'เรา', 'ดั่งกับ', 'พวกที่', 'ในช่วง', 'จนกระทั่ง', 'จรด', 'ทั้ง', 'จ้ะ', 'น้อย', 'เช่นนี้', 'ทันทีทันใด', 'บ่อยๆ', 'ใดๆ', 'คล้ายกัน', 'อดีต', 'จำเป็น', 'ขวาง', 'ด้วยเช่นกัน', 'จัดให้', 'จวบกับ', 'ช่วงระหว่าง', 'นับแต่', 'นอก', 'คิดว่า', 'บางกว่า', 'ภายภาคหน้า', 'พอสม', 'เป็นต้น', 'ตามแต่', 'ข้าง', 'เช่นดังว่า', 'แค่ว่า', 'ด้วยเหตุนี้', 'ประสบ', 'ทุกคราว', 'นำ', 'นี้แหล่', 'ยัง', 'ครบครัน', 'ทุกอัน', 'มักจะ', 'เช่นเมื่อ', 'สมัยนั้น', 'ภายหน้า', 'เพียงไหน', 'จะ', 'มัก', 'เมื่อคราว', 'แค่ไหน', 'ย่อม', 'นับจากนั้น', 'เพื่อ', 'ย่อย', 'ยอมรับ', 'เมื่อวันวาน', 'เป็นต้นไป', 'ใกล้', 'ที่ไหน', 'อย่างละ', 'เกี่ยวกัน', 'ไหนๆ', 'เป็นเพราะว่า', 'เสียนั่น', 'พอแล้ว', 'อย่างเช่น', 'เปิด', 'พวกเธอ', 'เฉยๆ', 'แต่อย่างใด', 'ราย', 'ยังจะ', 'จริงจัง', 'หากแม้นว่า', 'ยังงี้', '\\ufeffๆ', 'ทุกที่', 'แต่ละ', 'ประการ', 'แสดง', 'ตลอดจน', 'สุดๆ', 'จู่ๆ', 'พูด', 'เล่าว่า', 'เนี่ยเอง', 'ครา', 'เหล่านี้', 'ทั้งหมด', 'ไกล', 'ณ', 'แต่นั้น', 'ทำไร', 'หนอ', 'ทำให้', 'ประการใด', 'หมดสิ้น', 'ครบ', 'ขณะใด', 'ครั้งๆ', 'อาจ', 'ถึงแก่', 'หากแม้', 'ช่วงนี้', 'นี้', 'เพิ่งจะ', 'รวมถึง', 'ด้วยเหตุนั้น', 'แห่งนั้น', 'เช่นกัน', 'เกิน', 'เคย', 'คะ', 'อนึ่ง', 'คราวที่', 'มั้ยนั่น', 'ประกอบ', 'ไง', 'แล้วเสร็จ', 'ในระหว่าง', 'นับ', 'กัน', 'ทั้งนี้', 'หรือไม่', 'ออก', 'เสร็จสิ้น', 'จาก', 'ทั้งตัว', 'สมัย', 'ฯลฯ', 'แต่เพียง', 'ตลอดถึง', 'เพียงพอ', 'นาย', 'ยิ่งกว่า', 'เมื่อครั้งก่อน', 'ซะจนถึง', 'ขณะเดียวกัน', 'มองว่า', 'เพียงแต่', 'เช่นก่อน', 'กระทำ', 'ทั้งที', 'ได้แต่', 'ทีเถอะ', 'น่าจะ', 'พอควร', 'จัดการ', 'ให้ไป', 'ให้มา', 'ใช้', 'คล้ายกันกับ', 'ขวางๆ', 'รวม', 'หารือ', 'สิ้นกาลนาน', 'ละ', 'จริง', 'เพราะฉะนั้น', 'เกือบจะ', 'ทั้งปวง', 'ครั้งนี้', 'สุด', 'จับ', 'ส่วนน้อย', 'ใช่', 'กล่าวคือ', 'ทุก', 'ด้วยเพราะ', 'หรือไง', 'เนื่องจาก', 'โดย', 'นี่เอง', 'มอง', 'วันนั้น', 'จนแม้', 'ทำไม', 'เสีย', 'พวกโน้น', 'ซะจน', 'แล้ว', 'บางครั้ง', 'ตลอดทั่วถึง', 'ประการหนึ่ง', 'อันเนื่องมาจาก', 'อย่างนั้น', 'ไม่ค่อย', 'เช่นใด', 'ผ่านๆ', 'แรก', 'ก่อนหน้า', 'จนขณะนี้', 'มุ่ง', 'เหตุนี้', 'จัดทำ', 'มันๆ', 'จวบ', 'เมื่อคราวก่อน', 'เกือบๆ', 'ดังกับ', 'เยอะๆ', 'เป็นๆ', 'คล้ายกับว่า', 'เป็นที่', 'เผื่อ', 'เหตุ', 'ช่วงก่อน', 'ส่วนใหญ่', 'กันเถอะ', 'ที่ได้', 'นี่แน่ะ', 'เขียน', 'สิ่งนี้', 'ถึงแม้จะ', 'สูงๆ', 'บางคราว', 'เพิ่ม', 'หลาย', 'ภายใน', 'เผื่อจะ', 'สิ่ง', 'ให้ดี', 'ส่วนใด', 'คราวหน้า', 'ตลอดทั่ว', 'ก็จะ', 'อย่างเดียว', 'ครั้งไหน', 'ใน', 'พวกท่าน', 'แยะๆ', 'สูงสุด', 'อยาก', 'คุณๆ', 'หรือไร', 'นิดหน่อย', 'เลย', 'ครั้งหลังสุด', 'คง', 'ไร', 'ถึงอย่างไร', 'ช่วงแรก', 'นั่น', 'แหละ', 'อยู่', 'บัดนั้น', 'ข้างบน', 'ครัน', 'ที่ละ', 'อื่น', 'ตามด้วย', 'ดัง', 'อันๆ', 'แม้นว่า', 'กลุ่ม', 'อันที่จะ', 'ครั้งหนึ่ง', 'ต่อ', 'ช้านาน', 'เสียด้วย', 'ในที่', 'ฝ่าย', 'พอตัว', 'ถึงเมื่อ', 'แห่งนี้', 'เพื่อว่า', 'และ', 'ตลอดมา', 'ทุกหน', 'ล้วนจน', 'รวมๆ', 'ช่วย', 'แม้ว่า', 'ก่อนหน้านี้', 'ก็', 'อะไร', 'บอกแล้ว', 'เป็นการ', 'ไกลๆ', 'เสียนี่', 'อย่างมาก', 'ตลอดปี', 'จริงๆจังๆ', 'ผ่าน', 'บัดเดี๋ยวนี้', 'ในเมื่อ', 'ไหน', 'เห็นจะ', 'เพื่อที่', 'ยิ่งจะ', 'แต่ไร', 'คำ', 'ทั้งนั้นเพราะ', 'เยอะแยะ', 'พวก', 'ช่วงต่อไป', 'หน', 'ทุกวันนี้', 'มั๊ย', 'พร้อมกัน', 'ค่อนข้าง', 'แล้วแต่', 'ตลอดกาล', 'ทําให้', 'เมื่อก่อน', 'สั้น', 'ด้วยที่', 'ยิ่งเมื่อ', 'ทั้งหลาย', 'เสร็จกัน', 'นอกจากที่', 'เก็บ', 'ประการฉะนี้', 'ขอ', 'จ้า', 'เชื่อถือ', 'ครานั้น', 'แต่ก็', 'หาก', 'ถูก', 'ไป', 'หนอย', 'บางแห่ง', 'ให้แด่', 'หรือยัง', 'ใหญ่', 'เป็นอัน', 'ดังกับว่า', 'มากกว่า', 'พอดี', 'ตั้งแต่', 'รือว่า', 'บ่อยครั้ง', 'ส่วนดี', 'ใช่ไหม', 'แต่จะ', 'ยิ่งแล้ว', 'เกี่ยวกับ', 'พร้อมเพียง', 'เมื่อ', 'ช่วงท้าย', 'น่ะ', 'ชาว', 'ครั้งหลัง', 'อย่างหนึ่ง', 'ไม่ค่อยจะ', 'เรื่อยๆ', 'ข้าฯ', 'เยอะ', 'ทุกคน', 'เสมือนว่า', 'เมื่อไหร่', 'จัด', 'ก็ตามแต่', 'แต่เมื่อ', 'เช่นนั้นเอง', 'เท่านั้น', 'จนเมื่อ', 'ควร', 'สิ้น', 'จนแม้น', 'นั้นไว', 'ด้าน', 'เถอะ', 'ช่วงๆ', 'คราวไหน', 'วันใด', 'จัดหา', 'ข้างล่าง', 'รวมด้วย', 'แต่ว่า', 'เมื่อใด', 'เล็กน้อย', 'สมัยนี้', 'ค่อนข้างจะ', 'อาจเป็นด้วย', 'นี้เอง', 'แล้วกัน', 'จรดกับ', 'เป็นอันมาก', 'นั่นแหละ', 'โต', 'เอา', 'แม้แต่', 'มาก', 'ครั้งก่อน', 'ยิ่ง', 'ปัจจุบัน', 'ยืนยัน', 'นู้น', 'ข้างๆ', 'ที่ใด', 'อย่างไรเสีย', 'ที่แท้', 'นั้นๆ', 'ที่จริง', 'สิ่งไหน', 'บัดนี้', 'เช่นที่', 'จวนเจียน', 'เนี่ย', 'แต่', 'สมัยก่อน', 'เช่นเดียวกับ', 'ง่ายๆ', 'ทั้งนั้นด้วย', 'ก็ได้', 'คล้ายกับ', 'พวกนู้น', 'ส่วนมาก', 'ทุกเมื่อ', 'พา', 'ให้แก่', 'ได้แก่', 'ได้มา', 'ขึ้น', 'ข้า', 'ถ้า', 'เพียงไร', 'นั้น', 'ดังกล่าว', 'ว่า', 'คราวนี้', 'หลังจาก', 'น้อยกว่า', 'ใครๆ', 'ทีๆ', 'เท่า', 'ก็ดี', 'ครั้งกระนั้น', 'จึง', 'เท่ากับ', 'ให้', 'จากนี้', 'สามารถ', 'เปิดเผย', 'ด้วยกัน', 'ตลอดศก', 'จ๊ะ', 'ยืนยาว', 'เต็มๆ', 'ก็แล้วแต่', 'อย่างยิ่ง', 'เพียงเพราะ', 'เสมือนกับ', 'ครั้งที่', 'เช่นไร', 'กลุ่มก้อน', 'เป็นแต่', 'เป็นดัง', 'แท้จริง', 'ทีเดียว', 'คราที่', 'อย่างใด', 'ด้วยเหตุเพราะ', 'ค่อยไปทาง', 'นี่ไง', 'ต่างๆ', 'อย่าง', 'ทุกวัน', 'ลง', 'ช่วงถัดไป', 'มิ', 'ตลอดไป', 'ภาย', 'ขณะหนึ่ง', 'พอที', 'เต็มไปหมด', 'รับ', 'เห็นว่า', 'คราวหลัง', 'ต่างหาก', 'เสียนั่นเอง', 'ต่าง', 'เท่านี้', 'ทัน', 'สูงส่ง', 'ตลอดกาลนาน', 'ครั้งคราว', 'มิฉะนั้น', 'แก้ไข', 'นาน', 'นั่นเป็น', 'กลุ่มๆ', 'ง่าย', 'เป็นแต่เพียง', 'บาง', 'เสียแล้ว', 'สำคัญ', 'ตลอดเวลา', 'อย่างที่', 'เพราะว่า', 'เพียง', 'ดังเคย', 'ครบถ้วน', 'สืบเนื่อง', 'กันดีไหม', 'เสียจน', 'บางที่', 'ยิ่งขึ้นไป', 'แท้', 'ตลอด', 'หรือ', 'วันนี้', 'พบ', 'ทํา', 'สูงกว่า', 'อัน', 'แห่งไหน', 'ค่อน', 'เสร็จ', 'ขณะ', 'กับ', 'คราว', 'มึง', 'ถึงแม้', 'ถึงบัดนั้น', 'อย่างไหน', 'กำหนด', 'มัน', 'ก่อนๆ', 'ใคร่จะ', 'ส่วนนั้น', 'ช่วงที่', 'จง', 'แค่จะ', 'นอกเหนือจาก', 'บัดดล', 'ขณะที่', 'ดังเก่า', 'ร่วมด้วย', 'เสียจนกระทั่ง', 'ภายภาค', 'ปรากฏ', 'กลับ', 'กันและกัน', 'จากนี้ไป', 'เกี่ยวข้อง', 'ของ', 'พอเหมาะ', 'ถูกต้อง', 'ใคร่', 'จน', 'พร้อมกับ', 'รือ', 'นะ', 'แต่ที่', 'อันจะ', 'เขา', 'เมื่อนี้', 'เป็นอาทิ', 'จังๆ', 'ร่วม', 'เข้าใจ', 'ยิ่งขึ้น', 'เช่นที่ว่า', 'ทั้งนั้น', 'ช่วงนั้น', 'ถึงเมื่อใด', 'ไม่ค่อยเป็น', 'กันเอง', 'เป็นเพียง', 'นาง', 'ผู้ใด', 'ถึงเมื่อไร', 'บางขณะ', 'พอๆ', 'ซึ่งกันและกัน', 'จนถึง', 'เช่นนั้น', 'ไม่เป็นไร', 'จากนั้น', 'ซึ่งกัน', 'นำมา', 'ตามที่', 'นอกจาก', 'แค่นี้', 'กว้าง', 'หมด', 'เพื่อให้', 'ซะ', 'ซึ่งๆ', 'พวกแก', 'ทุกอย่าง', 'ยาว', 'บางครา', 'ข้างเคียง', 'ครานี้', 'เหตุผล', 'แม้กระทั่ง', 'ซะจนกระทั่ง', 'พวกคุณ', 'นิด', 'อันได้แก่', 'อย่างดี', 'คราใด', 'ช่วงหลัง', 'มากมาย', 'มุ่งหมาย', 'คราวโน้น', 'นู่น', 'ก็ต่อเมื่อ', 'ต่างก็', 'เกี่ยวเนื่อง', 'ก็ตามที', 'เสียนี่กระไร', 'สิ่งนั้น', 'กว้างขวาง', 'ผล', 'ตามๆ', 'สําหรับ', 'เหตุไร', 'ทุกที', 'เหลือ', 'เฉกเช่น', 'ครั้งละ', 'นอกจากว่า', 'นางสาว', 'นี่', 'อย่างน้อย', 'ต้อง', 'อย่างโน้น', 'ทั้งมวล', 'พื้นๆ', 'คล้ายว่า', 'เห็นแก่', 'บ้าง', 'สบาย', 'ซะก่อน', 'เร็ว', 'ข้าพเจ้า', 'รวมทั้ง', 'ไว้', 'เสียก่อน', 'ที่นี้', 'พอสมควร', 'กว้างๆ', 'ทั้งๆ', 'เสร็จแล้ว', 'อันใด', 'จึงเป็น', 'เสร็จสมบูรณ์', 'กว่า', 'ก็ตาม', 'ด้วยเหตุว่า', 'ฉะนั้น', 'ภาคฯ', 'จำ', 'จริงๆ', 'เห็นควร', 'แต่ไหน', 'เมื่อวาน', 'แบบ', 'นักๆ', 'เช่นเดียวกัน', 'พึ่ง', 'เมื่อนั้น', 'นับแต่นี้', 'เต็มไปด้วย', 'ยกให้', 'ครั้งนั้น', 'ปรากฏว่า', 'ก็คือ', 'เกิด', 'ซึ่ง', 'ฝ่ายใด', 'ช้า', 'ยิ่งใหญ่', 'วัน', 'ที่แล้ว', 'ครั้งใด', 'นอกนั้น', 'ผิดๆ', 'ผิด', 'ที่แห่งนั้น', 'พร้อม', 'มั้ยนะ', 'แต่ถ้า', 'ส่วนเกิน', 'เปลี่ยนแปลง', 'ร่วมมือ', 'พยายาม', 'ค่ะ'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "# ตัดคำ\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text1))\n",
        "words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "# ดึงรายการ stop words ในภาษาไทย\n",
        "stopwords = thai_stopwords()\n",
        "# แปลง stop words เป็นเซ็ต (set) สำหรับการเพิ่ม/ลบ\n",
        "\n",
        "stopwords = set(stopwords)\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_8keLiHlENu",
        "outputId": "730cb19c-a25a-4061-c964-bc4e7dd0b7b1"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "custom dictionary : ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text2))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.discard(\"คำแนะนำ\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text2))\n",
        "words = custom_tokenizer.word_tokenize(text2)\n",
        "\n",
        "stopwords = thai_stopwords()\n",
        "stopwords = set(stopwords)\n",
        "stopwords.discard(\"สามารถ\")\n",
        "stopwords.discard(\"คำ\")\n",
        "stopwords.discard(\"ได้\")\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "id": "FrLPcE7cO53B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304b0436-96e7-40ac-c131-280361d949e2"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำแนะนำ', 'ได้', 'กับ', 'อาจารย์ที่ปรึกษา']\n",
            "custom dictionary : ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำ', 'แนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำ', 'แนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'คำ', 'แนะนำ', 'ได้', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text3))\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text3))\n",
        "words = custom_tokenizer.word_tokenize(text3)\n",
        "\n",
        "stopwords = thai_stopwords()\n",
        "stopwords = set(stopwords)\n",
        "stopwords.discard(\"เกี่ยวกับ\")\n",
        "stopwords.discard(\"คำ\")\n",
        "stopwords.add(\"สำหรับ\")\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c497kmcx91yE",
        "outputId": "cc66ac7d-9f47-4165-8928-230ab1a505fa"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำแนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n",
            "custom dictionary : ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n",
            "Original words: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n",
            "Filtered words: ['ขอบคุณ', 'อาจารย์', 'คำ', 'แนะนำ', 'เกี่ยวกับ', 'เลือก', 'วิชา', 'เรียน']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0A45r2s7_aI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part of Speech tagging"
      ],
      "metadata": {
        "id": "B9hosQNsPiw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
        "pos_tag(words)"
      ],
      "metadata": {
        "id": "ZNUCg1s3Piw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f71727-5803-4dd1-f15d-e432c648b210"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('สวัสดี', 'NCMN'), ('อาจารย์', 'NCMN'), ('ที่ปรึกษา', 'NCMN')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_tsl_grammar(words):\n",
        "    # ตัวอย่างกฎพื้นฐานสำหรับ TSL\n",
        "    words = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
        "    pos_tag(words)\n",
        "\n",
        "    expected_order = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา'] # รูปแบบที่คาดหวัง\n",
        "    tags = pos_tag(words)  # รับ POS tags สำหรับคำ\n",
        "    print(\"POS Tags:\", tags)\n",
        "\n",
        "    # ตรวจสอบการเรียงลำดับพื้นฐานตามกฎที่กำหนดเอง\n",
        "    for i, word in enumerate(words):\n",
        "        if word in ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']:  # คำบอกเวลา\n",
        "            if i != 0:  # คำบอกเวลาควรอยู่ที่ตำแหน่งแรก\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# ใช้ฟังก์ชันเพื่อตรวจสอบ\n",
        "is_correct_order = check_tsl_grammar(words)\n",
        "print(\"Is correct order:\", is_correct_order)"
      ],
      "metadata": {
        "id": "8FqIUNUURcDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b2d927-74d1-439e-f13c-aedc456fd931"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('สวัสดี', 'NCMN'), ('อาจารย์', 'NCMN'), ('ที่ปรึกษา', 'NCMN')]\n",
            "Is correct order: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization: Reduce each word to its base form, depending on its POS tag."
      ],
      "metadata": {
        "id": "oLM9FnsfPiw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "\n",
        "print(get_lemma(\"ที่ปรึกษา\"))"
      ],
      "metadata": {
        "id": "E-x2DMApPiw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c28317-ba3e-4394-cb40-e99c57eb4b02"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ปรึกษา\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# สร้าง custom dictionary\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "# ใช้ custom tokenizer\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "print(\"custom dictionary:\", tokenized_words)\n",
        "\n",
        "# ดึง stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in tokenized_words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", tokenized_words)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in filtered_words]\n",
        "\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "id": "-SzUZngcPiw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6db4beb-7457-4c7e-f983-1aea7c316097"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Lemmatized words: ['สวัสดี', 'อาจารย์', 'ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.discard(\"คำแนะนำ\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text2)\n",
        "\n",
        "print(\"custom dictionary:\", tokenized_words)\n",
        "\n",
        "# ดึง stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "stopwords.discard(\"สามารถ\")\n",
        "stopwords.discard(\"คำ\")\n",
        "stopwords.discard(\"ได้\")\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in tokenized_words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", tokenized_words)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in filtered_words]\n",
        "\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX0cV3pF867c",
        "outputId": "14509309-0fa2-46af-c147-5b70733097d8"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom dictionary: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำ', 'แนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำ', 'แนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'คำ', 'แนะนำ', 'ได้', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Lemmatized words: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'คำ', 'แนะนำ', 'ได้', 'อาจารย์', 'ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\"\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "words = set(thai_words())\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.discard(\"คำแนะนำ\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text3)\n",
        "\n",
        "print(\"custom dictionary:\", tokenized_words)\n",
        "\n",
        "# ดึง stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "stopwords.discard(\"สามารถ\")\n",
        "stopwords.discard(\"คำ\")\n",
        "stopwords.discard(\"ได้\")\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in tokenized_words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", tokenized_words)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in filtered_words]\n",
        "\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYFnDY5h9wGp",
        "outputId": "bef67e43-6ab8-4f70-e462-8e6bf81bb522"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom dictionary: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n",
            "Original words: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n",
            "Filtered words: ['ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เลือก', 'วิชา', 'เรียน']\n",
            "Lemmatized words: ['ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำ', 'แนะนำ', 'เลือก', 'วิชา', 'เรียน']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The reordering of sentences based on Indian Sign Language grammar rules."
      ],
      "metadata": {
        "id": "amtvFL9BPiw9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUeRBzOiaIVZ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Category ที่ทำงาน\n",
        "```\n",
        "11.เคยใช้กูเกิ้ลโครมเพื่อแชร์หรือไฟล์ในกูเกิ้ลไดร์ฟไหม\n",
        "12.ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\n",
        "13.ขอยืมเมาส์บลูทูธและแป้นพิมพ์ของเธอได้มั้ย\n",
        "14.ทักทายเพื่อนที่เป็นสมาชิกใหม่ในองค์กรคมนาคม\n",
        "15.ประสบการณ์การใช้หูฟังไร้สายช่วยลดความเพลียได้\n",
        "16.เห็นด้วยกับระเบียบใหม่ที่ให้อนุมัติได้ง่ายขึ้น\n",
        "17.อย่าดูถูกคนที่มีอายุน้อยและประสบการณ์ที่น้อยกว่า\n",
        "18.หมดแรงเพราะหน้าที่นี้มีการทำงานหนักมาก\n",
        "19.ถ้าคุณแนบเอกสารในกูเกิ้ลไดร์ฟแล้ว ช่วยตอบกลับอีเมลด้วย\n",
        "20.สามารถเขียนเว็บไซต์จากโปรแกรมคอมพิวเตอร์\n",
        "```\n"
      ],
      "metadata": {
        "id": "uQ9hn2tjOXP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenization"
      ],
      "metadata": {
        "id": "NTUccqMaOLde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text11 = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text11))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text11))"
      ],
      "metadata": {
        "id": "JnPHAqegLPPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a877f3b3-f3df-4e46-8462-027a7b3f7a30"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['เคย', 'ใช้', 'กูเกิ้ล', 'โครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ล', 'ไดร์', 'ฟ', 'ไหม']\n",
            "custom dictionary : ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text12 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text12))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfqrVQuJaiuN",
        "outputId": "112181f8-3112-4386-c0d3-f7ab7072f7c2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text13 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text13))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-s04Rbeb2Qh",
        "outputId": "82e74988-77a5-4108-bc34-5eb3356eb547"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text14 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text14))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov9ngcgAb2pw",
        "outputId": "d39d7057-8300-4bb6-f9c5-ce198434606f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text15 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text15))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItqPSom3b3C1",
        "outputId": "f908aec8-0e48-4eca-825f-770a665f6c73"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text16 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text16))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ZyCtDIb-my",
        "outputId": "898afa6f-7d3b-4498-b424-5cc3f8bd8e0b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text17 = \"ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text17))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text17))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9inXLkkXb_bM",
        "outputId": "290f0bbc-03ad-4d00-9482-2996689ff1e3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n",
            "custom dictionary : ['ตอบกลับ', 'ใน', 'แอปพลิเคชั่น', 'ไลน์', 'เพื่อ', 'อนุมัติ', 'หน้าที่', 'ที่', 'เห็นด้วย']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Word Removal\n"
      ],
      "metadata": {
        "id": "Tc9PTjMLXP7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords)"
      ],
      "metadata": {
        "id": "dny6xk9fzX2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f283130-5645-41da-a4f4-c1f65b7b7d39"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'จัง', 'บางๆ', 'เรียก', 'คราวละ', 'ก็แค่', 'ช่วงหน้า', 'ถึงแม้ว่า', 'ยก', 'ถูกๆ', 'ล้วน', 'ภายนอก', 'มีแต่', 'ปิด', 'อย่างๆ', 'ดั่งกับว่า', 'หาใช่', 'น้อยๆ', 'เชื่อ', 'ยิ่งจน', 'อย่างไรก็', 'ภายใต้', 'แค่เพียง', 'ทว่า', 'เช่นดัง', 'จ๋า', 'คิด', 'ทั้งสิ้น', 'ใกล้ๆ', 'แก่', 'เราๆ', 'เท่าใด', 'คงอยู่', 'แต่ก่อน', 'หากว่า', 'เผื่อที่', 'เสียจนถึง', 'ทีไร', 'จด', 'เชื่อว่า', 'ใหญ่ๆ', 'เฉย', 'หลัง', 'พบว่า', 'ได้รับ', 'ขาด', 'นับแต่ที่', 'เรื่อย', 'ถือว่า', 'เป็นด้วย', 'เป็นเพราะ', 'จนทั่ว', 'ระยะๆ', 'จัดตั้ง', 'ตรง', 'เหล่า', 'แต่ทว่า', 'ตนเอง', 'ที่ว่า', 'ตลอดวัน', 'ก่อน', 'พร้อมที่', 'ระยะ', 'ค่อนมาทาง', 'เช่น', 'ดั่ง', 'นั่นเอง', 'ไม่ว่า', 'เท่าไร', 'น่า', 'เถิด', 'หรือเปล่า', 'หาความ', 'ตรงๆ', 'นัก', 'เผื่อว่า', 'ส่วนที่', 'ภายหลัง', 'ไป่', 'ยาก', 'ฯ', 'เป็นที', 'มิได้', 'อย่างนี้', 'นั่นไง', 'ที', 'ทั่ว', 'แต่ต้อง', 'ยังไง', 'หนึ่ง', 'ใหม่', 'เท่าไหร่', 'รึว่า', 'อันที่จริง', 'อย่างไร', 'รึ', 'เน้น', 'เพื่อที่จะ', 'มา', 'แต่เดิม', 'ตลอดทั้ง', 'หน่อย', 'ยืนยง', 'เช่นดังก่อน', 'ปรับ', 'พวกเขา', 'เห็น', 'ทั้งคน', 'มุ่งเน้น', 'วันไหน', 'เช่นเคย', 'กำลังจะ', 'เปลี่ยน', 'ล่าสุด', 'อันที่', 'เท่ากัน', 'เป็น', 'จะได้', 'ด้วยว่า', 'กันนะ', 'ถ้าจะ', 'เพียงใด', 'จัดงาน', 'การ', 'ทันที', 'ระหว่าง', 'มี', 'เพิ่มเติม', 'เกือบ', 'นอกจากนั้น', 'ตนฯ', 'ซึ่งได้แก่', 'นับจากนี้', 'พวกกัน', 'ได้', 'กันไหม', 'เฉพาะ', 'ไม่ใช่', 'ทันใดนั้น', 'เคยๆ', 'พอกัน', 'แห่ง', 'ยังโง้น', 'ทุกสิ่ง', 'จนบัดนี้', 'อาจเป็น', 'คราวๆ', 'ที่', 'เดียว', 'ฯล', 'พวกนี้', 'เหลือเกิน', 'ด้วย', 'คล้าย', 'กระนั้น', 'เท่าที่', 'คราวหนึ่ง', 'เล็ก', 'คราวใด', 'ครับ', 'เรียบ', 'ที่สุด', 'ทั้งที่', 'ช้าๆ', 'แม้', 'ซึ่งก็คือ', 'ตลอดระยะเวลา', 'บ่อยกว่า', 'ข้างต้น', 'ยืนนาน', 'เมื่อคืน', 'ถ้าหาก', 'ทุกชิ้น', 'สู่', 'ทั้งเป็น', 'อีก', 'เพียงแค่', 'ดั่งเก่า', 'เมื่อเย็น', 'ผู้', 'เกินๆ', 'จวบจน', 'ทุกๆ', 'จวน', 'สั้นๆ', 'ทุกแห่ง', 'จัดแจง', 'ทุกตัว', 'มิใช่', 'แค่นั้น', 'พวกมึง', 'ใหญ่โต', 'อย่างไรก็ได้', 'ที่นั้น', 'พอที่', 'นับแต่นั้น', 'พร้อมด้วย', 'จำพวก', 'กำลัง', 'ประมาณ', 'สมัยโน้น', 'คราไหน', 'เช่นดังเก่า', 'ไฉน', 'เป็นเพื่อ', 'หากแม้น', 'เหล่านั้น', 'ทุกครา', 'แก', 'กล่าว', 'ทำๆ', 'รวมกัน', 'ทีละ', 'ได้ที่', 'เสียยิ่ง', 'ความ', 'ส่ง', 'ๆ', 'ยังงั้น', 'ยาวนาน', 'นานๆ', 'กระผม', 'อันไหน', 'ยอม', 'ร่วมกัน', 'ต่อกัน', 'จนตลอด', 'บอก', 'บ่อย', 'เข้า', 'นอกเหนือ', 'ขั้น', 'เล็กๆ', 'เมื่อครั้ง', 'พวกฉัน', 'กระทั่ง', 'แห่งโน้น', 'ถึงจะ', 'เป็นเพียงว่า', 'พร้อมทั้ง', 'อาจจะ', 'นี่นา', 'คราวนั้น', 'ขณะนั้น', 'กู', 'แห่งใด', 'เช่นดังที่', 'ทุกทาง', 'ไม่', 'เป็นอันๆ', 'เมื่อไร', 'ซึ่งก็', 'บอกว่า', 'ค่อย', 'แค่', 'เพียงเพื่อ', 'ค่อยๆ', 'นับตั้งแต่', 'ที่ๆ', 'ด้วยประการฉะนี้', 'ช่วง', 'ที่แท้จริง', 'มั้ย', 'ส่วน', 'ล้วนแต่', 'นิดๆ', 'จวนจะ', 'ปฏิบัติ', 'มั้ยล่ะ', 'นี่แหละ', 'บน', 'ที่ซึ่ง', 'เมื่อคราวที่', 'พวกนั้น', 'ด้วยเหมือนกัน', 'เอง', 'จึงจะ', 'ยังแต่', 'สิ่งใด', 'เร็วๆ', 'คงจะ', 'ถึงบัดนี้', 'ตน', 'ถือ', 'เป็นต้นมา', 'เสียยิ่งนัก', 'เพราะ', 'จนกว่า', 'หมดกัน', 'พอจะ', 'ส่วนด้อย', 'โตๆ', 'ขณะนี้', 'นำพา', 'ภาค', 'ครั้งครา', 'ตั้ง', 'พวกกู', 'ใต้', 'เธอ', 'พึง', 'ยังคง', 'ยิ่งนัก', 'นํา', 'ด้วยเหตุที่', 'บางที', 'รับรอง', 'เมื่อเช้า', 'ฉะนี้', 'แสดงว่า', 'รวดเร็ว', 'มั้ยเนี่ย', 'คือ', 'ทรง', 'เป็นอันว่า', 'เหตุนั้น', 'ตาม', 'อื่นๆ', 'กันดีกว่า', 'คราวก่อน', 'ฉัน', 'พวกมัน', 'ถึง', 'เกี่ยวๆ', 'ดั่งเคย', 'ใหม่ๆ', 'เช่นที่เคย', 'นอกจากนี้', 'ครั้ง', 'เริ่ม', 'ทุกครั้ง', 'อันละ', 'เป็นที่สุด', 'แยะ', 'เชื่อมั่น', 'ทาง', 'ขณะใดๆ', 'สูง', 'รวด', 'ใคร', 'ตลอดทั่วทั้ง', 'คุณ', 'เอ็ง', 'พอเพียง', 'เดียวกัน', 'ทีใด', 'พอ', 'คราหนึ่ง', 'เพิ่ง', 'เรา', 'ดั่งกับ', 'พวกที่', 'ในช่วง', 'จนกระทั่ง', 'จรด', 'ทั้ง', 'จ้ะ', 'น้อย', 'เช่นนี้', 'ทันทีทันใด', 'บ่อยๆ', 'ใดๆ', 'คล้ายกัน', 'อดีต', 'จำเป็น', 'ขวาง', 'ด้วยเช่นกัน', 'จัดให้', 'จวบกับ', 'ช่วงระหว่าง', 'นับแต่', 'นอก', 'คิดว่า', 'บางกว่า', 'ภายภาคหน้า', 'พอสม', 'เป็นต้น', 'ตามแต่', 'ข้าง', 'เช่นดังว่า', 'แค่ว่า', 'ด้วยเหตุนี้', 'ประสบ', 'ทุกคราว', 'นำ', 'นี้แหล่', 'ยัง', 'ครบครัน', 'ทุกอัน', 'มักจะ', 'เช่นเมื่อ', 'สมัยนั้น', 'ภายหน้า', 'เพียงไหน', 'จะ', 'มัก', 'เมื่อคราว', 'แค่ไหน', 'ย่อม', 'นับจากนั้น', 'เพื่อ', 'ย่อย', 'ยอมรับ', 'เมื่อวันวาน', 'เป็นต้นไป', 'ใกล้', 'ที่ไหน', 'อย่างละ', 'เกี่ยวกัน', 'ไหนๆ', 'เป็นเพราะว่า', 'เสียนั่น', 'พอแล้ว', 'อย่างเช่น', 'เปิด', 'พวกเธอ', 'เฉยๆ', 'แต่อย่างใด', 'ราย', 'ยังจะ', 'จริงจัง', 'หากแม้นว่า', 'ยังงี้', '\\ufeffๆ', 'ทุกที่', 'แต่ละ', 'ประการ', 'แสดง', 'ตลอดจน', 'สุดๆ', 'จู่ๆ', 'พูด', 'เล่าว่า', 'เนี่ยเอง', 'ครา', 'เหล่านี้', 'ทั้งหมด', 'ไกล', 'ณ', 'แต่นั้น', 'ทำไร', 'หนอ', 'ทำให้', 'ประการใด', 'หมดสิ้น', 'ครบ', 'ขณะใด', 'ครั้งๆ', 'อาจ', 'ถึงแก่', 'หากแม้', 'ช่วงนี้', 'นี้', 'เพิ่งจะ', 'รวมถึง', 'ด้วยเหตุนั้น', 'แห่งนั้น', 'เช่นกัน', 'เกิน', 'เคย', 'คะ', 'อนึ่ง', 'คราวที่', 'มั้ยนั่น', 'ประกอบ', 'ไง', 'แล้วเสร็จ', 'ในระหว่าง', 'นับ', 'กัน', 'ทั้งนี้', 'หรือไม่', 'ออก', 'เสร็จสิ้น', 'จาก', 'ทั้งตัว', 'สมัย', 'ฯลฯ', 'แต่เพียง', 'ตลอดถึง', 'เพียงพอ', 'นาย', 'ยิ่งกว่า', 'เมื่อครั้งก่อน', 'ซะจนถึง', 'ขณะเดียวกัน', 'มองว่า', 'เพียงแต่', 'เช่นก่อน', 'กระทำ', 'ทั้งที', 'ได้แต่', 'ทีเถอะ', 'น่าจะ', 'พอควร', 'จัดการ', 'ให้ไป', 'ให้มา', 'ใช้', 'คล้ายกันกับ', 'ขวางๆ', 'รวม', 'หารือ', 'สิ้นกาลนาน', 'ละ', 'จริง', 'เพราะฉะนั้น', 'เกือบจะ', 'ทั้งปวง', 'ครั้งนี้', 'สุด', 'จับ', 'ส่วนน้อย', 'ใช่', 'กล่าวคือ', 'ทุก', 'ด้วยเพราะ', 'หรือไง', 'เนื่องจาก', 'โดย', 'นี่เอง', 'มอง', 'วันนั้น', 'จนแม้', 'ทำไม', 'เสีย', 'พวกโน้น', 'ซะจน', 'แล้ว', 'บางครั้ง', 'ตลอดทั่วถึง', 'ประการหนึ่ง', 'อันเนื่องมาจาก', 'อย่างนั้น', 'ไม่ค่อย', 'เช่นใด', 'ผ่านๆ', 'แรก', 'ก่อนหน้า', 'จนขณะนี้', 'มุ่ง', 'เหตุนี้', 'จัดทำ', 'มันๆ', 'จวบ', 'เมื่อคราวก่อน', 'เกือบๆ', 'ดังกับ', 'เยอะๆ', 'เป็นๆ', 'คล้ายกับว่า', 'เป็นที่', 'เผื่อ', 'เหตุ', 'ช่วงก่อน', 'ส่วนใหญ่', 'กันเถอะ', 'ที่ได้', 'นี่แน่ะ', 'เขียน', 'สิ่งนี้', 'ถึงแม้จะ', 'สูงๆ', 'บางคราว', 'เพิ่ม', 'หลาย', 'ภายใน', 'เผื่อจะ', 'สิ่ง', 'ให้ดี', 'ส่วนใด', 'คราวหน้า', 'ตลอดทั่ว', 'ก็จะ', 'อย่างเดียว', 'ครั้งไหน', 'ใน', 'พวกท่าน', 'แยะๆ', 'สูงสุด', 'อยาก', 'คุณๆ', 'หรือไร', 'นิดหน่อย', 'เลย', 'ครั้งหลังสุด', 'คง', 'ไร', 'ถึงอย่างไร', 'ช่วงแรก', 'นั่น', 'แหละ', 'อยู่', 'บัดนั้น', 'ข้างบน', 'ครัน', 'ที่ละ', 'อื่น', 'ตามด้วย', 'ดัง', 'อันๆ', 'แม้นว่า', 'กลุ่ม', 'อันที่จะ', 'ครั้งหนึ่ง', 'ต่อ', 'ช้านาน', 'เสียด้วย', 'ในที่', 'ฝ่าย', 'พอตัว', 'ถึงเมื่อ', 'แห่งนี้', 'เพื่อว่า', 'และ', 'ตลอดมา', 'ทุกหน', 'ล้วนจน', 'รวมๆ', 'ช่วย', 'แม้ว่า', 'ก่อนหน้านี้', 'ก็', 'อะไร', 'บอกแล้ว', 'เป็นการ', 'ไกลๆ', 'เสียนี่', 'อย่างมาก', 'ตลอดปี', 'จริงๆจังๆ', 'ผ่าน', 'บัดเดี๋ยวนี้', 'ในเมื่อ', 'ไหน', 'เห็นจะ', 'เพื่อที่', 'ยิ่งจะ', 'แต่ไร', 'คำ', 'ทั้งนั้นเพราะ', 'เยอะแยะ', 'พวก', 'ช่วงต่อไป', 'หน', 'ทุกวันนี้', 'มั๊ย', 'พร้อมกัน', 'ค่อนข้าง', 'แล้วแต่', 'ตลอดกาล', 'ทําให้', 'เมื่อก่อน', 'สั้น', 'ด้วยที่', 'ยิ่งเมื่อ', 'ทั้งหลาย', 'เสร็จกัน', 'นอกจากที่', 'เก็บ', 'ประการฉะนี้', 'ขอ', 'จ้า', 'เชื่อถือ', 'ครานั้น', 'แต่ก็', 'หาก', 'ถูก', 'ไป', 'หนอย', 'บางแห่ง', 'ให้แด่', 'หรือยัง', 'ใหญ่', 'เป็นอัน', 'ดังกับว่า', 'มากกว่า', 'พอดี', 'ตั้งแต่', 'รือว่า', 'บ่อยครั้ง', 'ส่วนดี', 'ใช่ไหม', 'แต่จะ', 'ยิ่งแล้ว', 'เกี่ยวกับ', 'พร้อมเพียง', 'เมื่อ', 'ช่วงท้าย', 'น่ะ', 'ชาว', 'ครั้งหลัง', 'อย่างหนึ่ง', 'ไม่ค่อยจะ', 'เรื่อยๆ', 'ข้าฯ', 'เยอะ', 'ทุกคน', 'เสมือนว่า', 'เมื่อไหร่', 'จัด', 'ก็ตามแต่', 'แต่เมื่อ', 'เช่นนั้นเอง', 'เท่านั้น', 'จนเมื่อ', 'ควร', 'สิ้น', 'จนแม้น', 'นั้นไว', 'ด้าน', 'เถอะ', 'ช่วงๆ', 'คราวไหน', 'วันใด', 'จัดหา', 'ข้างล่าง', 'รวมด้วย', 'แต่ว่า', 'เมื่อใด', 'เล็กน้อย', 'สมัยนี้', 'ค่อนข้างจะ', 'อาจเป็นด้วย', 'นี้เอง', 'แล้วกัน', 'จรดกับ', 'เป็นอันมาก', 'นั่นแหละ', 'โต', 'เอา', 'แม้แต่', 'มาก', 'ครั้งก่อน', 'ยิ่ง', 'ปัจจุบัน', 'ยืนยัน', 'นู้น', 'ข้างๆ', 'ที่ใด', 'อย่างไรเสีย', 'ที่แท้', 'นั้นๆ', 'ที่จริง', 'สิ่งไหน', 'บัดนี้', 'เช่นที่', 'จวนเจียน', 'เนี่ย', 'แต่', 'สมัยก่อน', 'เช่นเดียวกับ', 'ง่ายๆ', 'ทั้งนั้นด้วย', 'ก็ได้', 'คล้ายกับ', 'พวกนู้น', 'ส่วนมาก', 'ทุกเมื่อ', 'พา', 'ให้แก่', 'ได้แก่', 'ได้มา', 'ขึ้น', 'ข้า', 'ถ้า', 'เพียงไร', 'นั้น', 'ดังกล่าว', 'ว่า', 'คราวนี้', 'หลังจาก', 'น้อยกว่า', 'ใครๆ', 'ทีๆ', 'เท่า', 'ก็ดี', 'ครั้งกระนั้น', 'จึง', 'เท่ากับ', 'ให้', 'จากนี้', 'สามารถ', 'เปิดเผย', 'ด้วยกัน', 'ตลอดศก', 'จ๊ะ', 'ยืนยาว', 'เต็มๆ', 'ก็แล้วแต่', 'อย่างยิ่ง', 'เพียงเพราะ', 'เสมือนกับ', 'ครั้งที่', 'เช่นไร', 'กลุ่มก้อน', 'เป็นแต่', 'เป็นดัง', 'แท้จริง', 'ทีเดียว', 'คราที่', 'อย่างใด', 'ด้วยเหตุเพราะ', 'ค่อยไปทาง', 'นี่ไง', 'ต่างๆ', 'อย่าง', 'ทุกวัน', 'ลง', 'ช่วงถัดไป', 'มิ', 'ตลอดไป', 'ภาย', 'ขณะหนึ่ง', 'พอที', 'เต็มไปหมด', 'รับ', 'เห็นว่า', 'คราวหลัง', 'ต่างหาก', 'เสียนั่นเอง', 'ต่าง', 'เท่านี้', 'ทัน', 'สูงส่ง', 'ตลอดกาลนาน', 'ครั้งคราว', 'มิฉะนั้น', 'แก้ไข', 'นาน', 'นั่นเป็น', 'กลุ่มๆ', 'ง่าย', 'เป็นแต่เพียง', 'บาง', 'เสียแล้ว', 'สำคัญ', 'ตลอดเวลา', 'อย่างที่', 'เพราะว่า', 'เพียง', 'ดังเคย', 'ครบถ้วน', 'สืบเนื่อง', 'กันดีไหม', 'เสียจน', 'บางที่', 'ยิ่งขึ้นไป', 'แท้', 'ตลอด', 'หรือ', 'วันนี้', 'พบ', 'ทํา', 'สูงกว่า', 'อัน', 'แห่งไหน', 'ค่อน', 'เสร็จ', 'ขณะ', 'กับ', 'คราว', 'มึง', 'ถึงแม้', 'ถึงบัดนั้น', 'อย่างไหน', 'กำหนด', 'มัน', 'ก่อนๆ', 'ใคร่จะ', 'ส่วนนั้น', 'ช่วงที่', 'จง', 'แค่จะ', 'นอกเหนือจาก', 'บัดดล', 'ขณะที่', 'ดังเก่า', 'ร่วมด้วย', 'เสียจนกระทั่ง', 'ภายภาค', 'ปรากฏ', 'กลับ', 'กันและกัน', 'จากนี้ไป', 'เกี่ยวข้อง', 'ของ', 'พอเหมาะ', 'ถูกต้อง', 'ใคร่', 'จน', 'พร้อมกับ', 'รือ', 'นะ', 'แต่ที่', 'อันจะ', 'เขา', 'เมื่อนี้', 'เป็นอาทิ', 'จังๆ', 'ร่วม', 'เข้าใจ', 'ยิ่งขึ้น', 'เช่นที่ว่า', 'ทั้งนั้น', 'ช่วงนั้น', 'ถึงเมื่อใด', 'ไม่ค่อยเป็น', 'กันเอง', 'เป็นเพียง', 'นาง', 'ผู้ใด', 'ถึงเมื่อไร', 'บางขณะ', 'พอๆ', 'ซึ่งกันและกัน', 'จนถึง', 'เช่นนั้น', 'ไม่เป็นไร', 'จากนั้น', 'ซึ่งกัน', 'นำมา', 'ตามที่', 'นอกจาก', 'แค่นี้', 'กว้าง', 'หมด', 'เพื่อให้', 'ซะ', 'ซึ่งๆ', 'พวกแก', 'ทุกอย่าง', 'ยาว', 'บางครา', 'ข้างเคียง', 'ครานี้', 'เหตุผล', 'แม้กระทั่ง', 'ซะจนกระทั่ง', 'พวกคุณ', 'นิด', 'อันได้แก่', 'อย่างดี', 'คราใด', 'ช่วงหลัง', 'มากมาย', 'มุ่งหมาย', 'คราวโน้น', 'นู่น', 'ก็ต่อเมื่อ', 'ต่างก็', 'เกี่ยวเนื่อง', 'ก็ตามที', 'เสียนี่กระไร', 'สิ่งนั้น', 'กว้างขวาง', 'ผล', 'ตามๆ', 'สําหรับ', 'เหตุไร', 'ทุกที', 'เหลือ', 'เฉกเช่น', 'ครั้งละ', 'นอกจากว่า', 'นางสาว', 'นี่', 'อย่างน้อย', 'ต้อง', 'อย่างโน้น', 'ทั้งมวล', 'พื้นๆ', 'คล้ายว่า', 'เห็นแก่', 'บ้าง', 'สบาย', 'ซะก่อน', 'เร็ว', 'ข้าพเจ้า', 'รวมทั้ง', 'ไว้', 'เสียก่อน', 'ที่นี้', 'พอสมควร', 'กว้างๆ', 'ทั้งๆ', 'เสร็จแล้ว', 'อันใด', 'จึงเป็น', 'เสร็จสมบูรณ์', 'กว่า', 'ก็ตาม', 'ด้วยเหตุว่า', 'ฉะนั้น', 'ภาคฯ', 'จำ', 'จริงๆ', 'เห็นควร', 'แต่ไหน', 'เมื่อวาน', 'แบบ', 'นักๆ', 'เช่นเดียวกัน', 'พึ่ง', 'เมื่อนั้น', 'นับแต่นี้', 'เต็มไปด้วย', 'ยกให้', 'ครั้งนั้น', 'ปรากฏว่า', 'ก็คือ', 'เกิด', 'ซึ่ง', 'ฝ่ายใด', 'ช้า', 'ยิ่งใหญ่', 'วัน', 'ที่แล้ว', 'ครั้งใด', 'นอกนั้น', 'ผิดๆ', 'ผิด', 'ที่แห่งนั้น', 'พร้อม', 'มั้ยนะ', 'แต่ถ้า', 'ส่วนเกิน', 'เปลี่ยนแปลง', 'ร่วมมือ', 'พยายาม', 'ค่ะ'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "# ตัดคำ\n",
        "print(\"default dictionary:\", word_tokenize(text))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text))\n",
        "words = custom_tokenizer.word_tokenize(text)\n",
        "\n",
        "# ดึงรายการ stop words ในภาษาไทย\n",
        "stopwords = thai_stopwords()\n",
        "# แปลง stop words เป็นเซ็ต (set) สำหรับการเพิ่ม/ลบ\n",
        "\n",
        "stopwords = set(stopwords)\n",
        "\n",
        "# เพิ่มคำใหม่เข้าไปใน stop words\n",
        "stopwords.add(\"ไหม\")\n",
        "stopwords.add(\"ทำงาน\")\n",
        "\n",
        "# ลบคำบางคำออกจาก stop words\n",
        "stopwords.discard(\"เคย\")\n",
        "stopwords.discard(\"ใช้\")\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "id": "o9UOjfeQX9o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e08fa7-2898-496d-87d6-b5fa8473eeac"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['เคย', 'ใช้', 'กูเกิ้ล', 'โครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ล', 'ไดร์', 'ฟ', 'ไหม']\n",
            "custom dictionary : ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Original words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Filtered words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'แชร์', 'รูปภาพ', 'กูเกิ้ลไดร์ฟ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part of Speech tagging"
      ],
      "metadata": {
        "id": "_9FW41E0WuWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
        "pos_tag(words)"
      ],
      "metadata": {
        "id": "ernbPKbDOq2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d37794-5def-430f-e645-689ab06bd09c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('เคย', 'XVMM'),\n",
              " ('ใช้', 'VACT'),\n",
              " ('กูเกิ้ลโครม', 'NCMN'),\n",
              " ('เพื่อ', 'RPRE'),\n",
              " ('แชร์', 'VACT'),\n",
              " ('รูปภาพ', 'NCMN'),\n",
              " ('ใน', 'RPRE'),\n",
              " ('กูเกิ้ลไดร์ฟ', 'NCMN'),\n",
              " ('ไหม', 'NCMN')]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization: Reduce each word to its base form, depending on its POS tag."
      ],
      "metadata": {
        "id": "vG3y24f52B2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The reordering of sentences based on Indian Sign Language grammar rules."
      ],
      "metadata": {
        "id": "IdPMtwGPqLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_to_tsl(words):\n",
        "    # ลบคำที่ไม่จำเป็น เช่น คำบอกเพศ คำเสริม\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # เรียงลำดับโดยย้ายคำบอกเวลาไปด้านหน้า\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # รายการคำบอกเวลา\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # เรียงลำดับ (Time-Topic-Comment)\n",
        "    reordered_sentence = time_elements + non_time_elements\n",
        "\n",
        "    # รวมคำกลับเป็นประโยค\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ประโยคตัวอย่าง\n",
        "text = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "# เพิ่มคำพิเศษใน custom dictionary\n",
        "words = set(thai_words())  # thai_words() คืนค่า frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "\n",
        "# ตัดคำด้วย custom dictionary\n",
        "words_tokenized = custom_tokenizer.word_tokenize(text)\n",
        "\n",
        "# ดึงรายการ stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "\n",
        "# เพิ่มคำใหม่เข้าไปใน stop words\n",
        "stopwords.add(\"ไหม\")\n",
        "stopwords.add(\"ทำงาน\")\n",
        "\n",
        "# ลบคำบางคำออกจาก stop words\n",
        "stopwords.discard(\"เคย\")\n",
        "stopwords.discard(\"ใช้\")\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in words_tokenized if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words_tokenized)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้คำที่กรองแล้วมาเรียงลำดับตามกฎ TSL\n",
        "tsl_sentence = reorder_to_tsl(filtered_words)\n",
        "print(\"Reordered sentence (TSL):\", tsl_sentence)"
      ],
      "metadata": {
        "id": "qoAZxOzaEPXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0750d4-d7bd-4b98-98ff-79c4183d6d7b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Filtered words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'แชร์', 'รูปภาพ', 'กูเกิ้ลไดร์ฟ']\n",
            "Reordered sentence (TSL): เคย ใช้ กูเกิ้ลโครม แชร์ รูปภาพ กูเกิ้ลไดร์ฟ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_to_tsl_and_noun_before_verb(sentence):\n",
        "    # Tokenize the sentence using PyThaiNLP\n",
        "    words = pythainlp.word_tokenize(sentence, engine='newmm')  # Using the 'newmm' tokenizer\n",
        "\n",
        "    # Simplify the sentence by removing articles and auxiliary verbs\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # Step 1: Move time words to the beginning (TSL structure)\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # List of common time-related words\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # Reorder the sentence (Time-Topic-Comment structure)\n",
        "    sentence_after_tsl = time_elements + non_time_elements\n",
        "\n",
        "    # Step 2: Perform part-of-speech tagging to identify nouns and verbs\n",
        "    pos_tags = pos_tag(sentence_after_tsl, engine='perceptron', corpus='orchid')\n",
        "\n",
        "    # Separate nouns and verbs\n",
        "    nouns = [word for word, pos in pos_tags if pos.startswith('N')]  # Noun\n",
        "    verbs = [word for word, pos in pos_tags if pos.startswith('V')]  # Verb\n",
        "    others = [word for word, pos in pos_tags if not (pos.startswith('N') or pos.startswith('V'))]  # Other words\n",
        "\n",
        "    # Combine and remove duplicates\n",
        "    reordered_sentence = list(dict.fromkeys(time_elements + nouns + others + verbs))\n",
        "\n",
        "    # Join words back into a string\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ตัวอย่างประโยคภาษาไทย\n",
        "sentence3 = \"ฉันจะไปตลาดพรุ่งนี้\"\n",
        "\n",
        "# Reorder the sentence following TSL grammar and nouns before verbs\n",
        "reordered_sentence3 = reorder_to_tsl_and_noun_before_verb(sentence3)\n",
        "print(\"ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา:\", reordered_sentence3)"
      ],
      "metadata": {
        "id": "1_YvPxmnyLuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6636f408-3dac-4161-b127-d73ac818cf32"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา: พรุ่งนี้ ตลาด ฉัน ไป\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "\n",
        "print(get_lemma(\"ที่ปรึกษา\"))"
      ],
      "metadata": {
        "id": "1w-R7DtYCsF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda03549-74f9-4d19-c42f-c09cc128c53b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ปรึกษา\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# สร้าง custom dictionary\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.add(\"สวัสดีค่ะ\")  # เพิ่มคำ \"สวัสดีค่ะ\"\n",
        "\n",
        "# ใช้ custom tokenizer\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in tokenized_words]\n",
        "\n",
        "print(\"newmm (custom dictionary):\", tokenized_words)\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "id": "GwDSJ7YXKKif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc43f3b-9514-4702-fcad-291767e434f8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "newmm (custom dictionary): ['สวัสดีค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Lemmatized words: ['สวัสดี', 'อาจารย์', 'ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp\n",
        "from pythainlp.tag import pos_tag\n",
        "\n",
        "# ฟังก์ชันการหาคำพื้นฐาน (lemma)\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# ฟังก์ชันการเรียงตามไวยากรณ์ TSL และเรียงคำนามก่อนกริยา พร้อมการใช้ lemma\n",
        "def reorder_to_tsl_and_noun_before_verb(sentence):\n",
        "    # Tokenize the sentence using PyThaiNLP\n",
        "    words = pythainlp.word_tokenize(sentence, engine='newmm')  # Using the 'newmm' tokenizer\n",
        "\n",
        "    # Simplify the sentence by removing articles and auxiliary verbs\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # Step 1: Move time words to the beginning (TSL structure)\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # List of common time-related words\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # Reorder the sentence (Time-Topic-Comment structure)\n",
        "    sentence_after_tsl = time_elements + non_time_elements\n",
        "\n",
        "    # Step 2: Perform part-of-speech tagging to identify nouns and verbs\n",
        "    pos_tags = pos_tag(sentence_after_tsl, engine='perceptron', corpus='orchid')\n",
        "\n",
        "    # Apply the custom get_lemma function to all words in the sentence\n",
        "    sentence_after_lemma = [get_lemma(word) for word in sentence_after_tsl]\n",
        "\n",
        "    # Separate nouns and verbs\n",
        "    nouns = [word for word, pos in pos_tags if pos.startswith('N')]  # Noun\n",
        "    verbs = [word for word, pos in pos_tags if pos.startswith('V')]  # Verb\n",
        "    others = [word for word, pos in pos_tags if not (pos.startswith('N') or pos.startswith('V'))]  # Other words\n",
        "\n",
        "    # Reorder: Nouns -> Others -> Verbs\n",
        "    reordered_sentence = time_elements + nouns + others + verbs\n",
        "\n",
        "    # Join words back into a string\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ตัวอย่างประโยคภาษาไทย\n",
        "sentence3 = \"ฉันจะไปตลาดพรุ่งนี้\"\n",
        "\n",
        "# Reorder the sentence following TSL grammar and nouns before verbs\n",
        "reordered_sentence3 = reorder_to_tsl_and_noun_before_verb(sentence3)\n",
        "print(\"ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา พร้อมการใช้ lemma:\", reordered_sentence3)"
      ],
      "metadata": {
        "id": "MLZ07UzPEC8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4a343a-e553-4f8a-ac37-22dc098f12d8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา พร้อมการใช้ lemma: พรุ่งนี้ ตลาด พรุ่งนี้ ฉัน ไป\n"
          ]
        }
      ]
    }
  ]
}