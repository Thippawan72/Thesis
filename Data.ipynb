{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ri5cVDAWIgp7",
        "MqR6Klwc-UAH",
        "A6gy4MLGIgp9",
        "32vFPqeB-UAJ",
        "B9hosQNsPiw0",
        "_9FW41E0WuWg",
        "IdPMtwGPqLDK"
      ],
      "mount_file_id": "1MsIwZL9GB6DnXojABJF5N2V1zIPRxx3d",
      "authorship_tag": "ABX9TyP/xoEAB2z0LiISazJBNuO8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thippawan72/Thesis/blob/main/Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VhBw2AmK4sGQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "jEVHz8jCFOnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m23WOv5CmOHg",
        "outputId": "c1c889e4-90a1-4b57-aee0-fe202cc6405d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f05dnQR43St",
        "outputId": "ff952fe2-4692-4f76-c1ac-24444591448c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip"
      ],
      "metadata": {
        "id": "e4GtPYPDnl3F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the input and output directories\n",
        "formal_input_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ภาษาระดับกึ่งทางการ/วิดีโอทั้งหมดกึ่งทางการ'\n",
        "formal_output_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ภาษาระดับกึ่งทางการ/Video_กึ่งทางการ'\n",
        "\n",
        "casual_input_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ระดับการใช้ในชีวิตประจำวัน /วิดีโอทั้งหมดการใช้ชีวิตประจำวัน'\n",
        "casual_output_directory = '/content/drive/MyDrive/Thesis/วิดีโอภาษามือ/ระดับการใช้ในชีวิตประจำวัน /Video_การใช้ชีวิตประจำวัน'"
      ],
      "metadata": {
        "id": "dxA0Dw77n1ZC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert GIF to MP4\n",
        "def convert_gif_to_mp4(input_gif, output_mp4):\n",
        "    try:\n",
        "        # Load the GIF file\n",
        "        clip = VideoFileClip(input_gif)\n",
        "\n",
        "        # Write the video to MP4 format\n",
        "        clip.write_videofile(output_mp4, codec='libx264')\n",
        "        print(f\"Successfully converted {input_gif} to {output_mp4}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to convert {input_gif}: {e}\" )"
      ],
      "metadata": {
        "id": "1OSXPthpm8r3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess all GIFs in a directory\n",
        "#def preprocess_videos(input_dir, output_dir):\n",
        "#   if not os.path.exists(output_dir):\n",
        " #       os.makedirs(output_dir)\n",
        "\n",
        "#    # Loop over all files in the input directory\n",
        " #   for filename in os.listdir(input_dir):\n",
        "  #      if filename.endswith(\".gif\"):\n",
        "   #         input_path = os.path.join(input_dir, filename)\n",
        "    #        output_filename = filename.replace(\".gif\", \".mp4\")\n",
        "     #       output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "            # Convert GIF to MP4\n",
        "      #      convert_gif_to_mp4(input_path, output_path)\n",
        "\n",
        "# Start preprocessing the GIFs\n",
        "#preprocess_videos(formal_input_directory, formal_output_directory)"
      ],
      "metadata": {
        "id": "HVpZAsKSna4v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5cVDAWIgp7"
      },
      "source": [
        "# PyThaiNLP Get Started\n",
        "\n",
        "Code examples for basic functions in PyThaiNLP https://github.com/PyThaiNLP/pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3HsfhZlwInqs"
      },
      "outputs": [],
      "source": [
        "# # pip install required modules\n",
        "# # uncomment if running from colab\n",
        "# # see list of modules in `requirements` and `extras`\n",
        "# # in https://github.com/PyThaiNLP/pythainlp/blob/dev/setup.py\n",
        "\n",
        "#!pip install pythainlp\n",
        "#!pip install epitran"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install required modules"
      ],
      "metadata": {
        "id": "BaT_g8fV-7xp",
        "outputId": "f932fe43-36c1-4ed9-9ff7-4ea743b60fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: required in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: modules in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from required) (1.16.0)\n",
            "Requirement already satisfied: lark-parser in /usr/local/lib/python3.10/dist-packages (from required) (0.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pythainlp\n",
        "#!pip install epitran"
      ],
      "metadata": {
        "id": "E32blbWe_CLX",
        "outputId": "9976022e-51a5-469a-a34b-daae3c80c530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n",
            "Downloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.0.4\n",
            "Collecting epitran\n",
            "  Downloading epitran-1.25.1-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from epitran) (71.0.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from epitran) (2024.5.15)\n",
            "Collecting panphon>=0.20 (from epitran)\n",
            "  Downloading panphon-0.21.2-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.10/dist-packages (from epitran) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from epitran) (2.32.3)\n",
            "Collecting jamo (from epitran)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting g2pk (from epitran)\n",
            "  Downloading g2pK-0.9.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting unicodecsv (from panphon>=0.20->epitran)\n",
            "  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (1.26.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from panphon>=0.20->epitran) (0.8.1)\n",
            "Collecting munkres (from panphon>=0.20->epitran)\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from g2pk->epitran) (3.8.1)\n",
            "Collecting konlpy (from g2pk->epitran)\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting python-mecab-ko (from g2pk->epitran)\n",
            "  Downloading python_mecab_ko-1.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->epitran) (2024.8.30)\n",
            "Collecting JPype1>=0.7.0 (from konlpy->g2pk->epitran)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy->g2pk->epitran) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->g2pk->epitran) (4.66.5)\n",
            "Collecting python-mecab-ko-dic (from python-mecab-ko->g2pk->epitran)\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy->g2pk->epitran) (24.1)\n",
            "Downloading epitran-1.25.1-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.1/184.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading panphon-0.21.2-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pK-0.9.4-py3-none-any.whl (27 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Downloading python_mecab_ko-1.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (577 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.1/577.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unicodecsv\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10745 sha256=7e40cf4f06ab6b478b7203ac26f3b37a95b7e5caa300886d8c67b229724bfc3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/ea/66/8e45247b09052a933eb1a680b7c64802298faba58aac9b346b\n",
            "Successfully built unicodecsv\n",
            "Installing collected packages: unicodecsv, python-mecab-ko-dic, munkres, jamo, python-mecab-ko, panphon, JPype1, konlpy, g2pk, epitran\n",
            "Successfully installed JPype1-1.5.0 epitran-1.25.1 g2pk-0.9.4 jamo-0.4.1 konlpy-0.6.0 munkres-1.1.4 panphon-0.21.2 python-mecab-ko-1.3.7 python-mecab-ko-dic-2.1.1.post2 unicodecsv-0.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqR6Klwc-UAH"
      },
      "source": [
        "## Import PyThaiNLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp"
      ],
      "metadata": {
        "id": "9IhnIXQJ-oDg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "R7CkITTf-UAH",
        "outputId": "33548fd7-81a9-4456-d88e-571209a76c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pythainlp\n",
        "\n",
        "pythainlp.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6gy4MLGIgp9"
      },
      "source": [
        "## Thai Characters\n",
        "\n",
        "PyThaiNLP provides some ready-to-use Thai character set (e.g. Thai consonants, vowels, tonemarks, symbols) as a string for convenience. There are also few utility functions to test if a string is in Thai or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GAvoeZg3Igp-",
        "outputId": "8d3c78d9-8527-478d-a7a9-b18f886f1ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮฤฦะัาำิีึืุูเแโใไๅํ็่้๊๋ฯฺๆ์ํ๎๏๚๛๐๑๒๓๔๕๖๗๘๙฿'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "pythainlp.thai_characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TFPtK_FL-UAI",
        "outputId": "671cecd8-bb46-4553-b140-192ae66dd986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(pythainlp.thai_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uPwx53A6IgqF",
        "outputId": "26a0c028-5cd7-494e-f847-e345e57c094c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "pythainlp.thai_consonants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e5-lZjsd-UAJ",
        "outputId": "1fe83f50-169d-49d3-829d-3706d18a3fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(pythainlp.thai_consonants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5UA7Hwy_IgqI",
        "outputId": "a321e749-e14d-4ed3-ae2e-92fdaff3b354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\"๔\" in pythainlp.thai_digits  # check if Thai digit \"4\" is in the character set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vFPqeB-UAJ"
      },
      "source": [
        "## Checking if a string contains Thai character or not, or how many"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t3NvXqYFIgqK",
        "outputId": "ff1e9354-4429-4ee5-e416-da753f4cdbb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import pythainlp.util\n",
        "\n",
        "pythainlp.util.isthai(\"ก\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sRzSQjugIgqM",
        "outputId": "61c45029-a4fa-49c5-b20e-701682ba9ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DP5yfJebIgqP",
        "outputId": "ab46afc0-1a60-4a86-c9a9-78a1c0d7b1dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pythainlp.util.isthai(\"(ก.พ.)\", ignore_chars=\".()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ภาษาระดับกึ่งทางการ\n"
      ],
      "metadata": {
        "id": "FxkLG5Av-BoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp import sent_tokenize\n",
        "from pythainlp.corpus.common import thai_words\n",
        "from pythainlp import Tokenizer\n",
        "from pythainlp.tokenize import subword_tokenize\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.tag import pos_tag\n",
        "from pythainlp.corpus import thai_stopwords"
      ],
      "metadata": {
        "id": "WDZtB1BND8m_"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Category มหาวิทยาลัย\n",
        "```\n",
        "1.สวัสดีค่ะอาจารย์ที่ปรึกษา\n",
        "2.นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\n",
        "3.ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\n",
        "4.นักศึกษาต้องการโน็ตบุ๊คในการทำงานหรือไม่\n",
        "5.ผมขอสอบถามเกี่ยวกับการเตรียมพร้อมในการสอบวิชาอาจาร์ยหน่อยครับ\n",
        "6.นักศึกษาควรเตรียมพร้อมสำหรับการสอบในหนึ่งสัปดาห์หน้า\n",
        "7.นักศึกษาสามารถใช้อินเตอร์เน็ตในการเรียนได้\n",
        "8.คุณคือหัวหน้า เขียนชื่อ-นามสกุลนักศึกษาที่ลาออกมาให้อาจารย์\n",
        "9.นักศึกษาหมดกำลังใจในการทำงาน\n",
        "10.อาจาร์ยที่ปรึกษาอนุมัติให้ทำงานตามข้อหัวนี้\n",
        "```"
      ],
      "metadata": {
        "id": "PN8cnBkOV-Ul"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VFPOHyZIgqh"
      },
      "source": [
        "###Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5P_YygrIgqm"
      },
      "source": [
        "Other algorithm can be chosen. We can also create a tokenizer with a custom dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXUxXlTIgqo"
      },
      "source": [
        "Default word tokenizer use a word list from `pythainlp.corpus.common.thai_words()`.\n",
        "We can get that list, add/remove words, and create new tokenizer from the modified list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SklPJ-DbIgqi"
      },
      "source": [
        "### Word\n",
        "Default word tokenizer (\"newmm\") use maximum matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"newmm (custom dictionary):\", custom_tokenizer.word_tokenize(text1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKvEDM3U-YGy",
        "outputId": "cef4f7d6-9705-4048-cc1b-74a840e63bb5"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "newmm (custom dictionary): ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "JEbY-MGCIgqi",
        "outputId": "b244cf8c-b3e1-4d02-e307-863e63660d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำแนะนำ', 'ได้', 'กับ', 'อาจารย์ที่ปรึกษา']\n",
            "custom dictionary : ['นักศึกษา', 'สามารถ', 'ติดต่อ', 'ขอ', 'คำแนะนำ', 'ได้', 'กับ', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ],
      "source": [
        "text2 = \"นักศึกษาสามารถติดต่อขอคำแนะนำได้กับอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text2))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"ขอขอบคุณอาจารย์สำหรับคำแนะนำเกี่ยวกับการเลือกวิชาเรียน\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc9PVhShepRM",
        "outputId": "3a7c06b1-c3d3-4f68-818a-688889bb8142"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['ขอ', 'ขอบคุณ', 'อาจารย์', 'สำหรับ', 'คำแนะนำ', 'เกี่ยวกับ', 'การ', 'เลือก', 'วิชา', 'เรียน']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text4 = \"นักศึกษาต้องการโน็ตบุ๊คในการทำงานหรือไม่\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text4))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"โน็ตบุ๊ค\")\n",
        "words.discard(\"การทำงาน\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary:\", custom_tokenizer.word_tokenize(text4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7EBXclqYM6k",
        "outputId": "9a2c878c-e3a8-4f71-c964-bdb4fd191d25"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['นักศึกษา', 'ต้องการ', 'โน', '็ต', 'บุ๊ค', 'ใน', 'การทำงาน', 'หรือไม่']\n",
            "custom dictionary: ['นักศึกษา', 'ต้องการ', 'โน็ตบุ๊ค', 'ใน', 'การ', 'ทำงาน', 'หรือไม่']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.tokenize import word_detokenize\n",
        "print(word_detokenize(['โน็', 'ตบุ๊ค']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfa4655-abd1-4f70-a540-aa97b23f815a",
        "id": "p7Q3qoEPYegy"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "โน็ตบุ๊ค\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Word Removal\n"
      ],
      "metadata": {
        "id": "lRuhGEg-O53A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c196df31-df55-4575-fe17-ba400da36252",
        "id": "JLpuvsxOO53A"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ย่อย', 'พวกนู้น', 'เป็นเพราะว่า', 'พวกกู', 'สิ่งใด', 'เปลี่ยน', 'ทุกเมื่อ', 'เริ่ม', 'ร่วม', 'แต่ละ', 'เป็นเพื่อ', 'กระทั่ง', 'เกือบจะ', 'ก่อน', 'ตั้ง', 'เหล่านี้', 'เพิ่งจะ', 'ทาง', 'ทุกอย่าง', 'แต่ต้อง', 'สำคัญ', 'ผู้', 'เป็นอันๆ', 'พอกัน', 'เช่นเดียวกับ', 'วัน', 'ทำไม', 'ที่จริง', 'เสมือนกับ', 'อันได้แก่', 'ปรากฏว่า', 'เพิ่มเติม', 'นัก', 'ดังกับว่า', 'เมื่อคืน', 'เป็นด้วย', 'จง', 'ทุกที', 'ถ้าหาก', 'หารือ', 'เช่นเดียวกัน', 'ใหญ่โต', 'เช่นนั้น', 'พร้อมด้วย', 'ทั้งนี้', 'เพียงไหน', 'ด้วยประการฉะนี้', 'เสียแล้ว', 'แต่ก็', 'เป็นที่สุด', 'เสียจน', 'นาง', 'ด้วยที่', 'นอกจากนั้น', 'จน', 'ปรับ', 'เพียงแค่', 'เสร็จแล้ว', 'ข้าง', 'นี้แหล่', 'ทั้งตัว', 'ใหญ่', 'ภายภาคหน้า', 'ยังแต่', 'จากนี้ไป', 'ทำๆ', 'พอเพียง', 'ทั้งนั้นเพราะ', 'กล่าวคือ', 'ตลอดถึง', 'เหตุนั้น', 'แห่งนี้', 'นี่เอง', 'ที่ว่า', 'ด้วยว่า', 'นาน', 'เช่นเคย', 'สิ่งไหน', 'เมื่อเช้า', 'จนบัดนี้', 'กัน', 'เสร็จสิ้น', 'รวมกัน', 'หากว่า', 'ทีเดียว', 'พวกเธอ', 'นอกนั้น', 'หน่อย', 'นอกจาก', 'แค่นี้', 'ด้วยเหตุที่', 'กำลัง', 'ส่วนน้อย', 'ซึ่งได้แก่', 'สู่', 'ซะจน', 'พวกกัน', 'เหลือเกิน', 'คราว', 'เกี่ยวข้อง', 'ยก', 'ดั่งกับ', 'ภายนอก', 'จวน', 'เห็นควร', '\\ufeffๆ', 'ที่ๆ', 'ทีละ', 'สิ่ง', 'คะ', 'เรื่อยๆ', 'ไว้', 'ไหน', 'พอที่', 'ไม่เป็นไร', 'คราใด', 'อย่างละ', 'พร้อม', 'ที่นี้', 'เมื่อวันวาน', 'เนี่ย', 'เสียนั่น', 'ช่วงต่อไป', 'จัดงาน', 'พวกที่', 'จ้ะ', 'เท่าที่', 'ใคร่จะ', 'ซะ', 'ปรากฏ', 'กว่า', 'ช่วงที่', 'ด้วยเหตุนั้น', 'มั้ยนะ', 'ไฉน', 'อันจะ', 'เรียก', 'เอ็ง', 'ยัง', 'ให้', 'ดังเก่า', 'ก็ตาม', 'ดังกล่าว', 'ทีเถอะ', 'ทั้งที', 'เต็มไปหมด', 'ถึง', 'ส่วนดี', 'ยังงี้', 'ขวาง', 'อยู่', 'ครบ', 'นำพา', 'แต่ว่า', 'แค่นั้น', 'จนถึง', 'จวนจะ', 'ให้ดี', 'ข้างล่าง', 'คราวนั้น', 'เช่นดังว่า', 'มิได้', 'ล้วนจน', 'พวกมัน', 'ไม่ใช่', 'ระหว่าง', 'เพื่อว่า', 'เพียงไร', 'เยอะ', 'นั้นๆ', 'พอเหมาะ', 'หาความ', 'ล้วนแต่', 'ถึงจะ', 'จัดแจง', 'เสียก่อน', 'เชื่อมั่น', 'มอง', 'ครั้งหลังสุด', 'เดียวกัน', 'เขียน', 'ตลอดทั่วทั้ง', 'เช่นนี้', 'แสดง', 'ผล', 'มี', 'เกือบๆ', 'อย่างไร', 'คราวก่อน', 'ยิ่ง', 'เท่ากับ', 'จัดทำ', 'กว้างๆ', 'ซึ่งก็คือ', 'เก็บ', 'สั้น', 'จริงๆจังๆ', 'พอจะ', 'บ้าง', 'หน', 'นะ', 'หาก', 'จนขณะนี้', 'เมื่อเย็น', 'มัน', 'บางที', 'อย่างนี้', 'มั้ยเนี่ย', 'ครั้งหนึ่ง', 'นั่นไง', 'จนแม้น', 'จรดกับ', 'ที่ไหน', 'บัดเดี๋ยวนี้', 'อาจเป็นด้วย', 'แท้', 'เผื่อจะ', 'บางขณะ', 'ขณะเดียวกัน', 'ครั้งกระนั้น', 'เสียจนถึง', 'เป็นแต่เพียง', 'พวกฉัน', 'คราวโน้น', 'ยืนยัน', 'ภาค', 'เป็นต้นมา', 'จากนั้น', 'เสียด้วย', 'เลย', 'หลังจาก', 'เต็มๆ', 'ทีใด', 'ยังโง้น', 'พื้นๆ', 'กลุ่มก้อน', 'แต่เดิม', 'คราวละ', 'น่า', 'ทำไร', 'ออก', 'แห่งโน้น', 'แค่ว่า', 'กลับ', 'แห่ง', 'ไม่ค่อย', 'ยิ่งขึ้น', 'ครบครัน', 'หนอ', 'ทุกทาง', 'สมัยโน้น', 'เสร็จ', 'ตรงๆ', 'รวมทั้ง', 'ทุกครา', 'คราหนึ่ง', 'ไม่ค่อยจะ', 'ยังจะ', 'ได้ที่', 'ปัจจุบัน', 'หรือไม่', 'ทําให้', 'ข้า', 'อันเนื่องมาจาก', 'ดัง', 'นั่น', 'หรือไง', 'อีก', 'ตาม', 'กันเอง', 'พบว่า', 'เอา', 'เพียงใด', 'ถูก', 'ยังไง', 'อย่างไหน', 'อาจเป็น', 'นี่ไง', 'ช่วงแรก', 'พา', 'ที่ละ', 'ภายใน', 'ใน', 'นิด', 'ฉะนั้น', 'เผื่อว่า', 'อย่างดี', 'พยายาม', 'ที่แล้ว', 'ช้า', 'น้อยๆ', 'ซึ่งๆ', 'เช่นดังที่', 'ยิ่งเมื่อ', 'สบาย', 'ราย', 'แต่ก่อน', 'บ่อย', 'เข้า', 'ซึ่งก็', 'จัดตั้ง', 'ทั้งมวล', 'เสียนั่นเอง', 'ทันที', 'ก็ดี', 'ทำงาน', 'ช่วงถัดไป', 'ให้ไป', 'ครา', 'ทั้งนั้นด้วย', 'โต', 'ณ', 'พึง', 'เขา', 'ภาคฯ', 'พึ่ง', 'ตลอดปี', 'ตลอดทั่ว', 'คำ', 'ของ', 'นั้น', 'ฯลฯ', 'เราๆ', 'พร้อมกัน', 'เห็นแก่', 'เพราะ', 'เช่นที่ว่า', 'ก็แค่', 'นิดหน่อย', 'พอแล้ว', 'ขณะ', 'ยังคง', 'ประการ', 'ประการฉะนี้', 'แยะ', 'อันใด', 'จนตลอด', 'เรื่อย', 'เปิดเผย', 'เช่นก่อน', 'เช่นดังก่อน', 'ถึงแก่', 'นี่แน่ะ', 'ทุกครั้ง', 'ก่อนหน้านี้', 'ครัน', 'ยิ่งจะ', 'หนอย', 'เมื่อวาน', 'ในช่วง', 'แต่เพียง', 'กำลังจะ', 'เมื่อไหร่', 'เมื่อ', 'กลุ่มๆ', 'ก็จะ', 'เสมือนว่า', 'ฯ', 'ทั้งๆ', 'กันเถอะ', 'เสร็จสมบูรณ์', 'ทุก', 'เนื่องจาก', 'แค่เพียง', 'แม้', 'ทำให้', 'เข้าใจ', 'ภายหลัง', 'จำพวก', 'ยาวนาน', 'ระยะๆ', 'เพื่อ', 'รวมถึง', 'เพื่อที่จะ', 'บางๆ', 'จับ', 'หลาย', 'เพียงแต่', 'ผ่าน', 'ด้วยเหตุนี้', 'ก็คือ', 'อย่างไรก็ได้', 'ทั้งที่', 'การ', 'สมัยก่อน', 'แต่ถ้า', 'อย่างน้อย', 'ค่อนมาทาง', 'เมื่อครั้งก่อน', 'ช้านาน', 'ก่อนหน้า', 'เกิด', 'ตลอดจน', 'หนึ่ง', 'ทั้งหมด', 'เรา', 'มั๊ย', 'เห็นว่า', 'เท่ากัน', 'บางกว่า', 'น่ะ', 'มีแต่', 'สั้นๆ', 'อันที่จะ', 'เหล่านั้น', 'อนึ่ง', 'เหตุไร', 'ระยะ', 'จากนี้', 'กลุ่ม', 'ละ', 'นิดๆ', 'อดีต', 'ให้แด่', 'นับจากนี้', 'พอควร', 'ดังกับ', 'เป็นต้น', 'ด้วยเพราะ', 'เฉกเช่น', 'ทํา', 'ที่สุด', 'จด', 'ซึ่ง', 'นำ', 'สมัยนี้', 'อันไหน', 'อย่างเดียว', 'พวกคุณ', 'เมื่อครั้ง', 'พวกท่าน', 'รวมๆ', 'เร็ว', 'กระนั้น', 'อย่างยิ่ง', 'เมื่อคราวก่อน', 'เกี่ยวกัน', 'มักจะ', 'สิ้น', 'ด้วยเหตุว่า', 'นี่แหละ', 'ค่อย', 'พอสม', 'เกิน', 'ชาว', 'นั่นเอง', 'ทั้งเป็น', 'เพราะว่า', 'เพื่อให้', 'หาใช่', 'ทุกๆ', 'อย่างมาก', 'จะ', 'เชื่อถือ', 'รับรอง', 'ซะก่อน', 'เป็นเพียงว่า', 'อย่างๆ', 'บาง', 'จึงจะ', 'ได้แต่', 'มาก', 'ดังเคย', 'รวมด้วย', 'เยอะๆ', 'ตนฯ', 'เพราะฉะนั้น', 'บอก', 'เมื่อคราวที่', 'อย่างที่', 'ครั้งละ', 'ตลอดไป', 'ที่ใด', 'พอๆ', 'ขณะนี้', 'ฝ่าย', 'เชื่อ', 'จริงจัง', 'เคยๆ', 'ภายหน้า', 'หรือไร', 'ต่างก็', 'และ', 'แค่', 'ซะจนถึง', 'เพียง', 'ที่นั้น', 'จัดการ', 'ตนเอง', 'แบบ', 'เสีย', 'เช่น', 'สมัย', 'แต่ทว่า', 'ยืนยง', 'ครั้งก่อน', 'ส่วนใหญ่', 'นอกจากที่', 'เมื่อใด', 'แล้วเสร็จ', 'อย่าง', 'ทรง', 'ช่วงหลัง', 'นับแต่ที่', 'แหละ', 'รึ', 'โดย', 'แม้นว่า', 'ใหญ่ๆ', 'นับตั้งแต่', 'ที่แท้จริง', 'ตลอดเวลา', 'ค่อน', 'ทุกที่', 'ไร', 'ส่วนใด', 'พร้อมกับ', 'นี่', 'หมดสิ้น', 'มิใช่', 'หรือยัง', 'ยิ่งใหญ่', 'ไม่', 'ทุกวันนี้', 'เป็นอาทิ', 'ข้าฯ', 'ที่', 'แต่นั้น', 'ทุกแห่ง', 'ก็', 'ได้รับ', 'เป็นอันมาก', 'รวด', 'เสียนี่', 'ช่วงระหว่าง', 'แล้วกัน', 'สืบเนื่อง', 'ทันใดนั้น', 'ได้แก่', 'ค่อนข้างจะ', 'ให้แก่', 'อื่น', 'จำเป็น', 'ต่างหาก', 'ตลอดมา', 'สมัยนั้น', 'มั้ย', 'ลง', 'จริง', 'เหลือ', 'ตลอดวัน', 'ไหนๆ', 'เฉย', 'เท่าใด', 'ครั้งไหน', 'ช่วงก่อน', 'เป็นอันว่า', 'ยืนยาว', 'ทั้งปวง', 'ที่แท้', 'ทันทีทันใด', 'กู', 'ไป', 'แล้วแต่', 'คราวหนึ่ง', 'ทุกหน', 'บ่อยกว่า', 'ถ้าจะ', 'ถึงเมื่อไร', 'นางสาว', 'นู้น', 'ครบถ้วน', 'ร่วมกัน', 'ยิ่งขึ้นไป', 'มุ่งเน้น', 'แห่งใด', 'สิ่งนั้น', 'ในระหว่าง', 'เสียจนกระทั่ง', 'แล้ว', 'ทีๆ', 'ใกล้', 'อันที่', 'ต้อง', 'บางแห่ง', 'หากแม้น', 'ใกล้ๆ', 'วันไหน', 'น้อยกว่า', 'ครานั้น', 'แห่งนั้น', 'ขณะนั้น', 'อย่างโน้น', 'แรก', 'ส่ง', 'เมื่อนี้', 'นู่น', 'แค่จะ', 'อย่างนั้น', 'ครั้งๆ', 'เช่นนั้นเอง', 'เนี่ยเอง', 'ตามที่', 'บ่อยๆ', 'ข้างบน', 'กันไหม', 'เป็นเพราะ', 'แท้จริง', 'ใช่', 'พอ', 'ปฏิบัติ', 'ก่อนๆ', 'ต่างๆ', 'เกินๆ', 'ใช่ไหม', 'ยังงั้น', 'ต่าง', 'เกี่ยวเนื่อง', 'นั่นแหละ', 'แม้กระทั่ง', 'แก่', 'คราวที่', 'ใคร', 'ได้', 'กันและกัน', 'ยอม', 'ขณะใดๆ', 'ข้างเคียง', 'บน', 'เป็นอัน', 'จังๆ', 'จวบกับ', 'คราวนี้', 'ขณะใด', 'หากแม้', 'วันนั้น', 'หรือเปล่า', 'จู่ๆ', 'แต่ไหน', 'ทุกคน', 'ขั้น', 'แต่เมื่อ', 'คงจะ', 'อย่างใด', 'จ้า', 'สามารถ', 'ก็ได้', 'เน้น', 'เอง', 'จึง', 'ไป่', 'ทุกคราว', 'ภายภาค', 'บอกว่า', 'กันดีไหม', 'ตลอดระยะเวลา', 'มุ่งหมาย', 'ใต้', 'เท่านี้', 'อาจจะ', 'คล้ายกัน', 'ข้าพเจ้า', 'พร้อมทั้ง', 'เหตุนี้', 'เถิด', 'ตามๆ', 'เท่า', 'สูงสุด', 'ตลอดกาล', 'เมื่อนั้น', 'ค่อยไปทาง', 'ใหม่ๆ', 'นับแต่นี้', 'จนเมื่อ', 'เมื่อไร', 'วันใด', 'คราวหน้า', 'ย่อม', 'ทั่ว', 'ทัน', 'ยิ่งกว่า', 'ครั้ง', 'เปิด', 'บัดนั้น', 'ส่วนนั้น', 'รวม', 'ต่อกัน', 'ด้วยกัน', 'กว้างขวาง', 'ประการใด', 'ถ้า', 'ทีไร', 'ส่วน', 'ควร', 'ถูกต้อง', 'นอกจากว่า', 'ถึงอย่างไร', 'มา', 'นอกเหนือจาก', 'ช่วงท้าย', 'ตลอดศก', 'คราวใด', 'เช่นใด', 'พวกแก', 'นอกจากนี้', 'พวกนั้น', 'ล่าสุด', 'สูง', 'ตน', 'ขาด', 'เยอะแยะ', 'กล่าว', 'ครั้งที่', 'ที', 'พวกมึง', 'เท่าไร', 'เผื่อที่', 'เป็นๆ', 'กระทำ', 'ในที่', 'จวนเจียน', 'ด้วยเหมือนกัน', 'ยาว', 'จริงๆ', 'เหตุผล', 'คุณๆ', 'ส่วนมาก', 'เพียงพอ', 'บางที่', 'ช่วงๆ', 'ความ', 'พอตัว', 'ดั่งเคย', 'ช่วงหน้า', 'คล้ายกับว่า', 'ตลอดทั่วถึง', 'ทุกสิ่ง', 'รับ', 'โตๆ', 'นับแต่', 'แม้ว่า', 'เกี่ยวๆ', 'แม้แต่', 'เมื่อก่อน', 'ถึงบัดนั้น', 'เช่นที่', 'ยอมรับ', 'นักๆ', 'คราวหลัง', 'คราที่', 'รือว่า', 'พูด', 'ภายใต้', 'ครั้งครา', 'ง่ายๆ', 'รึว่า', 'พอดี', 'ช่วงนี้', 'หลัง', 'เพียงเพราะ', 'ดั่ง', 'ผ่านๆ', 'เช่นกัน', 'ได้มา', 'น่าจะ', 'กันนะ', 'มั้ยนั่น', 'เป็นต้นไป', 'ดั่งเก่า', 'ว่า', 'มั้ยล่ะ', 'สูงๆ', 'เปลี่ยนแปลง', 'ก็ตามที', 'กระผม', 'นี้', 'ประการหนึ่ง', 'ครั้งหลัง', 'เห็นจะ', 'แต่ที่', 'ใหม่', 'ครานี้', 'เร็วๆ', 'จนกว่า', 'ล้วน', 'ใคร่', 'แต่ไร', 'เช่นดัง', 'เธอ', 'ครั้งคราว', 'ด้วย', 'เห็น', 'พวกเขา', 'ผิดๆ', 'มิฉะนั้น', 'กันดีกว่า', 'ขณะที่', 'พร้อมที่', 'นานๆ', 'ตลอดกาลนาน', 'จวบจน', 'สุด', 'ค่ะ', 'หากแม้นว่า', 'จะได้', 'นอกเหนือ', 'กับ', 'ครั้งนี้', 'นอก', 'พร้อมเพียง', 'เรียบ', 'พวกโน้น', 'ซะจนกระทั่ง', 'สิ้นกาลนาน', 'กำหนด', 'ทุกอัน', 'จนทั่ว', 'อะไร', 'ฝ่ายใด', 'เหตุ', 'ยิ่งจน', 'บัดดล', 'จัด', 'ข้างต้น', 'ดั่งกับว่า', 'ช่วงนั้น', 'สูงกว่า', 'ผิด', 'นับจากนั้น', 'คล้ายกับ', 'คล้ายว่า', 'ขณะหนึ่ง', 'ฉะนี้', 'นับแต่นั้น', 'อื่นๆ', 'บางคราว', 'ค่อยๆ', 'มองว่า', 'คงอยู่', 'นี่นา', 'ง่าย', 'จึงเป็น', 'รือ', 'อัน', 'พวกนี้', 'แต่', 'ยาก', 'คิด', 'จวบ', 'แก', 'เป็นการ', 'วันนี้', 'ถือว่า', 'แต่จะ', 'เป็นที', 'ตั้งแต่', 'ด้วยเหตุเพราะ', 'อย่างหนึ่ง', 'คราไหน', 'พวก', 'เท่านั้น', 'ข้างๆ', 'ยกให้', 'ตามแต่', 'เล่าว่า', 'จัง', 'เพียงเพื่อ', 'ครั้งนั้น', 'ประสบ', 'ไหม', 'เพื่อที่', 'ขวางๆ', 'คล้าย', 'เป็นเพียง', 'จำ', 'น้อย', 'แต่อย่างใด', 'ๆ', 'ปิด', 'ถึงแม้ว่า', 'บางครั้ง', 'แสดงว่า', 'นาย', 'เป็น', 'มากกว่า', 'จัดให้', 'บางครา', 'สูงส่ง', 'คง', 'อันๆ', 'ถึงบัดนี้', 'ครั้งใด', 'นี้เอง', 'ช้าๆ', 'ในเมื่อ', 'แก้ไข', 'ถือ', 'ซึ่งกันและกัน', 'ทั้ง', 'ร่วมมือ', 'ถึงแม้', 'ด้าน', 'เผื่อ', 'มึง', 'อย่างเช่น', 'จรด', 'อาจ', 'เชื่อว่า', 'ตรง', 'ยืนนาน', 'มัก', 'พอที', 'ช่วง', 'ค่อนข้าง', 'หรือ', 'เล็กน้อย', 'คือ', 'เป็นที่', 'ถูกๆ', 'ร่วมด้วย', 'ไม่ว่า', 'นับ', 'ถึงเมื่อ', 'ส่วนเกิน', 'เต็มไปด้วย', 'พอสมควร', 'ครับ', 'เล็กๆ', 'ใครๆ', 'ฯล', 'ทุกตัว', 'ที่ได้', 'ทั้งนั้น', 'คราวๆ', 'ต่อ', 'บัดนี้', 'เฉยๆ', 'ประมาณ', 'บอกแล้ว', 'เช่นไร', 'ภาย', 'เป็นดัง', 'ยิ่งนัก', 'คล้ายกันกับ', 'เดียว', 'ให้มา', 'นั่นเป็น', 'เพิ่ม', 'พบ', 'จาก', 'ไง', 'เสียนี่กระไร', 'ทุกวัน', 'ยิ่งแล้ว', 'มันๆ', 'จนกระทั่ง', 'จ๊ะ', 'สําหรับ', 'คราวไหน', 'อย่างไรก็', 'ซึ่งกัน', 'ทั้งสิ้น', 'เท่าไหร่', 'คุณ', 'นำมา', 'ประกอบ', 'ใดๆ', 'นํา', 'บ่อยครั้ง', 'ไกลๆ', 'มากมาย', 'แยะๆ', 'ส่วนที่', 'ก็ตามแต่', 'ทั้งหลาย', 'ขอ', 'แห่งไหน', 'หมดกัน', 'สิ่งนี้', 'ถึงแม้จะ', 'ช่วย', 'เกี่ยวกับ', 'เฉพาะ', 'ขึ้น', 'เถอะ', 'เกือบ', 'ตลอด', 'รวดเร็ว', 'ก็แล้วแต่', 'ไม่ค่อยเป็น', 'ก็ต่อเมื่อ', 'ด้วยเช่นกัน', 'ผู้ใด', 'แค่ไหน', 'เสียยิ่งนัก', 'จนแม้', 'ที่แห่งนั้น', 'ที่ซึ่ง', 'เล็ก', 'เสียยิ่ง', 'ฉัน', 'ทุกชิ้น', 'นั้นไว', 'เช่นดังเก่า', 'ถึงเมื่อใด', 'เหล่า', 'เพิ่ง', 'ตลอดทั้ง', 'ทว่า', 'มุ่ง', 'จัดหา', 'ทั้งคน', 'ตามด้วย', 'อันละ', 'หมด', 'อย่างไรเสีย', 'กว้าง', 'เป็นแต่', 'สุดๆ', 'อันที่จริง', 'คิดว่า', 'มิ', 'ไกล', 'เช่นเมื่อ', 'เช่นที่เคย', 'เมื่อคราว', 'จ๋า', 'เสร็จกัน', 'อยาก', 'ส่วนด้อย'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "# ตัดคำ\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text1))\n",
        "words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "# ดึงรายการ stop words ในภาษาไทย\n",
        "stopwords = thai_stopwords()\n",
        "# แปลง stop words เป็นเซ็ต (set) สำหรับการเพิ่ม/ลบ\n",
        "\n",
        "stopwords = set(stopwords)\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4074ba8-2545-4e1c-91a0-fb8e19c3a557",
        "id": "FrLPcE7cO53B"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "custom dictionary : ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part of Speech tagging"
      ],
      "metadata": {
        "id": "B9hosQNsPiw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
        "pos_tag(words)"
      ],
      "metadata": {
        "outputId": "38a278e8-a306-4588-99c8-8b676c152abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNUCg1s3Piw9"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('สวัสดี', 'NCMN'), ('อาจารย์', 'NCMN'), ('ที่ปรึกษา', 'NCMN')]"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_tsl_grammar(words):\n",
        "    # ตัวอย่างกฎพื้นฐานสำหรับ TSL\n",
        "    words = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
        "    pos_tag(words)\n",
        "\n",
        "    expected_order = ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา'] # รูปแบบที่คาดหวัง\n",
        "    tags = pos_tag(words)  # รับ POS tags สำหรับคำ\n",
        "    print(\"POS Tags:\", tags)\n",
        "\n",
        "    # ตรวจสอบการเรียงลำดับพื้นฐานตามกฎที่กำหนดเอง\n",
        "    for i, word in enumerate(words):\n",
        "        if word in ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']:  # คำบอกเวลา\n",
        "            if i != 0:  # คำบอกเวลาควรอยู่ที่ตำแหน่งแรก\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# ใช้ฟังก์ชันเพื่อตรวจสอบ\n",
        "is_correct_order = check_tsl_grammar(words)\n",
        "print(\"Is correct order:\", is_correct_order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FqIUNUURcDJ",
        "outputId": "37b77015-bf38-40df-d49f-d87d6b727ab9"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('สวัสดี', 'NCMN'), ('อาจารย์', 'NCMN'), ('ที่ปรึกษา', 'NCMN')]\n",
            "Is correct order: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The reordering of sentences based on Indian Sign Language grammar rules."
      ],
      "metadata": {
        "id": "amtvFL9BPiw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization: Reduce each word to its base form, depending on its POS tag."
      ],
      "metadata": {
        "id": "oLM9FnsfPiw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "\n",
        "print(get_lemma(\"ที่ปรึกษา\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49088714-1121-4eb8-fe18-b2896925acd1",
        "id": "E-x2DMApPiw-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ปรึกษา\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# สร้าง custom dictionary\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "\n",
        "# ใช้ custom tokenizer\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "print(\"custom dictionary:\", tokenized_words)\n",
        "\n",
        "# ดึง stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in tokenized_words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", tokenized_words)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in filtered_words]\n",
        "\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7663cb7-01fd-425c-fb0d-ea3834b5223d",
        "id": "-SzUZngcPiw-"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Original words: ['สวัสดี', 'ค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Filtered words: ['สวัสดี', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Lemmatized words: ['สวัสดี', 'อาจารย์', 'ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Category ที่ทำงาน\n",
        "```\n",
        "11.เคยใช้กูเกิ้ลโครมเพื่อแชร์หรือไฟล์ในกูเกิ้ลไดร์ฟไหม\n",
        "12.ตอบกลับในแอปพลิเคชั่นไลน์เพื่ออนุมัติหน้าที่ที่เห็นด้วย\n",
        "13.ขอยืมเมาส์บลูทูธและแป้นพิมพ์ของเธอได้มั้ย\n",
        "14.ทักทายเพื่อนที่เป็นสมาชิกใหม่ในองค์กรคมนาคม\n",
        "15.ประสบการณ์การใช้หูฟังไร้สายช่วยลดความเพลียได้\n",
        "16.เห็นด้วยกับระเบียบใหม่ที่ให้อนุมัติได้ง่ายขึ้น\n",
        "17.อย่าดูถูกคนที่มีอายุน้อยและประสบการณ์ที่น้อยกว่า\n",
        "18.หมดแรงเพราะหน้าที่นี้มีการทำงานหนักมาก\n",
        "19.ถ้าคุณแนบเอกสารในกูเกิ้ลไดร์ฟแล้ว ช่วยตอบกลับอีเมลด้วย\n",
        "20.สามารถเขียนเว็บไซต์จากโปรแกรมคอมพิวเตอร์\n",
        "```\n"
      ],
      "metadata": {
        "id": "uQ9hn2tjOXP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenization"
      ],
      "metadata": {
        "id": "NTUccqMaOLde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text))"
      ],
      "metadata": {
        "id": "JnPHAqegLPPJ",
        "outputId": "33030f20-dde3-4423-d513-2ac78c90cde0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['เคย', 'ใช้', 'กูเกิ้ล', 'โครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ล', 'ไดร์', 'ฟ', 'ไหม']\n",
            "custom dictionary : ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Word Removal\n"
      ],
      "metadata": {
        "id": "Tc9PTjMLXP7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dny6xk9fzX2c",
        "outputId": "e57fde83-72a9-426a-b850-6239d8924f2e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozenset({'ค่อน', 'ย่อย', 'ทุกที่', 'ไร', 'พวกนู้น', 'เป็นเพราะว่า', 'ส่วนใด', 'พวกกู', 'นี่', 'สิ่งใด', 'เปลี่ยน', 'ทุกเมื่อ', 'เริ่ม', 'หมดสิ้น', 'มิใช่', 'ร่วม', 'พร้อมกับ', 'แต่ละ', 'เป็นเพื่อ', 'กระทั่ง', 'หรือยัง', 'ก่อน', 'ตั้ง', 'เกือบจะ', 'ยิ่งใหญ่', 'ไม่', 'เหล่านี้', 'ทุกวันนี้', 'เป็นอาทิ', 'ข้าฯ', 'ทาง', 'เพิ่งจะ', 'ที่', 'แต่นั้น', 'ทุกแห่ง', 'ก็', 'ได้รับ', 'สำคัญ', 'แต่ต้อง', 'ทุกอย่าง', 'ผู้', 'เป็นอันๆ', 'พอกัน', 'เป็นอันมาก', 'เช่นเดียวกับ', 'รวด', 'วัน', 'ทำไม', 'ที่จริง', 'เสียนี่', 'เสมือนกับ', 'อันได้แก่', 'ช่วงระหว่าง', 'ปรากฏว่า', 'แล้วกัน', 'สืบเนื่อง', 'ทันใดนั้น', 'เพิ่มเติม', 'นัก', 'ได้แก่', 'ดังกับว่า', 'ค่อนข้างจะ', 'ให้แก่', 'เคย', 'อื่น', 'เมื่อคืน', 'จำเป็น', 'เป็นด้วย', 'ต่างหาก', 'ตลอดมา', 'สมัยนั้น', 'มั้ย', 'จง', 'ลง', 'ทุกที', 'จริง', 'หารือ', 'ถ้าหาก', 'เช่นเดียวกัน', 'ใหญ่โต', 'เช่นนั้น', 'พร้อมด้วย', 'ทั้งนี้', 'เหลือ', 'ตลอดวัน', 'ไหนๆ', 'เพียงไหน', 'ด้วยประการฉะนี้', 'เฉย', 'เสียแล้ว', 'เท่าใด', 'แต่ก็', 'เป็นที่สุด', 'เสียจน', 'นาง', 'ครั้งไหน', 'ด้วยที่', 'ช่วงก่อน', 'นอกจากนั้น', 'เป็นอันว่า', 'จน', 'ยืนยาว', 'ปรับ', 'ทั้งปวง', 'เพียงแค่', 'ข้าง', 'ที่แท้', 'นี้แหล่', 'เสร็จแล้ว', 'ทันทีทันใด', 'ทั้งตัว', 'กู', 'ไป', 'ใหญ่', 'แล้วแต่', 'ภายภาคหน้า', 'คราวหนึ่ง', 'ยังแต่', 'จากนี้ไป', 'ทุกหน', 'บ่อยกว่า', 'ทำๆ', 'ถ้าจะ', 'พอเพียง', 'ทั้งนั้นเพราะ', 'ถึงเมื่อไร', 'กล่าวคือ', 'ตลอดถึง', 'เหตุนั้น', 'แห่งนี้', 'นางสาว', 'นู้น', 'ที่ว่า', 'นี่เอง', 'ครบถ้วน', 'นาน', 'ด้วยว่า', 'เช่นเคย', 'ร่วมกัน', 'สิ่งไหน', 'ยิ่งขึ้นไป', 'มุ่งเน้น', 'แห่งใด', 'เมื่อเช้า', 'สิ่งนั้น', 'ในระหว่าง', 'จนบัดนี้', 'เสียจนกระทั่ง', 'กัน', 'แล้ว', 'ทีๆ', 'ใกล้', 'อันที่', 'ต้อง', 'รวมกัน', 'หากว่า', 'บางแห่ง', 'ใกล้ๆ', 'หากแม้น', 'เสร็จสิ้น', 'วันไหน', 'น้อยกว่า', 'ครานั้น', 'ทีเดียว', 'แห่งนั้น', 'พวกเธอ', 'นอกนั้น', 'หน่อย', 'ขณะนั้น', 'อย่างโน้น', 'นอกจาก', 'แรก', 'แค่นี้', 'ด้วยเหตุที่', 'ส่ง', 'เมื่อนี้', 'นู่น', 'แค่จะ', 'อย่างนั้น', 'กำลัง', 'ส่วนน้อย', 'ซึ่งได้แก่', 'สู่', 'ครั้งๆ', 'ซะจน', 'พวกกัน', 'เนี่ยเอง', 'คราว', 'เหลือเกิน', 'ยก', 'เกี่ยวข้อง', 'เช่นนั้นเอง', 'ดั่งกับ', 'ภายนอก', 'ตามที่', 'จวน', 'บ่อยๆ', '\\ufeffๆ', 'เห็นควร', 'ข้างบน', 'กันไหม', 'ที่ๆ', 'ทีละ', 'สิ่ง', 'แท้จริง', 'ใช่', 'เป็นเพราะ', 'คะ', 'พอ', 'ปฏิบัติ', 'เรื่อยๆ', 'ไว้', 'ก่อนๆ', 'ไหน', 'ต่างๆ', 'เกินๆ', 'ใช่ไหม', 'ต่าง', 'ยังงั้น', 'นั่นแหละ', 'เกี่ยวเนื่อง', 'พอที่', 'ไม่เป็นไร', 'คราใด', 'อย่างละ', 'แม้กระทั่ง', 'พร้อม', 'ที่นี้', 'เมื่อวันวาน', 'แก่', 'เนี่ย', 'เสียนั่น', 'คราวที่', 'ใคร', 'ได้', 'ช่วงต่อไป', 'กันและกัน', 'จัดงาน', 'พวกที่', 'ยอม', 'ขณะใดๆ', 'ข้างเคียง', 'บน', 'เป็นอัน', 'จ้ะ', 'จังๆ', 'จวบกับ', 'เท่าที่', 'ใคร่จะ', 'ซะ', 'ปรากฏ', 'คราวนี้', 'กว่า', 'ขณะใด', 'หากแม้', 'วันนั้น', 'ช่วงที่', 'หรือเปล่า', 'ด้วยเหตุนั้น', 'จู่ๆ', 'แต่ไหน', 'ทุกคน', 'มั้ยนะ', 'ไฉน', 'ขั้น', 'แต่เมื่อ', 'คงจะ', 'อย่างใด', 'อันจะ', 'จ้า', 'สามารถ', 'ก็ได้', 'เน้น', 'เอง', 'จึง', 'ไป่', 'ทุกคราว', 'เรียก', 'เอ็ง', 'ยัง', 'ให้', 'ภายภาค', 'ดังเก่า', 'ก็ตาม', 'บอกว่า', 'กันดีไหม', 'ดังกล่าว', 'ตลอดระยะเวลา', 'ทีเถอะ', 'มุ่งหมาย', 'ใต้', 'ทั้งที', 'เท่านี้', 'อาจจะ', 'เต็มไปหมด', 'ถึง', 'คล้ายกัน', 'ส่วนดี', 'ยังงี้', 'ขวาง', 'ข้าพเจ้า', 'พร้อมทั้ง', 'อยู่', 'เหตุนี้', 'เถิด', 'ครบ', 'ตามๆ', 'นำพา', 'เท่า', 'สูงสุด', 'แต่ว่า', 'ตลอดกาล', 'เมื่อนั้น', 'แค่นั้น', 'จนถึง', 'จวนจะ', 'ให้ดี', 'ข้างล่าง', 'คราวนั้น', 'ค่อยไปทาง', 'เช่นดังว่า', 'มิได้', 'ใหม่ๆ', 'ล้วนจน', 'พวกมัน', 'ไม่ใช่', 'ระหว่าง', 'เพื่อว่า', 'เพียงไร', 'นับแต่นี้', 'จนเมื่อ', 'เมื่อไร', 'เยอะ', 'วันใด', 'คราวหน้า', 'นั้นๆ', 'ย่อม', 'พอเหมาะ', 'ทั่ว', 'หาความ', 'ทัน', 'ล้วนแต่', 'ถึงจะ', 'จัดแจง', 'ยิ่งกว่า', 'เสียก่อน', 'ครั้ง', 'เปิด', 'บัดนั้น', 'ส่วนนั้น', 'เชื่อมั่น', 'รวม', 'ต่อกัน', 'มอง', 'ครั้งหลังสุด', 'ด้วยกัน', 'กว้างขวาง', 'ประการใด', 'เดียวกัน', 'ถ้า', 'เขียน', 'ตลอดทั่วทั้ง', 'ทีไร', 'ส่วน', 'ควร', 'ถูกต้อง', 'แสดง', 'ผล', 'มี', 'เกือบๆ', 'อย่างไร', 'เช่นนี้', 'นอกจากว่า', 'ถึงอย่างไร', 'คราวก่อน', 'มา', 'ยิ่ง', 'นอกเหนือจาก', 'ช่วงท้าย', 'ตลอดศก', 'คราวใด', 'เช่นใด', 'พวกแก', 'จัดทำ', 'กว้างๆ', 'เท่ากับ', 'นอกจากนี้', 'พวกนั้น', 'ล่าสุด', 'ซึ่งก็คือ', 'เก็บ', 'สูง', 'ตน', 'สั้น', 'จริงๆจังๆ', 'พอจะ', 'ขาด', 'บ้าง', 'หน', 'เยอะแยะ', 'กล่าว', 'ครั้งที่', 'นะ', 'หาก', 'จนขณะนี้', 'ที', 'เมื่อเย็น', 'มัน', 'พวกมึง', 'เท่าไร', 'บางที', 'เผื่อที่', 'เป็นๆ', 'อย่างนี้', 'มั้ยเนี่ย', 'กระทำ', 'ในที่', 'นั่นไง', 'จวนเจียน', 'ครั้งหนึ่ง', 'ด้วยเหมือนกัน', 'ยาว', 'จนแม้น', 'จริงๆ', 'จรดกับ', 'ที่ไหน', 'เหตุผล', 'คุณๆ', 'บัดเดี๋ยวนี้', 'ส่วนมาก', 'เพียงพอ', 'บางที่', 'ช่วงๆ', 'ความ', 'พอตัว', 'แท้', 'ดั่งเคย', 'ช่วงหน้า', 'คล้ายกับว่า', 'อาจเป็นด้วย', 'ตลอดทั่วถึง', 'ทุกสิ่ง', 'เผื่อจะ', 'รับ', 'โตๆ', 'บางขณะ', 'ขณะเดียวกัน', 'นับแต่', 'ครั้งกระนั้น', 'แม้ว่า', 'เกี่ยวๆ', 'แม้แต่', 'เมื่อก่อน', 'เสียจนถึง', 'เป็นแต่เพียง', 'ถึงบัดนั้น', 'พวกฉัน', 'คราวโน้น', 'เช่นที่', 'ยืนยัน', 'ยอมรับ', 'ภาค', 'นักๆ', 'เป็นต้นมา', 'จากนั้น', 'คราวหลัง', 'คราที่', 'เสียด้วย', 'รือว่า', 'พูด', 'ภายใต้', 'ครั้งครา', 'เลย', 'ง่ายๆ', 'รึว่า', 'หลังจาก', 'เต็มๆ', 'พอดี', 'ช่วงนี้', 'หลัง', 'ทีใด', 'เพียงเพราะ', 'ยังโง้น', 'พื้นๆ', 'ดั่ง', 'ผ่านๆ', 'เช่นกัน', 'กลุ่มก้อน', 'ได้มา', 'คราวละ', 'แต่เดิม', 'น่าจะ', 'น่า', 'ทำไร', 'ออก', 'แห่งโน้น', 'แค่ว่า', 'กันนะ', 'มั้ยนั่น', 'เป็นต้นไป', 'กลับ', 'แห่ง', 'ไม่ค่อย', 'ดั่งเก่า', 'ว่า', 'ยิ่งขึ้น', 'ครบครัน', 'มั้ยล่ะ', 'หนอ', 'ทุกทาง', 'สูงๆ', 'สมัยโน้น', 'เปลี่ยนแปลง', 'เสร็จ', 'ตรงๆ', 'กระผม', 'นี้', 'ก็ตามที', 'รวมทั้ง', 'ประการหนึ่ง', 'ครั้งหลัง', 'ทุกครา', 'คราหนึ่ง', 'ไม่ค่อยจะ', 'ยังจะ', 'เห็นจะ', 'ได้ที่', 'แต่ที่', 'ใหม่', 'ครานี้', 'เร็วๆ', 'ปัจจุบัน', 'จนกว่า', 'ล้วน', 'ใคร่', 'หรือไม่', 'ทําให้', 'ข้า', 'แต่ไร', 'เช่นดัง', 'เนื่องจาก', 'อันเนื่องมาจาก', 'เธอ', 'ดัง', 'นั่น', 'หรือไง', 'อีก', 'ตาม', 'กันเอง', 'ด้วย', 'พบว่า', 'เห็น', 'ครั้งคราว', 'เอา', 'พวกเขา', 'ผิดๆ', 'มิฉะนั้น', 'เพียงใด', 'ถูก', 'ยังไง', 'อย่างไหน', 'กันดีกว่า', 'ขณะที่', 'อาจเป็น', 'นี่ไง', 'ช่วงแรก', 'พา', 'นานๆ', 'พร้อมที่', 'ตลอดกาลนาน', 'ที่ละ', 'จวบจน', 'ภายใน', 'สุด', 'ใน', 'ค่ะ', 'นิด', 'ฉะนั้น', 'เผื่อว่า', 'หากแม้นว่า', 'จะได้', 'นอกเหนือ', 'อย่างดี', 'กับ', 'พยายาม', 'ที่แล้ว', 'ช้า', 'ครั้งนี้', 'นอก', 'พร้อมเพียง', 'น้อยๆ', 'ซึ่งๆ', 'เรียบ', 'พวกโน้น', 'ซะจนกระทั่ง', 'สิ้นกาลนาน', 'เช่นดังที่', 'ยิ่งเมื่อ', 'กำหนด', 'สบาย', 'ทุกอัน', 'ราย', 'จนทั่ว', 'อะไร', 'ฝ่ายใด', 'เหตุ', 'แต่ก่อน', 'บ่อย', 'ยิ่งจน', 'บัดดล', 'เข้า', 'ซึ่งก็', 'จัด', 'ข้างต้น', 'ดั่งกับว่า', 'ช่วงนั้น', 'จัดตั้ง', 'ทั้งมวล', 'เสียนั่นเอง', 'สูงกว่า', 'ผิด', 'ทันที', 'ก็ดี', 'คล้ายกับ', 'นับจากนั้น', 'ช่วงถัดไป', 'คล้ายว่า', 'ขณะหนึ่ง', 'ฉะนี้', 'ครา', 'ให้ไป', 'อื่นๆ', 'บางคราว', 'โต', 'ณ', 'นับแต่นั้น', 'ทั้งนั้นด้วย', 'พึง', 'ค่อยๆ', 'มองว่า', 'คงอยู่', 'นี่นา', 'ง่าย', 'จึงเป็น', 'รือ', 'เขา', 'อัน', 'ภาคฯ', 'พึ่ง', 'แต่', 'ยาก', 'ตลอดปี', 'คิด', 'จวบ', 'คำ', 'พวกนี้', 'ตลอดทั่ว', 'แก', 'เป็นการ', 'ของ', 'วันนี้', 'นั้น', 'ฯลฯ', 'ถือว่า', 'แต่จะ', 'เป็นที', 'เราๆ', 'พร้อมกัน', 'ตั้งแต่', 'เห็นแก่', 'เพราะ', 'เช่นที่ว่า', 'ก็แค่', 'ด้วยเหตุเพราะ', 'อย่างหนึ่ง', 'คราไหน', 'พวก', 'นิดหน่อย', 'เท่านั้น', 'ข้างๆ', 'พอแล้ว', 'ขณะ', 'ยกให้', 'ยังคง', 'จัง', 'ตามแต่', 'ประการ', 'เล่าว่า', 'ประการฉะนี้', 'แยะ', 'อันใด', 'เพียงเพื่อ', 'ครั้งนั้น', 'ประสบ', 'จนตลอด', 'เรื่อย', 'เพื่อที่', 'ขวางๆ', 'คล้าย', 'เปิดเผย', 'เช่นก่อน', 'เช่นดังก่อน', 'ถึงแก่', 'นี่แน่ะ', 'ทุกครั้ง', 'เป็นเพียง', 'ก่อนหน้านี้', 'จำ', 'น้อย', 'แต่อย่างใด', 'ๆ', 'ครัน', 'ยิ่งจะ', 'ปิด', 'หนอย', 'เมื่อวาน', 'ถึงแม้ว่า', 'บางครั้ง', 'ในช่วง', 'แสดงว่า', 'แต่เพียง', 'กำลังจะ', 'เมื่อไหร่', 'นาย', 'เป็น', 'มากกว่า', 'เมื่อ', 'จัดให้', 'บางครา', 'สูงส่ง', 'คง', 'อันๆ', 'กลุ่มๆ', 'ก็จะ', 'ถึงบัดนี้', 'ครั้งใด', 'นี้เอง', 'เสมือนว่า', 'ฯ', 'ช้าๆ', 'ทั้งๆ', 'กันเถอะ', 'ในเมื่อ', 'เสร็จสมบูรณ์', 'แก้ไข', 'ถือ', 'ทุก', 'ซึ่งกันและกัน', 'ทั้ง', 'ร่วมมือ', 'แค่เพียง', 'แม้', 'ทำให้', 'ถึงแม้', 'ด้าน', 'เข้าใจ', 'ภายหลัง', 'เผื่อ', 'มึง', 'จำพวก', 'ยาวนาน', 'ระยะๆ', 'เพื่อ', 'จรด', 'อย่างเช่น', 'อาจ', 'รวมถึง', 'เพื่อที่จะ', 'เชื่อว่า', 'ตรง', 'ยืนนาน', 'บางๆ', 'มัก', 'จับ', 'หลาย', 'เพียงแต่', 'ใช้', 'พอที', 'ผ่าน', 'ด้วยเหตุนี้', 'ก็คือ', 'อย่างไรก็ได้', 'ช่วง', 'ค่อนข้าง', 'หรือ', 'ทั้งที่', 'การ', 'เล็กน้อย', 'คือ', 'สมัยก่อน', 'เป็นที่', 'แต่ถ้า', 'ถูกๆ', 'อย่างน้อย', 'ค่อนมาทาง', 'เมื่อครั้งก่อน', 'ร่วมด้วย', 'ช้านาน', 'ไม่ว่า', 'นับ', 'ถึงเมื่อ', 'ก่อนหน้า', 'เกิด', 'ตลอดจน', 'ส่วนเกิน', 'หนึ่ง', 'ทั้งหมด', 'พอสมควร', 'เต็มไปด้วย', 'เรา', 'ครับ', 'มั๊ย', 'เห็นว่า', 'เท่ากัน', 'บางกว่า', 'เล็กๆ', 'น่ะ', 'ใครๆ', 'ฯล', 'มีแต่', 'สั้นๆ', 'อันที่จะ', 'ทุกตัว', 'ที่ได้', 'เหล่านั้น', 'อนึ่ง', 'เหตุไร', 'ระยะ', 'ทั้งนั้น', 'จากนี้', 'คราวๆ', 'ต่อ', 'กลุ่ม', 'บัดนี้', 'ละ', 'นิดๆ', 'เฉยๆ', 'ประมาณ', 'อดีต', 'ให้แด่', 'บอกแล้ว', 'นับจากนี้', 'พอควร', 'ดังกับ', 'เช่นไร', 'เป็นต้น', 'ภาย', 'เป็นดัง', 'ด้วยเพราะ', 'ยิ่งนัก', 'คล้ายกันกับ', 'เฉกเช่น', 'เดียว', 'ทํา', 'ที่สุด', 'จด', 'ให้มา', 'ซึ่ง', 'นำ', 'สมัยนี้', 'เพิ่ม', 'อันไหน', 'นั่นเป็น', 'พวกคุณ', 'อย่างเดียว', 'เมื่อครั้ง', 'พบ', 'จาก', 'พวกท่าน', 'ไง', 'รวมๆ', 'เสียนี่กระไร', 'เร็ว', 'กระนั้น', 'อย่างยิ่ง', 'เมื่อคราวก่อน', 'ทุกวัน', 'ยิ่งแล้ว', 'เกี่ยวกัน', 'มักจะ', 'มันๆ', 'สิ้น', 'จนกระทั่ง', 'จ๊ะ', 'ด้วยเหตุว่า', 'นี่แหละ', 'ค่อย', 'พอสม', 'สําหรับ', 'คราวไหน', 'อย่างไรก็', 'เกิน', 'ชาว', 'ซึ่งกัน', 'นั่นเอง', 'ทั้งสิ้น', 'ทั้งเป็น', 'เท่าไหร่', 'เพราะว่า', 'เพื่อให้', 'หาใช่', 'คุณ', 'ทุกๆ', 'อย่างมาก', 'นำมา', 'ประกอบ', 'ใดๆ', 'นํา', 'จะ', 'บ่อยครั้ง', 'เชื่อถือ', 'ไกลๆ', 'มากมาย', 'แยะๆ', 'ส่วนที่', 'รับรอง', 'ซะก่อน', 'ก็ตามแต่', 'เป็นเพียงว่า', 'ทั้งหลาย', 'อย่างๆ', 'ขอ', 'บาง', 'แห่งไหน', 'หมดกัน', 'จึงจะ', 'ได้แต่', 'สิ่งนี้', 'มาก', 'ดังเคย', 'รวมด้วย', 'ถึงแม้จะ', 'เยอะๆ', 'ตนฯ', 'ช่วย', 'เพราะฉะนั้น', 'บอก', 'เกี่ยวกับ', 'เฉพาะ', 'ขึ้น', 'เมื่อคราวที่', 'อย่างที่', 'เถอะ', 'เกือบ', 'ครั้งละ', 'ตลอด', 'รวดเร็ว', 'ก็แล้วแต่', 'ไม่ค่อยเป็น', 'ตลอดไป', 'ก็ต่อเมื่อ', 'ที่ใด', 'พอๆ', 'ด้วยเช่นกัน', 'ผู้ใด', 'ขณะนี้', 'แค่ไหน', 'ฝ่าย', 'เสียยิ่งนัก', 'เชื่อ', 'จนแม้', 'ที่แห่งนั้น', 'จริงจัง', 'เคยๆ', 'ภายหน้า', 'ที่ซึ่ง', 'เล็ก', 'หรือไร', 'เสียยิ่ง', 'ฉัน', 'ทุกชิ้น', 'ต่างก็', 'และ', 'นั้นไว', 'แค่', 'ซะจนถึง', 'เช่นดังเก่า', 'เพียง', 'ถึงเมื่อใด', 'เหล่า', 'ที่นั้น', 'นับตั้งแต่', 'เพิ่ง', 'ตลอดทั้ง', 'ทว่า', 'จัดการ', 'มุ่ง', 'ตนเอง', 'แบบ', 'เสีย', 'เช่น', 'สมัย', 'จัดหา', 'ทั้งคน', 'แต่ทว่า', 'ยืนยง', 'ตามด้วย', 'อันละ', 'หมด', 'อย่างไรเสีย', 'กว้าง', 'ครั้งก่อน', 'เป็นแต่', 'ส่วนใหญ่', 'นอกจากที่', 'เมื่อใด', 'แล้วเสร็จ', 'สุดๆ', 'อย่าง', 'อันที่จริง', 'คิดว่า', 'ทรง', 'ช่วงหลัง', 'มิ', 'ไกล', 'นับแต่ที่', 'แหละ', 'เช่นเมื่อ', 'เช่นที่เคย', 'รึ', 'โดย', 'เมื่อคราว', 'จ๋า', 'แม้นว่า', 'เสร็จกัน', 'ใหญ่ๆ', 'อยาก', 'ส่วนด้อย', 'ที่แท้จริง', 'ตลอดเวลา'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "# ตัดคำ\n",
        "print(\"default dictionary:\", word_tokenize(text))\n",
        "\n",
        "words = set(thai_words())  # thai_words() returns frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "print(\"custom dictionary :\", custom_tokenizer.word_tokenize(text))\n",
        "words = custom_tokenizer.word_tokenize(text)\n",
        "\n",
        "# ดึงรายการ stop words ในภาษาไทย\n",
        "stopwords = thai_stopwords()\n",
        "# แปลง stop words เป็นเซ็ต (set) สำหรับการเพิ่ม/ลบ\n",
        "\n",
        "stopwords = set(stopwords)\n",
        "\n",
        "# เพิ่มคำใหม่เข้าไปใน stop words\n",
        "stopwords.add(\"ไหม\")\n",
        "stopwords.add(\"ทำงาน\")\n",
        "\n",
        "# ลบคำบางคำออกจาก stop words\n",
        "stopwords.discard(\"เคย\")\n",
        "stopwords.discard(\"ใช้\")\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in words if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words)\n",
        "print(\"Filtered words:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9UOjfeQX9o2",
        "outputId": "711071a8-8493-40b7-a0e8-ececee0151c7"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['เคย', 'ใช้', 'กูเกิ้ล', 'โครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ล', 'ไดร์', 'ฟ', 'ไหม']\n",
            "custom dictionary : ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Original words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Filtered words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'แชร์', 'รูปภาพ', 'กูเกิ้ลไดร์ฟ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part of Speech tagging"
      ],
      "metadata": {
        "id": "_9FW41E0WuWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
        "pos_tag(words)"
      ],
      "metadata": {
        "id": "ernbPKbDOq2w",
        "outputId": "249e13d0-5a9f-4e55-8b82-a0e2bb6b55bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('เคย', 'XVMM'),\n",
              " ('ใช้', 'VACT'),\n",
              " ('กูเกิ้ลโครม', 'NCMN'),\n",
              " ('เพื่อ', 'RPRE'),\n",
              " ('แชร์', 'VACT'),\n",
              " ('รูปภาพ', 'NCMN'),\n",
              " ('ใน', 'RPRE'),\n",
              " ('กูเกิ้ลไดร์ฟ', 'NCMN'),\n",
              " ('ไหม', 'NCMN')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The reordering of sentences based on Indian Sign Language grammar rules."
      ],
      "metadata": {
        "id": "IdPMtwGPqLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_to_tsl(words):\n",
        "    # ลบคำที่ไม่จำเป็น เช่น คำบอกเพศ คำเสริม\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # เรียงลำดับโดยย้ายคำบอกเวลาไปด้านหน้า\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # รายการคำบอกเวลา\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # เรียงลำดับ (Time-Topic-Comment)\n",
        "    reordered_sentence = time_elements + non_time_elements\n",
        "\n",
        "    # รวมคำกลับเป็นประโยค\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ประโยคตัวอย่าง\n",
        "text = \"เคยใช้กูเกิ้ลโครมเพื่อแชร์รูปภาพในกูเกิ้ลไดร์ฟไหม\"\n",
        "\n",
        "# เพิ่มคำพิเศษใน custom dictionary\n",
        "words = set(thai_words())  # thai_words() คืนค่า frozenset\n",
        "words.add(\"กูเกิ้ลโครม\")\n",
        "words.add(\"กูเกิ้ลไดร์ฟ\")\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "\n",
        "# ตัดคำด้วย custom dictionary\n",
        "words_tokenized = custom_tokenizer.word_tokenize(text)\n",
        "\n",
        "# ดึงรายการ stop words ภาษาไทย\n",
        "stopwords = set(thai_stopwords())\n",
        "\n",
        "# เพิ่มคำใหม่เข้าไปใน stop words\n",
        "stopwords.add(\"ไหม\")\n",
        "stopwords.add(\"ทำงาน\")\n",
        "\n",
        "# ลบคำบางคำออกจาก stop words\n",
        "stopwords.discard(\"เคย\")\n",
        "stopwords.discard(\"ใช้\")\n",
        "\n",
        "# ลบคำที่อยู่ใน stop words\n",
        "filtered_words = [word for word in words_tokenized if word not in stopwords]\n",
        "\n",
        "print(\"Original words:\", words_tokenized)\n",
        "print(\"Filtered words:\", filtered_words)\n",
        "\n",
        "# ใช้คำที่กรองแล้วมาเรียงลำดับตามกฎ TSL\n",
        "tsl_sentence = reorder_to_tsl(filtered_words)\n",
        "print(\"Reordered sentence (TSL):\", tsl_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoAZxOzaEPXi",
        "outputId": "750d7712-1bd0-499a-9c42-93cb461218cd"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'เพื่อ', 'แชร์', 'รูปภาพ', 'ใน', 'กูเกิ้ลไดร์ฟ', 'ไหม']\n",
            "Filtered words: ['เคย', 'ใช้', 'กูเกิ้ลโครม', 'แชร์', 'รูปภาพ', 'กูเกิ้ลไดร์ฟ']\n",
            "Reordered sentence (TSL): เคย ใช้ กูเกิ้ลโครม แชร์ รูปภาพ กูเกิ้ลไดร์ฟ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reorder_to_tsl_and_noun_before_verb(sentence):\n",
        "    # Tokenize the sentence using PyThaiNLP\n",
        "    words = pythainlp.word_tokenize(sentence, engine='newmm')  # Using the 'newmm' tokenizer\n",
        "\n",
        "    # Simplify the sentence by removing articles and auxiliary verbs\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # Step 1: Move time words to the beginning (TSL structure)\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # List of common time-related words\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # Reorder the sentence (Time-Topic-Comment structure)\n",
        "    sentence_after_tsl = time_elements + non_time_elements\n",
        "\n",
        "    # Step 2: Perform part-of-speech tagging to identify nouns and verbs\n",
        "    pos_tags = pos_tag(sentence_after_tsl, engine='perceptron', corpus='orchid')\n",
        "\n",
        "    # Separate nouns and verbs\n",
        "    nouns = [word for word, pos in pos_tags if pos.startswith('N')]  # Noun\n",
        "    verbs = [word for word, pos in pos_tags if pos.startswith('V')]  # Verb\n",
        "    others = [word for word, pos in pos_tags if not (pos.startswith('N') or pos.startswith('V'))]  # Other words\n",
        "\n",
        "    # Combine and remove duplicates\n",
        "    reordered_sentence = list(dict.fromkeys(time_elements + nouns + others + verbs))\n",
        "\n",
        "    # Join words back into a string\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ตัวอย่างประโยคภาษาไทย\n",
        "sentence3 = \"ฉันจะไปตลาดพรุ่งนี้\"\n",
        "\n",
        "# Reorder the sentence following TSL grammar and nouns before verbs\n",
        "reordered_sentence3 = reorder_to_tsl_and_noun_before_verb(sentence3)\n",
        "print(\"ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา:\", reordered_sentence3)"
      ],
      "metadata": {
        "id": "1_YvPxmnyLuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211ac41c-38a8-406e-acf8-1a8d565044c3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา: พรุ่งนี้ ตลาด ฉัน ไป\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization: Reduce each word to its base form, depending on its POS tag."
      ],
      "metadata": {
        "id": "vG3y24f52B2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "\n",
        "print(get_lemma(\"ที่ปรึกษา\"))"
      ],
      "metadata": {
        "id": "1w-R7DtYCsF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49088714-1121-4eb8-fe18-b2896925acd1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ปรึกษา\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"สวัสดีค่ะอาจารย์ที่ปรึกษา\"\n",
        "\n",
        "print(\"default dictionary:\", word_tokenize(text1))\n",
        "\n",
        "# ฟังก์ชันสำหรับการปรับรูปเป็นคำพื้นฐาน\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",   # จับคู่ \"สวัสดีค่ะ\" เป็น \"สวัสดี\"\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",    # จับคู่ \"ที่ปรึกษา\" เป็น \"ปรึกษา\"\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# สร้าง custom dictionary\n",
        "words = set(thai_words())\n",
        "words.add(\"อาจารย์\")\n",
        "words.add(\"ปรึกษา\")\n",
        "words.discard(\"อาจารย์ที่ปรึกษา\")\n",
        "words.add(\"สวัสดีค่ะ\")  # เพิ่มคำ \"สวัสดีค่ะ\"\n",
        "\n",
        "# ใช้ custom tokenizer\n",
        "custom_tokenizer = Tokenizer(words)\n",
        "tokenized_words = custom_tokenizer.word_tokenize(text1)\n",
        "\n",
        "# ใช้ฟังก์ชัน get_lemma เพื่อปรับคำ\n",
        "lemmatized_words = [get_lemma(word) for word in tokenized_words]\n",
        "\n",
        "print(\"newmm (custom dictionary):\", tokenized_words)\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwDSJ7YXKKif",
        "outputId": "d4706b9c-f6ff-4d41-aa54-7318bd35bf5a"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default dictionary: ['สวัสดี', 'ค่ะ', 'อาจารย์ที่ปรึกษา']\n",
            "newmm (custom dictionary): ['สวัสดีค่ะ', 'อาจารย์', 'ที่ปรึกษา']\n",
            "Lemmatized words: ['สวัสดี', 'อาจารย์', 'ปรึกษา']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pythainlp\n",
        "from pythainlp.tag import pos_tag\n",
        "\n",
        "# ฟังก์ชันการหาคำพื้นฐาน (lemma)\n",
        "def get_lemma(word):\n",
        "    lemmas = {\n",
        "        \"ที่ปรึกษา\": \"ปรึกษา\",\n",
        "        \"สวัสดีค่ะ\": \"สวัสดี\",\n",
        "    }\n",
        "    return lemmas.get(word, word)\n",
        "\n",
        "# ฟังก์ชันการเรียงตามไวยากรณ์ TSL และเรียงคำนามก่อนกริยา พร้อมการใช้ lemma\n",
        "def reorder_to_tsl_and_noun_before_verb(sentence):\n",
        "    # Tokenize the sentence using PyThaiNLP\n",
        "    words = pythainlp.word_tokenize(sentence, engine='newmm')  # Using the 'newmm' tokenizer\n",
        "\n",
        "    # Simplify the sentence by removing articles and auxiliary verbs\n",
        "    simplified_sentence = [word for word in words if word not in ['คือ', 'เป็น', 'อยู่', 'มี', 'จะ', 'ได้', 'แล้ว', 'ก็', 'ที่', 'นั้น', 'นี้']]\n",
        "\n",
        "    # Step 1: Move time words to the beginning (TSL structure)\n",
        "    time_words = ['วันนี้', 'พรุ่งนี้', 'เมื่อวาน', 'ตอนเช้า', 'ตอนเย็น']  # List of common time-related words\n",
        "    time_elements = [word for word in simplified_sentence if word in time_words]\n",
        "    non_time_elements = [word for word in simplified_sentence if word not in time_words]\n",
        "\n",
        "    # Reorder the sentence (Time-Topic-Comment structure)\n",
        "    sentence_after_tsl = time_elements + non_time_elements\n",
        "\n",
        "    # Step 2: Perform part-of-speech tagging to identify nouns and verbs\n",
        "    pos_tags = pos_tag(sentence_after_tsl, engine='perceptron', corpus='orchid')\n",
        "\n",
        "    # Apply the custom get_lemma function to all words in the sentence\n",
        "    sentence_after_lemma = [get_lemma(word) for word in sentence_after_tsl]\n",
        "\n",
        "    # Separate nouns and verbs\n",
        "    nouns = [word for word, pos in pos_tags if pos.startswith('N')]  # Noun\n",
        "    verbs = [word for word, pos in pos_tags if pos.startswith('V')]  # Verb\n",
        "    others = [word for word, pos in pos_tags if not (pos.startswith('N') or pos.startswith('V'))]  # Other words\n",
        "\n",
        "    # Reorder: Nouns -> Others -> Verbs\n",
        "    reordered_sentence = time_elements + nouns + others + verbs\n",
        "\n",
        "    # Join words back into a string\n",
        "    return ' '.join(reordered_sentence)\n",
        "\n",
        "# ตัวอย่างประโยคภาษาไทย\n",
        "sentence3 = \"ฉันจะไปตลาดพรุ่งนี้\"\n",
        "\n",
        "# Reorder the sentence following TSL grammar and nouns before verbs\n",
        "reordered_sentence3 = reorder_to_tsl_and_noun_before_verb(sentence3)\n",
        "print(\"ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา พร้อมการใช้ lemma:\", reordered_sentence3)"
      ],
      "metadata": {
        "id": "MLZ07UzPEC8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16cc54b-a070-43b1-9b4c-3e1d0240b428"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ประโยคที่เรียงตามไวยากรณ์ TSL และคำนามก่อนกริยา พร้อมการใช้ lemma: พรุ่งนี้ ตลาด พรุ่งนี้ ฉัน ไป\n"
          ]
        }
      ]
    }
  ]
}